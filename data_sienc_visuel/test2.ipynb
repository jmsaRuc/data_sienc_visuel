{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFMinerPDFasHTMLLoader\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from langchain_community.docstore.document import Document\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(pat):\n",
    "    loader = PDFMinerPDFasHTMLLoader(pat)\n",
    "    data = loader.load()[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(data):\n",
    "    soup = BeautifulSoup(data.page_content, 'html.parser')\n",
    "    content = soup.find_all('span')\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snippets(content):\n",
    "    import re\n",
    "    cur_hSimNum = None\n",
    "    cur_fsm = None\n",
    "    cur_fs = None\n",
    "    cur_text = ''\n",
    "    snippets = []   # first collect all snippets that have the same font size\n",
    "    for c in content:\n",
    "        st = c.get('style')\n",
    "        if not st:\n",
    "            continue\n",
    "        fsm = re.findall('font-family:(.*?);',st)\n",
    "        fs = re.findall('font-size:(\\d+)px',st) \n",
    "        text_slice= c.text[:5]\n",
    "        hSimNum = re.findall(r'\\w+\\.\\w*|ยง', text_slice)\n",
    "        if not fsm or not fs:\n",
    "            continue\n",
    "        fsm = str(fsm[0]).strip()\n",
    "        fs = int(fs[0])\n",
    "        if hSimNum:\n",
    "            hSimNum = 't'\n",
    "        else:\n",
    "            hSimNum = 'f'   \n",
    "        if not cur_fsm: \n",
    "            cur_fsm = fsm\n",
    "        if not cur_fs:\n",
    "            cur_fs = fs  \n",
    "        if not cur_hSimNum:\n",
    "            cur_hSimNum = hSimNum        \n",
    "        if fsm == cur_fsm and fs == cur_fs and hSimNum == cur_hSimNum: \n",
    "            cur_text += c.text   \n",
    "        else:\n",
    "            snippets.append((cur_text,cur_fsm,cur_fs,cur_hSimNum))\n",
    "            cur_fsm = fsm\n",
    "            cur_fs = fs\n",
    "            cur_hSimNum = hSimNum\n",
    "            cur_text = c.text\n",
    "    snippets.append((cur_text,cur_fsm,cur_fs,cur_hSimNum))\n",
    "    return snippets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='D:/school/ALL_PDFs/print/W20061110525.pdf'\n",
    "data=get_data(path)\n",
    "content=get_content(data)\n",
    "snippets = get_snippets(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_snippets(data,snippets):\n",
    "    cur_idx = -1\n",
    "    semantic_snippets = []\n",
    "    # Assumption: headings have higher font size than their respective content\n",
    "    for s in snippets:\n",
    "        # if current snippet's font size > previous section's heading => it is a new heading\n",
    "        if not semantic_snippets or s[2] > semantic_snippets[cur_idx].metadata['heading_fontS']:   \n",
    "            metadata={'heading':s[0],'content_fontM':'', 'heading_fontM':s[1], 'content_fontS': 0, 'heading_fontS': s[2], 'content_has_h_elem':'', 'heading_has_h_elem':s[3]}\n",
    "            metadata.update(data.metadata)\n",
    "            semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "            cur_idx += 1\n",
    "            continue\n",
    "        \n",
    "        if s[1] != semantic_snippets[cur_idx].metadata['content_fontM']:\n",
    "            if semantic_snippets[cur_idx].page_content != '':\n",
    "                if 'Bold' in s[1] or 'Italic' in s[1] or 'BoldItalic' in s[1] or 'BoldOblique' in s[1] or 'BoldOblique' in s[1]:\n",
    "                    metadata={'heading':s[0],'content_fontM':'', 'heading_fontM':s[1], 'content_fontS': 0, 'heading_fontS': s[2], 'content_has_h_elem':'', 'heading_has_h_elem':s[3]}\n",
    "                    metadata.update(data.metadata)\n",
    "                    semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "                    cur_idx += 1\n",
    "                    continue\n",
    "                    \n",
    "        \n",
    "        if s[3] == 't':\n",
    "            if semantic_snippets[cur_idx].page_content != '':\n",
    "                if len(semantic_snippets[cur_idx].page_content) > 30000:\n",
    "                    metadata={'heading':s[0],'content_fontM':'', 'heading_fontM':s[1], 'content_fontS': 0, 'heading_fontS': s[2], 'content_has_h_elem':'', 'heading_has_h_elem':s[3]}\n",
    "                    metadata.update(data.metadata)\n",
    "                    semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "                    cur_idx += 1\n",
    "                    continue\n",
    "        # if current snippet's font size <= previous section's content => content belongs to the same section (one can also create\n",
    "        # a tree like structure for sub sections if needed but that may require some more thinking and may be data specific)\n",
    "\n",
    "            \n",
    "        if not semantic_snippets[cur_idx].metadata['content_fontS'] or not semantic_snippets[cur_idx].metadata['content_fontM'] or not semantic_snippets[cur_idx].metadata['content_has_h_elem'] or not 'Bold' in s[1] or not 'Italic' in s[1] or not 'BoldItalic' in s[1] or not 'BoldOblique' in s[1] or not  'BoldOblique' in s[1] or s[2] <= semantic_snippets[cur_idx].metadata['content_fontS']:\n",
    "            semantic_snippets[cur_idx].page_content += s[0]\n",
    "            semantic_snippets[cur_idx].metadata['content_fontM'] = s[1] if not semantic_snippets[cur_idx].metadata['content_fontM'] else semantic_snippets[cur_idx].metadata['content_fontM']\n",
    "            semantic_snippets[cur_idx].metadata['content_fontS'] = max(s[2], semantic_snippets[cur_idx].metadata['content_fontS'])\n",
    "            semantic_snippets[cur_idx].metadata['content_has_h_elem'] = s[3]\n",
    "            continue\n",
    "\n",
    "        # if current snippet's font size > previous section's content but less than previous section's heading than also make a new\n",
    "        # section (e.g. title of a PDF will have the highest font size but we don't want it to subsume all sections)\n",
    "        \n",
    "\n",
    "        \n",
    "        if s[2] > semantic_snippets[cur_idx].metadata['content_fontS'] and s[2] < semantic_snippets[cur_idx].metadata['heading_fontS']:\n",
    "            metadata={'heading':s[0],'content_fontM':'', 'heading_fontM':s[1], 'content_fontS': 0, 'heading_fontS': s[2], 'content_has_h_elem':'','heading_has_h_elem':'t'}\n",
    "            metadata.update(data.metadata)\n",
    "            semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "            cur_idx += 1\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        metadata={'heading':s[0], 'content_fontM':'', 'heading_fontM':s[1],'content_fontS': 0, 'heading_fontS': s[2],'content_has_h_elem':'','heading_has_h_elem':'t'}\n",
    "        metadata.update(data.metadata)\n",
    "        semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "        cur_idx += 1 \n",
    "    return semantic_snippets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='D:/school/ALL_PDFs/print/L20060000264.pdf'\n",
    "data=get_data(path)\n",
    "content=get_content(data)\n",
    "snippets = get_snippets(content)\n",
    "semantic_snippets = get_semantic_snippets(data,snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='D:/school/ALL_PDFs/well_structured/B20190036605.pdf'\n",
    "semantic_snippets = get_semantic_snippets(get_data(path),get_snippets(get_content(get_data(path))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(semantic_snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for snip in semantic_snippets:\n",
    "    print('HEADING:  ',snip.metadata['heading'])\n",
    "    print('-----------------')\n",
    "    print()\n",
    "    print('CONTENT_LENGT:  ',len(snip.page_content))\n",
    "    print()\n",
    "    print('CONTENT_ESTIMATET_TOKEN:  ',len(snip.page_content)/4)\n",
    "    print()\n",
    "    print('-----------------')\n",
    "    print()\n",
    "    print('CONTENT_FIRST_500C:')\n",
    "    print()\n",
    "    print(snip.page_content[:500])\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_opject(obj, file_name):\n",
    "    with open(file_name, 'wb') as outp:\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL) \n",
    "    outp.close()\n",
    "\n",
    "\n",
    "\n",
    "def snipmaker(file_pathT):\n",
    "    loader = PDFMinerPDFasHTMLLoader(file_pathT)\n",
    "    data = loader.load()[0] \n",
    "    soup = BeautifulSoup(data.page_content,'html.parser')\n",
    "    content = soup.find_all('div')\n",
    "    cur_fsm = None\n",
    "    cur_fs = None\n",
    "    cur_text = ''\n",
    "    snippets = []\n",
    "    for c in content:\n",
    "        st = c.get('style')\n",
    "        if not st:\n",
    "            continue\n",
    "        fsm = re.findall('font-family:(.*?);',st)\n",
    "        fs = re.findall('font-size:(\\d+)px',st)\n",
    "        if not fsm or not fs:\n",
    "            continue\n",
    "        fsm = str(fsm[0]).strip()\n",
    "        fs = int(fs[0])\n",
    "        if not cur_fsm: \n",
    "            cur_fsm = fsm\n",
    "        if not cur_fs:\n",
    "            cur_fs = fs      \n",
    "        if fsm == cur_fsm and fs == cur_fs: \n",
    "            cur_text += c.text  \n",
    "        else:\n",
    "            snippets.append((cur_text,cur_fsm,cur_fs))\n",
    "            cur_fsm = fsm\n",
    "            cur_fs = fs\n",
    "            cur_text = c.text\n",
    "    snippets.append((cur_text,cur_fsm,cur_fs))    \n",
    "    \n",
    "    cur_idx = -1\n",
    "    semantic_snippets = []\n",
    "    # Assumption: headings have higher font size than their respective content\n",
    "    for s in snippets:\n",
    "        # if current snippet's font size > previous section's heading => it is a new heading\n",
    "        if not semantic_snippets  or s[2] > semantic_snippets[cur_idx].metadata['heading_fontS']:   \n",
    "            metadata={'heading':s[0],'content_fontM':'', 'heading_fontM':s[1], 'content_fontS': 0, 'heading_fontS': s[2]}\n",
    "            metadata.update(data.metadata)\n",
    "            semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "            cur_idx += 1\n",
    "            continue\n",
    "        \n",
    "        if s[1] != semantic_snippets[cur_idx].metadata['content_fontM']:\n",
    "            if semantic_snippets[cur_idx].page_content != '':\n",
    "                    if 'Bold' in s[1] or 'Italic' in s[1] or 'BoldItalic' in s[1] or 'BoldOblique' in s[1] or 'BoldOblique' in s[1]:\n",
    "                        metadata={'heading':s[0],'content_fontM':'', 'heading_fontM':s[1], 'content_fontS': 0, 'heading_fontS': s[2]}\n",
    "                        metadata.update(data.metadata)\n",
    "                        semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "                        cur_idx += 1\n",
    "                        continue\n",
    "        # if current snippet's font size <= previous section's content => content belongs to the same section (one can also create\n",
    "        # a tree like structure for sub sections if needed but that may require some more thinking and may be data specific)\n",
    "\n",
    "            \n",
    "        if not semantic_snippets[cur_idx].metadata['content_fontS'] or not semantic_snippets[cur_idx].metadata['content_fontM'] or not 'Bold' in s[1] or not 'Italic' in s[1] or not 'BoldItalic' in s[1] or not 'BoldOblique' in s[1] or not  'BoldOblique' in s[1] or s[2] <= semantic_snippets[cur_idx].metadata['content_fontS']:\n",
    "            semantic_snippets[cur_idx].page_content += s[0]\n",
    "            semantic_snippets[cur_idx].metadata['content_fontM'] = s[1] if not semantic_snippets[cur_idx].metadata['content_fontM'] else semantic_snippets[cur_idx].metadata['content_fontM']\n",
    "            semantic_snippets[cur_idx].metadata['content_fontS'] = max(s[2], semantic_snippets[cur_idx].metadata['content_fontS'])\n",
    "            continue\n",
    "\n",
    "        # if current snippet's font size > previous section's content but less than previous section's heading than also make a new\n",
    "        # section (e.g. title of a PDF will have the highest font size but we don't want it to subsume all sections)\n",
    "        \n",
    "    \n",
    "        \n",
    "        if s[2] > semantic_snippets[cur_idx].metadata['content_fontS'] and s[2] < semantic_snippets[cur_idx].metadata['heading_fontS']:\n",
    "            metadata={'heading':s[0],'content_fontM':'', 'heading_fontM':s[1], 'content_fontS': 0, 'heading_fontS': s[2]}\n",
    "            metadata.update(data.metadata)\n",
    "            semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "            cur_idx += 1\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        metadata={'heading':s[0], 'content_fontM':'', 'heading_fontM':s[1],'content_fontS': 0, 'heading_fontS': s[2]}\n",
    "        metadata.update(data.metadata)\n",
    "        semantic_snippets.append(Document(page_content='',metadata=metadata))\n",
    "        cur_idx += 1\n",
    "    return semantic_snippets\n",
    "\n",
    "def run (file_paths, file_names): \n",
    "    for i in range(len(file_paths)):\n",
    "        gc.collect()\n",
    "        snip = snipmaker(file_paths[i])\n",
    "        save_path = 'D:/school/ALL_PDFs/snips2/' + file_names[i] + '.pkl'\n",
    "        gc.collect()\n",
    "        save_opject(snipmaker(file_paths[i]), 'D:/school/ALL_PDFs/snips2/' + file_names[i] + '.pkl')\n",
    "        gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "file_names1=[]\n",
    "file_paths = []\n",
    "def get_file_names(directory):\n",
    "    file_namesT = []\n",
    "    file_paths = []\n",
    "    for dir in directory:\n",
    "        for root, dirs, files in os.walk(dir):\n",
    "            for file in files:\n",
    "                file_path = root+'/'+file\n",
    "                file_paths.append(file_path)\n",
    "                split_file= file.split('.')\n",
    "                file_name = split_file[0]\n",
    "                file_namesT.append(file_name)     \n",
    "    return file_namesT, file_paths\n",
    "# Example usage\n",
    "directory_path = ['D:/school/ALL_PDFs/well_structured','D:/school/ALL_PDFs/print']\n",
    "file_names1,file_paths = get_file_names(directory_path)\n",
    "print(len(file_names1))\n",
    "print(len(file_paths))\n",
    "print(file_paths[48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_pdf = []\n",
    "file_names = []\n",
    "def make_urls_and_file_names(files):\n",
    "    urls_pdfT = []\n",
    "    file_namesT = []\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        file_namesT.append(file)\n",
    "        urls_pdfT.append(\"https://www.retsinformation.dk/eli/accn/\" + file)\n",
    "        count += 1    \n",
    "    print(count)    \n",
    "    return urls_pdfT,file_namesT\n",
    "\n",
    "urls_pdf, file_names = make_urls_and_file_names(file_names1)\n",
    "\n",
    "print(len(urls_pdf))\n",
    "print(len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksed_filenamses = []\n",
    "\n",
    "chunksed_filenamses = list(chunks(file_names, 1))  \n",
    "chunksed_urls_pdf = list(chunks(urls_pdf, 1))\n",
    "chunksed_file_paths = list(chunks(file_paths, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = 0\n",
    "\n",
    "\n",
    "print(len(chunksed_urls_pdf[part]))\n",
    "print(chunksed_urls_pdf[part])\n",
    "print(len(chunksed_filenamses[part]))\n",
    "print(chunksed_filenamses[part])\n",
    "print(len(chunksed_file_paths[part]))\n",
    "print(chunksed_file_paths[part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snipMandSave(file_pathsT2, fT2):\n",
    "    \n",
    "    run(file_pathsT2, fT2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(chunksed_urls_pdf)):\n",
    "    snipMandSave(chunksed_file_paths[i], chunksed_filenamses[i])\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-sienc-visuel-mvgrUAeD-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
    "items": [
        {
            "tags": [
                "python",
                "python-3.x",
                "dictionary"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 449260,
                        "reputation": 24874,
                        "user_id": 843953,
                        "user_type": "registered",
                        "accept_rate": 95,
                        "profile_image": "https://www.gravatar.com/avatar/d72147724fe203e81103ea6764240845?s=256&d=identicon&r=PG",
                        "display_name": "pho",
                        "link": "https://stackoverflow.com/users/843953/pho"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709066414,
                    "answer_id": 78070456,
                    "question_id": 78070444,
                    "body_markdown": "Iterate over the dictionary&#39;s `.items()` instead of just iterating over the dictionary (which is equivalent to iterating over its keys)\r\n\r\n```\r\nbar = {key: (value if not value % 2 else 0) for key, value in {&quot;hello&quot;: 123, &quot;world&quot;: 456}.items()}\r\n```\r\n\r\nThis feels icky to me, because it&#39;s unnecessary work to first define the dictionary and then iterate over all its contents. Especially for the case of a dictionary containing a million entries you mention in your comments.\r\nI&#39;d suggest you programmatically modify your dictionary and output the modified dictionary, and then use that output instead to define your class variable.\r\n",
                    "title": "Is there a concise one liner to process and replace values in a dictionary? (using some form of dictionary comprehension)"
                },
                {
                    "owner": {
                        "account_id": 30627087,
                        "reputation": 9,
                        "user_id": 23478411,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJ-gFKOQ4Z6rnWJj4IuZkAI2bzuKefYHjZDZecSK0ZQ=k-s256",
                        "display_name": "alix_coder",
                        "link": "https://stackoverflow.com/users/23478411/alix-coder"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709066572,
                    "answer_id": 78070466,
                    "question_id": 78070444,
                    "body_markdown": "You can achieve this by using a dictionary comprehension within the class definition. Here&#39;s how you can do it:\r\n\r\n    class Foo:\r\n    bar = {key: (val if val % 2 != 0 else 0) for key, val in {&quot;hello&quot;: 123, &quot;world&quot;: 456}.items()}\r\n",
                    "title": "Is there a concise one liner to process and replace values in a dictionary? (using some form of dictionary comprehension)"
                },
                {
                    "owner": {
                        "account_id": 2744437,
                        "reputation": 3182,
                        "user_id": 13395230,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/Gd4Jo.jpg?s=256&g=1",
                        "display_name": "Bobby Ocean",
                        "link": "https://stackoverflow.com/users/13395230/bobby-ocean"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709066686,
                    "answer_id": 78070473,
                    "question_id": 78070444,
                    "body_markdown": "I don&#39;t understand the need for a 1 liner. When you write to a class, you can access the attributes of the class while it is loading into memory. \r\n\r\n```\r\nclass Foo:\r\n    bar = dict(hello=123,world=456)\r\n    bar = {k:(Foo.bar[k] if Foo.bar[k]%2 else 0) for k in Foo.bar}\r\n```",
                    "title": "Is there a concise one liner to process and replace values in a dictionary? (using some form of dictionary comprehension)"
                }
            ],
            "owner": {
                "account_id": 11824738,
                "reputation": 3760,
                "user_id": 8652920,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/43e5d6ad1374a13d24484b4c211c6556?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "notacorn",
                "link": "https://stackoverflow.com/users/8652920/notacorn"
            },
            "is_answered": false,
            "view_count": 33,
            "favorite_count": 0,
            "answer_count": 3,
            "score": 0,
            "creation_date": 1709066125,
            "question_id": 78070444,
            "body_markdown": "say you have a class like\r\n\r\n```\r\nclass Foo:\r\n  bar = {&quot;hello&quot;: 123, &quot;world&quot;: 456}\r\n```\r\n\r\nAnd I want to define `Foo.bar` such that for all the keys and values of `bar`, all even values are replaced with 0.\r\n\r\nIs there a clean way to do that in one line? The issue is that the dictionary `{&quot;hello&quot;: 123, &quot;world&quot;: 456}` is not stored into a variable yet (I want `bar` to be defined with the processing already happened)\r\n\r\nSo the below is impossible because `d` is not a variable, but it feels (to me) like `d` has to be defined to do the one liner I&#39;m asking for.\r\n```\r\nclass Foo:\r\n  bar = {key: (d[key] if not d[key] % 2 else 0) for key in {&quot;hello&quot;: 123, &quot;world&quot;: 456}}\r\n```\r\n\r\nIs what I&#39;m asking for impossible?",
            "link": "https://stackoverflow.com/questions/78070444/is-there-a-concise-one-liner-to-process-and-replace-values-in-a-dictionary-usi",
            "title": "Is there a concise one liner to process and replace values in a dictionary? (using some form of dictionary comprehension)"
        },
        {
            "tags": [
                "python",
                "pandas",
                "dataframe",
                "merge"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 15012162,
                        "reputation": 6314,
                        "user_id": 10836309,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/H8pxC.jpg?s=256&g=1",
                        "display_name": "gtomer",
                        "link": "https://stackoverflow.com/users/10836309/gtomer"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709066709,
                    "answer_id": 78070475,
                    "question_id": 78070420,
                    "body_markdown": "Try `pd.melt`:\r\n\r\n    pd.melt(df2, id_vars=[&#39;NAME&#39;], value_vars=[&#39;2000&#39;, &#39;2001&#39;, &#39;2002&#39;])\r\n\r\nThis will give:\r\n\r\n       NAME variable  value\r\n    0  Anna     2000      5\r\n    1  Mary     2000      3\r\n    2  Paul     2000      2\r\n    3  Anna     2001      4\r\n    4  Mary     2001      2\r\n    5  Paul     2001      3\r\n    6  Anna     2002      3\r\n    7  Mary     2002      5\r\n    8  Paul     2002      4\r\n\r\nNow you can merge\r\n\r\nYou can also rename column names:\r\n\r\n    df2.rename(columns={&#39;variable&#39;:&#39;YEAR&#39;, &#39;value&#39;:&#39;SCORE&#39;})",
                    "title": "Populating new pandas column values from different dataframe that match a column value and column name"
                },
                {
                    "owner": {
                        "account_id": 13900216,
                        "reputation": 184517,
                        "user_id": 10035985,
                        "user_type": "registered",
                        "profile_image": "https://lh4.googleusercontent.com/-1WgJ_2yA-78/AAAAAAAAAAI/AAAAAAAAAOA/0CBOlYqYe7M/photo.jpg?sz=256",
                        "display_name": "Andrej Kesely",
                        "link": "https://stackoverflow.com/users/10035985/andrej-kesely"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709066911,
                    "answer_id": 78070495,
                    "question_id": 78070420,
                    "body_markdown": "Alternative, use `.set_index()`/`.stack()`:\r\n\r\n```py\r\nprint(\r\n    df2.set_index(&quot;NAME&quot;)\r\n    .stack()\r\n    .reset_index()\r\n    .rename(columns={0: &quot;SCORE&quot;, &quot;level_1&quot;: &quot;YEAR&quot;})\r\n)\r\n```\r\n\r\nPrints:\r\n\r\n```none\r\n   NAME  YEAR  SCORE\r\n0  Anna  2000      5\r\n1  Anna  2001      4\r\n2  Anna  2002      3\r\n3  Mary  2000      3\r\n4  Mary  2001      2\r\n5  Mary  2002      5\r\n6  Paul  2000      2\r\n7  Paul  2001      3\r\n8  Paul  2002      4\r\n```",
                    "title": "Populating new pandas column values from different dataframe that match a column value and column name"
                }
            ],
            "owner": {
                "account_id": 30645244,
                "reputation": 11,
                "user_id": 23492815,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/373d3238d9fbbf07c3cff0fc5808313f?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "no_more_lemons",
                "link": "https://stackoverflow.com/users/23492815/no-more-lemons"
            },
            "is_answered": false,
            "view_count": 21,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 1,
            "creation_date": 1709065836,
            "question_id": 78070420,
            "body_markdown": "Apologies for weird phrasing, wasn&#39;t sure how to even convey the issue but hopefully the example will. I have two dataframes and want to populate a new column in df1 with values from df2 by matching them based on values in two df1 columns. The problem is that in df2 one of these values is not in the columns but rather is the column name. \r\n\r\n\r\n```\r\ndf1\r\n\r\nNAME YEAR\r\n\r\nAnna 2002\r\nMary 2001\r\nPaul 2000\r\nPaul 2001\r\nMary 2002\r\nAnna 2001\r\nAnna 2000\r\nMary 2000\r\nPaul 2002\r\n\r\n\r\ndf2\r\n\r\nNAME 2000 2001 2002\r\n\r\nAnna 5    4    3\r\nMary 3    2    5\r\nPaul 2    3    4\r\n\r\n\r\nexpected result:\r\n\r\ndf1\r\n\r\nNAME YEAR SCORE\r\n\r\nAnna 2002 3\r\nMary 2001 2\r\nPaul 2000 2\r\nPaul 2001 3\r\nMary 2002 5\r\nAnna 2001 4\r\nAnna 2000 5\r\nMary 2000 3\r\nPaul 2002 4\r\n\r\n\r\n```\r\n\r\n\r\nI can merge the two dataframes on NAME but that does not solve my issue since I would just add the three columns. I was wondering if this would require some for loops iterating through columns but I&#39;m a beginner and am not sure if I&#39;m not overcomplicating things (and creating a very long process). Even just a hint at where to look in the documentation would be super helpful!",
            "link": "https://stackoverflow.com/questions/78070420/populating-new-pandas-column-values-from-different-dataframe-that-match-a-column",
            "title": "Populating new pandas column values from different dataframe that match a column value and column name"
        },
        {
            "tags": [
                "python",
                "django-rest-framework"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 20363425,
                        "reputation": 1,
                        "user_id": 14937274,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/818fcb61a4fe3269671eed223c9482a1?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Ergan",
                        "link": "https://stackoverflow.com/users/14937274/ergan"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709065016,
                    "answer_id": 78070362,
                    "question_id": 78070254,
                    "body_markdown": "The error message you&#39;re encountering indicates that the street field is expected in the validated data passed to the serializer but it&#39;s missing. This issue arises because the street field is being directly accessed in the create and update methods without checking if it&#39;s actually provided in the validated data.\r\n\r\nTo resolve this issue, you should modify your code to handle cases where street might not be included in the validated data. Here&#39;s a way to adjust your update method to handle the absence of the street field:\r\n\r\n    def update(self, instance, validated_data):\r\n    try:\r\n        with transaction.atomic():\r\n            user = instance.user\r\n            user.first_name = validated_data.get(&quot;user&quot;, {}).get(&quot;first_name&quot;, user.first_name)\r\n            user.last_name = validated_data.get(&quot;user&quot;, {}).get(&quot;last_name&quot;, user.last_name)\r\n            user.email = validated_data.get(&quot;user&quot;, {}).get(&quot;username&quot;, user.email)  # Assuming `email` is under `user` dict and using `username` key as per your `create` method logic\r\n            if &#39;user&#39; in validated_data and &#39;password&#39; in validated_data[&#39;user&#39;]:\r\n                user.set_password(validated_data[&quot;user&quot;][&quot;password&quot;])\r\n            user.save()\r\n            \r\n            instance.gender = validated_data.get(&quot;gender&quot;, instance.gender)\r\n            instance.birth_date = validated_data.get(&quot;birth_date&quot;, instance.birth_date)\r\n            instance.mobile_number = validated_data.get(&quot;mobile_number&quot;, instance.mobile_number)\r\n            instance.barangay = validated_data.get(&quot;barangay&quot;, instance.barangay)\r\n            instance.municipality = validated_data.get(&quot;municipality&quot;, instance.municipality)\r\n            instance.province = validated_data.get(&quot;province&quot;, instance.province)\r\n            \r\n            # Check for &#39;street&#39; in validated_data before accessing it\r\n            if &quot;street&quot; in validated_data:\r\n                instance.street = validated_data[&quot;street&quot;]\r\n            \r\n            if &quot;name_extension&quot; in validated_data:\r\n                instance.name_extension = validated_data[&quot;name_extension&quot;]\r\n            \r\n            instance.save()\r\n            return {\r\n                    &quot;success&quot;: True,\r\n                    &quot;message&quot;: &quot;User updated successfully.&quot;,\r\n                   }\r\n    except KeyError as e:\r\n        raise serializers.ValidationError(f&quot;Missing required field: {e}&quot;)\r\n\r\n\r\nAdditionally, ensure that the street field is correctly defined in your UserDetail model and is included in the serializer fields if it&#39;s intended to be part of the serialized/deserialized data.\r\n\r\nIf the street field is optional and not always provided, this approach will help you avoid the KeyError by not trying to access or update the street attribute unless it&#39;s explicitly included in the input data.",
                    "title": "My update function works but it returns an error"
                }
            ],
            "owner": {
                "account_id": 30645202,
                "reputation": 1,
                "user_id": 23492780,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJhItCgiP8dZaUMSshRqpV6Keae0wpEd9kau7_uBk1E=k-s256",
                "display_name": "Mercury Gingo",
                "link": "https://stackoverflow.com/users/23492780/mercury-gingo"
            },
            "is_answered": false,
            "view_count": 21,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709063775,
            "question_id": 78070254,
            "body_markdown": "I have an update function for my account in serializer\r\n\r\n        class AccountSerializer(serializers.ModelSerializer):\r\n        password = serializers.CharField(source=&quot;user.password&quot;, write_only=True)\r\n        first_name = serializers.CharField(source=&quot;user.first_name&quot;)\r\n        last_name = serializers.CharField(source=&quot;user.last_name&quot;)\r\n        email = serializers.EmailField(source=&quot;user.username&quot;)\r\n        name_extension = serializers.CharField(required=False)\r\n        \r\n        class Meta:\r\n            model = UserDetail\r\n            fields = [\r\n                \r\n                &quot;password&quot;,\r\n                &quot;gender&quot;,\r\n                &quot;name_extension&quot;,\r\n                &quot;email&quot;,\r\n                &quot;birth_date&quot;,\r\n                &quot;mobile_number&quot;,\r\n                &quot;barangay&quot;,\r\n                &quot;municipality&quot;,\r\n                &quot;province&quot;,\r\n                &quot;first_name&quot;,\r\n                &quot;last_name&quot;,\r\n            ]\r\n        \r\n        def create(self, validated_data):\r\n            try:\r\n                with transaction.atomic():\r\n                    verification_token_new = get_random_string(length=22) + date.today().strftime(&quot;%Y%m%d&quot;)\r\n                    user = User.objects.create_user(\r\n                        email=validated_data[&quot;user&quot;][&quot;username&quot;],\r\n                        username=validated_data[&quot;user&quot;][&quot;username&quot;],\r\n                        password=validated_data[&quot;user&quot;][&quot;password&quot;],\r\n                        first_name=validated_data[&quot;user&quot;][&quot;first_name&quot;],\r\n                        last_name=validated_data[&quot;user&quot;][&quot;last_name&quot;],\r\n                        is_superuser=False,\r\n                        is_staff=False,\r\n                        is_active=False,\r\n                    )\r\n                    \r\n                    Verification.objects.create(\r\n                        user=user,\r\n                        code=verification_token_new,\r\n                    )\r\n        \r\n                    user_detail_data = {\r\n                        &quot;user&quot;: user,\r\n                        &quot;gender&quot;: validated_data[&quot;gender&quot;],\r\n                        &quot;birth_date&quot;: validated_data[&quot;birth_date&quot;],\r\n                        &quot;mobile_number&quot;: validated_data[&quot;mobile_number&quot;],\r\n                        &quot;barangay&quot;: validated_data[&quot;barangay&quot;],\r\n                        &quot;municipality&quot;: validated_data[&quot;municipality&quot;],\r\n                        &quot;province&quot;: validated_data[&quot;province&quot;],\r\n                        &quot;street&quot;: validated_data[&quot;street&quot;],\r\n                    }\r\n        \r\n                    if &quot;name_extension&quot; in validated_data:\r\n                        user_detail_data[&quot;name_extension&quot;] = validated_data[&quot;name_extension&quot;]\r\n        \r\n                    UserDetail.objects.create(**user_detail_data)\r\n                    \r\n                    subject = &#39;Verify Your Email Address&#39;\r\n                    recipient_email = user.email\r\n                    register_message_url = os.environ.get(&#39;register_message&#39;)\r\n                    context = {\r\n                        &#39;user&#39;: user,\r\n                        &#39;verification_url&#39;: str(register_message_url % (str(verification_token_new), user.id))\r\n                    }\r\n                    print(register_message_url)\r\n                    template = &#39;verification_email.html&#39;\r\n        \r\n                    send_email(subject, recipient_email, context, template)\r\n        \r\n                    return {\r\n                        &quot;success&quot;: True,\r\n                        &quot;message&quot;: &quot;User created successfully. Verification email sent.&quot;,\r\n                    }\r\n        \r\n            except Exception as e:\r\n                print(f&quot;Error creating user: {e}&quot;)\r\n        \r\n                # If any exception occurs, transaction.atomic() will roll back any changes made within its \r\n                raise serializers.ValidationError({&quot;success&quot;: False, &quot;message&quot;: f&quot;{e}&quot;})\r\n            \r\n        \r\n        def update(self, instance, validated_data):\r\n            try:\r\n                with transaction.atomic():\r\n                    user = instance.user\r\n                    user.first_name = validated_data.get(&quot;first_name&quot;, user.first_name)\r\n                    user.last_name = validated_data.get(&quot;last_name&quot;, user.last_name)\r\n                    user.email = validated_data.get(&quot;email&quot;, user.email)\r\n                    if &#39;password&#39; in validated_data:\r\n                        user.set_password(validated_data[&quot;password&quot;])\r\n                    user.save()\r\n                    \r\n                    instance.gender = validated_data.get(&quot;gender&quot;, instance.gender)\r\n                    instance.birth_date = validated_data.get(&quot;birth_date&quot;, instance.birth_date)\r\n                    instance.mobile_number = validated_data.get(&quot;mobile_number&quot;, instance.mobile_number)\r\n                    instance.barangay = validated_data.get(&quot;barangay&quot;, instance.barangay)\r\n                    instance.municipality = validated_data.get(&quot;municipality&quot;, instance.municipality)\r\n                    instance.province = validated_data.get(&quot;province&quot;, instance.province)\r\n                    instance.street = validated_data.get(&quot;street&quot;, instance.street)\r\n        \r\n                    instance.name_extension = validated_data.get(&quot;name_extension&quot;, instance.name_extension)\r\n        \r\n                    instance.save()\r\n                    return {\r\n                            &quot;success&quot;: True,\r\n                            &quot;message&quot;: &quot;User created successfully. Verification email sent.&quot;,     }\r\n            except KeyError as e:\r\n                raise serializers.ValidationError(f&quot;Missing required field: {e}&quot;)\r\n\r\nit succesfully updates but returns an error &quot;Got KeyError when attempting to get a value for field `street` on serializer `AccountSerializer`.\\\\nThe serializer field might be named incorrectly and not match any attribute or key on the `dict` instance.\\\\nOriginal exception text was: &#39;street&#39;.&quot;\r\n\r\nMay I ask any ideas how can I fix this?",
            "link": "https://stackoverflow.com/questions/78070254/my-update-function-works-but-it-returns-an-error",
            "title": "My update function works but it returns an error"
        },
        {
            "tags": [
                "python",
                "pandas"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 15012162,
                        "reputation": 6314,
                        "user_id": 10836309,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/H8pxC.jpg?s=256&g=1",
                        "display_name": "gtomer",
                        "link": "https://stackoverflow.com/users/10836309/gtomer"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709066987,
                    "answer_id": 78070499,
                    "question_id": 78070233,
                    "body_markdown": "As @mozway suggested, try:\r\n\r\n    _df2 = _df[(_df.fa) &amp; (_df.fl) &amp; (~_df.fg)]\r\n\r\nThis will work if the values are boolean, i.e. True instead of &#39;TURE&#39;",
                    "title": "Conditional statement not working in Pandas"
                }
            ],
            "owner": {
                "account_id": 8349265,
                "reputation": 115,
                "user_id": 7446890,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/f240a7c0052ed5bc1f70c534c3cc9d85?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "user7446890",
                "link": "https://stackoverflow.com/users/7446890/user7446890"
            },
            "is_answered": false,
            "view_count": 26,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -1,
            "creation_date": 1709063651,
            "question_id": 78070233,
            "body_markdown": "When I write this line of code it returns empty results. Same datatype, don&#39;t know why it isn&#39;t working in vscode.\r\n\r\n\r\n````\r\n    _df2 = _df[(_df.fa == &#39;TRUE&#39;) &amp; (_df.fl == &#39;TRUE&#39;) &amp; (_df.fg == &#39;FALSE&#39;)]\r\n````",
            "link": "https://stackoverflow.com/questions/78070233/conditional-statement-not-working-in-pandas",
            "title": "Conditional statement not working in Pandas"
        },
        {
            "tags": [
                "python",
                "file"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 8260894,
                        "reputation": 2799,
                        "user_id": 6212350,
                        "user_type": "registered",
                        "accept_rate": 70,
                        "profile_image": "https://i.stack.imgur.com/qXnGn.jpg?s=256&g=1",
                        "display_name": "TheHungryCub",
                        "link": "https://stackoverflow.com/users/6212350/thehungrycub"
                    },
                    "is_accepted": false,
                    "score": 2,
                    "creation_date": 1709063704,
                    "answer_id": 78070243,
                    "question_id": 78070205,
                    "body_markdown": "The `rstrip()` method returns a new string with trailing characters removed, it doesn\u2019t modify the original string in place. You need to assign the result back to the variable. Try this:\r\n\r\n    lines = readFile.readlines()\r\n    \r\n    for i in range(len(lines)):\r\n        lines[i] = lines[i].rstrip(&#39;\\n&#39;)\r\n    \r\n    if lines[127] == &quot;&lt;th&gt;FID&lt;/th&gt;&quot;:\r\n        print(lines[127] + &quot; is equal to &lt;th&gt;FID&lt;/th&gt;&quot;)\r\n    else:\r\n        print(lines[127] + &quot; is not equal to &lt;th&gt;FID&lt;/th&gt;&quot;)\r\n\r\nThis will ensure that each line in the lines list has its trailing newline character removed.",
                    "title": "Python: rstrip(&#39;\\n&#39;) is not stripping the \\n in my list"
                }
            ],
            "owner": {
                "account_id": 25175698,
                "reputation": 1,
                "user_id": 19017920,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a-/AOh14Gh1m0pEnrFi5e7CA2Px-2w6UWZ31eAld3y95hQLKw=k-s256",
                "display_name": "Jacob Dankel",
                "link": "https://stackoverflow.com/users/19017920/jacob-dankel"
            },
            "is_answered": true,
            "view_count": 24,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709063423,
            "question_id": 78070205,
            "body_markdown": "I split a file into its lines using `.readLines()` but for some reason after I create the list and use `line.rstrip(&#39;\\n&#39;)` there is still `&#39;\\n&#39;` at the end of my items.\r\n```\r\nlines = readFile.readlines()\r\n\r\nfor line in lines :\r\n    line.rstrip(&#39;\\n&#39;)\r\n\r\nif lines[127] == &quot;&lt;th&gt;FID&lt;/th&gt;&quot; :\r\n    print(lines[127] + &quot;is equal to &lt;th&gt;FID&lt;/th&gt;&quot;)\r\nelse :\r\n    print(lines[127] + &quot;is not equal to &lt;th&gt;FID&lt;/th&gt;&quot;)\r\n```\r\nI tried to strip using\r\n```\r\nline.rstrip(&#39;\\n&#39;)\r\n```\r\nBut after the comparison it still outputs &lt;kbd&gt;it is not equal&lt;/kbd&gt;.",
            "link": "https://stackoverflow.com/questions/78070205/python-rstrip-n-is-not-stripping-the-n-in-my-list",
            "title": "Python: rstrip(&#39;\\n&#39;) is not stripping the \\n in my list"
        },
        {
            "tags": [
                "python",
                "azure",
                "azure-cosmosdb"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30520610,
                        "reputation": 89,
                        "user_id": 23390416,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/QBswL.jpg?s=256&g=1",
                        "display_name": "KonTheCat",
                        "link": "https://stackoverflow.com/users/23390416/konthecat"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709065369,
                    "answer_id": 78070388,
                    "question_id": 78070160,
                    "body_markdown": "I think the problem you are having is that you are using /value as partition key, which you also need to look up the item you are trying to work with. I would try the following:\r\n 1. Make a new container where your partition key is something like /config_type.\r\n 2. Make a new item in that container with whatever ID makes sense for you and the partition key value of /visit_count. This item should also have a property corresponding to the number of visitors.\r\n3. Try that with your code, modifying as needed, and see where you get to.\r\n\r\nDon&#39;t hesitate to follow up in comments, I have been doing some work in Python using Cosmos DB recently so I don&#39;t mind helping to a greater extent if needed.",
                    "title": "Updating value of the document / row in azure cosmosdb in python"
                }
            ],
            "owner": {
                "account_id": 10703226,
                "reputation": 1,
                "user_id": 7877836,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/5200cc9a2d9c0fceed45e7cbdf51d38b?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Daniel T",
                "link": "https://stackoverflow.com/users/7877836/daniel-t"
            },
            "is_answered": false,
            "view_count": 21,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709062807,
            "question_id": 78070160,
            "body_markdown": "Evening all,\r\n\r\nI am writing small project, and want to add to te website hosted in azure storage (which is static) visit counter.\r\nI want to write short script in python that when called in Azure Functions, it would update a value of the record to be +=1\r\nWay I created a document:\r\n\r\n```\r\n## Create a container entry for amount of visits\r\ntry:\r\n    item = {\r\n        &#39;id&#39;: &#39;visits&#39;,\r\n        &#39;value&#39;: 0,\r\n        &#39;description&#39;: &#39;amount of visits&#39;\r\n\r\n    }\r\n    container.create_item(body=item)\r\n    print(&#39;Successfully added to DB&#39;)\r\nexcept exceptions.CosmosHttpResponseError:\r\n    print(&#39;Cant do it&#39;)\r\n```\r\n\r\nAnd it looks like that now in the panel:\r\n[Azure CosmosDB Data Explorer](https://i.stack.imgur.com/sNZDn.png)\r\n\r\nI want to modify now visits value to be one more each time function will be called.\r\nTrying to sort this out for past two days and I don&#39;t get it.\r\nI am absolutely beginner at all of this, never done anything similar in my life, therefore if I could ask for an advice or point me where to look, that would be amazing.\r\n\r\nWhen running:\r\n```\r\nitem = container.read_item(&#39;visits&#39;, partition_key=&#39;/value&#39;)\r\nitem += 1\r\nupdated_item = container.upsert_item(item)\r\n```\r\n*I am getting:\r\nTraceback (most recent call last):\r\n  File &quot;c:\\Users\\DellWS\\Desktop\\The Cloud Resume Challenge\\The-Cloud-Resume-Challenge\\function_app.py&quot;, line 69, in &lt;module&gt;\r\n    item = container.read_item(&#39;visits&#39;, partition_key=&#39;/value&#39;)\r\n.\r\n.\r\n.\r\nazure.cosmos.exceptions.CosmosResourceNotFoundError: (NotFound) Entity with the specified id does not exist in the system. More info: https://aka.ms/cosmosdb-tsg-not-found,\r\nRequestStartTime: 2024-02-27T19:21:44.4403736Z, RequestEndTime: 2024-02-27T19:21:44.4554468Z,  Number of regions attempted:1 *\r\n\r\nTried it in a different way:\r\n\r\n```\r\n## Increment visit value\r\nitem_id = &#39;visits&#39;\r\nitem = container.read_item(item=item_id, partition_key=&#39;/value&#39;)\r\nprint(item)\r\n\r\nif item:\r\n    ## increment a value by one\r\n    item[&#39;value&#39;] += 1\r\n    container.replace_item(item=item, body=item)\r\n    print(&#39;Successfully incremented&#39;)\r\nelse:\r\n    print(&#39;Item not found, or couldnt update&#39;)\r\n```\r\nand was getting above error code as well.",
            "link": "https://stackoverflow.com/questions/78070160/updating-value-of-the-document-row-in-azure-cosmosdb-in-python",
            "title": "Updating value of the document / row in azure cosmosdb in python"
        },
        {
            "tags": [
                "python",
                "python-requests"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30637768,
                        "reputation": 9,
                        "user_id": 23486802,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKnnb7TSno_-VFHaBghuN2INDWrdVxLM23aT0sVKS-TQg=k-s256",
                        "display_name": "WissamH",
                        "link": "https://stackoverflow.com/users/23486802/wissamh"
                    },
                    "is_accepted": false,
                    "score": -1,
                    "creation_date": 1709065168,
                    "answer_id": 78070375,
                    "question_id": 78070118,
                    "body_markdown": "Both approaches should indeed work correctly in python language.\r\n\r\nBut ofc you can add some debugging statements or print statements to inspect the value of error.response and error.response.status_code to understand why the condition is not being met. This can help identify any unexpected behavior or discrepancies in the data.",
                    "title": "Python Weird Conditional Check Behavior"
                }
            ],
            "owner": {
                "account_id": 21549587,
                "reputation": 56,
                "user_id": 17369067,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/PGvYI.png?s=256&g=1",
                "display_name": "vantaboard",
                "link": "https://stackoverflow.com/users/17369067/vantaboard"
            },
            "is_answered": false,
            "view_count": 31,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709062376,
            "question_id": 78070118,
            "body_markdown": "In Python, it seems that there is a difference in the `requests` library, and likely in other cases, where doing a conditional check on a class may not be truthy.\r\n\r\nHere is a repository with two tests that demonstrate what seems to be a bug: https://github.com/vantaboard/minimal-reproduction-requests-bug\r\n\r\nAnd here are the relevant snippets:\r\n```python\r\nexcept HTTPError as error:\r\n    # This will not work as expected even if error.response is not None\r\n    if error.response and error.response.status_code == 404:\r\n        print(&quot;Not Found&quot;)\r\n                                                                         \r\n    # This does work, and I don&#39;t know why\r\n    if error.response is not None and error.response.status_code == 404:\r\n        print(&quot;Not Found&quot;)\r\n```\r\n\r\nI&#39;m wondering if this means I need to do this explicitly instead of what I&#39;m used to with other programming languages.",
            "link": "https://stackoverflow.com/questions/78070118/python-weird-conditional-check-behavior",
            "title": "Python Weird Conditional Check Behavior"
        },
        {
            "tags": [
                "python",
                "pandas",
                "numpy",
                "data-science"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 13900216,
                        "reputation": 184517,
                        "user_id": 10035985,
                        "user_type": "registered",
                        "profile_image": "https://lh4.googleusercontent.com/-1WgJ_2yA-78/AAAAAAAAAAI/AAAAAAAAAOA/0CBOlYqYe7M/photo.jpg?sz=256",
                        "display_name": "Andrej Kesely",
                        "link": "https://stackoverflow.com/users/10035985/andrej-kesely"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709063912,
                    "answer_id": 78070271,
                    "question_id": 78070079,
                    "body_markdown": "You can use [`.expanding()`][1] + `.apply()`:\r\n\r\n```py\r\ndef skew(acumulado):\r\n    demeaned_r = acumulado - acumulado.mean()\r\n    # use the population standard deviation, so set dof=0\r\n    sigma_r = acumulado.std(ddof=0)\r\n    exp = (demeaned_r**3).mean()\r\n    return exp / sigma_r**3\r\n\r\n\r\ndf1[&quot;SK_new&quot;] = df1[&quot;Col_name&quot;].expanding().apply(skew)\r\nprint(df1)\r\n```\r\n\r\nPrints:\r\n\r\n```none\r\n   Col_name        SK    SK_new\r\n0         1       NaN       NaN\r\n1         2  0.000000  0.000000\r\n2         3  0.000000  0.000000\r\n3         0  0.000000  0.000000\r\n4         1  0.271545  0.271545\r\n5         2  0.000000  0.000000\r\n6         3 -0.192012 -0.192012\r\n```\r\n\r\n\r\n  [1]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.expanding.html#pandas-series-expanding",
                    "title": "How could I optimize this function?"
                }
            ],
            "owner": {
                "account_id": 30645066,
                "reputation": 11,
                "user_id": 23492678,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKyRVggkSJ3zL9eMbwEf2GyCNCV5pD1kvWZzJtr5lmf=k-s256",
                "display_name": "Josue",
                "link": "https://stackoverflow.com/users/23492678/josue"
            },
            "is_answered": false,
            "view_count": 34,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709061822,
            "question_id": 78070079,
            "body_markdown": "I want to take all values before current and compute skewness on them, so at the end I can have a Series where each row has cumulative skewness of last values. \r\nNote that r series also contains zeroes \r\n\r\n```\r\ndef skewness_line(r):\r\n\r\n    &quot;&quot;&quot;\r\n    Computes the skewness for each row of the supplied DataFrame\r\n    Returns a Series with the skewness for each row cummulative\r\n    &quot;&quot;&quot;\r\n    acumulado = pd.Series()\r\n    result = []\r\n    contador = 0\r\n    for i in r: \r\n        acumulado[contador] = i\r\n        demeaned_r = acumulado - acumulado.mean()\r\n        # use the population standard deviation, so set dof=0\r\n        sigma_r = acumulado.std(ddof=0)\r\n        exp = (demeaned_r**3).mean()\r\n        result.append(exp/sigma_r**3)\r\n        contador += 1\r\n        \r\n    return result\r\n```\r\n\r\nUsage example\r\n\r\n```\r\ndf1[&#39;SK&#39;] = skewness(df1[&#39;Col_name&#39;])\r\ndf1.head()\r\n```",
            "link": "https://stackoverflow.com/questions/78070079/how-could-i-optimize-this-function",
            "title": "How could I optimize this function?"
        },
        {
            "tags": [
                "python",
                "windows",
                "uninstallation"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 8260894,
                        "reputation": 2799,
                        "user_id": 6212350,
                        "user_type": "registered",
                        "accept_rate": 70,
                        "profile_image": "https://i.stack.imgur.com/qXnGn.jpg?s=256&g=1",
                        "display_name": "TheHungryCub",
                        "link": "https://stackoverflow.com/users/6212350/thehungrycub"
                    },
                    "is_accepted": true,
                    "score": 0,
                    "creation_date": 1709061826,
                    "answer_id": 78070080,
                    "question_id": 78070052,
                    "body_markdown": "You could create a separate uninstallation script that is placed outside the installation directory, and it can call the uninstaller script from within the directory. \r\n\r\n1.Create an uninstallation script (uninstall.py) outside the installation directory.\r\n\r\n2.Inside uninstall.py, execute the uninstaller script (uninstaller.py) located within the installation directory using os.chdir() to change the working directory.\r\n\r\nExample:\r\n\r\n    import os\r\n\r\n    def uninstall():\r\n        uninstall_script_path = &quot;path/to/installation/directory/uninstaller.py&quot;\r\n        try:\r\n        os.chdir(&quot;path/to/installation/directory&quot;)\r\n        exec(open(uninstall_script_path).read())\r\n    except Exception as e:\r\n        print(f&quot;Error during uninstallation: {e}&quot;)\r\n\r\n    if __name__ == &quot;__main__&quot;:\r\n        uninstall()\r\n\r\nWith this, users can run uninstall.py from outside the installation directory, and it will execute uninstaller.py located within the installation directory, effectively removing the application without encountering permission issues\r\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\r\n\r\nHere\u2019s how you could modify the script to make it delete itself after uninstalling the application:\r\n\r\n    import os\r\n    import sys\r\n    import shutil\r\n\r\n    def uninstall():\r\n        install_dir = &quot;path/to/installation/directory&quot;\r\n        uninstall_script = os.path.abspath(__file__)  # Get absolute path of uninstaller script\r\n        try:\r\n        # Remove the installation directory\r\n        shutil.rmtree(install_dir)\r\n        # Remove the uninstaller script itself\r\n        os.remove(uninstall_script)\r\n        print(&quot;Uninstallation complete.&quot;)\r\n    except Exception as e:\r\n        print(f&quot;Error during uninstallation: {e}&quot;)\r\n\r\n    # Delete the script file itself\r\n    try:\r\n        os.remove(__file__)\r\n        print(&quot;Uninstaller script deleted.&quot;)\r\n    except Exception as e:\r\n        print(f&quot;Error deleting uninstaller script: {e}&quot;)\r\n\r\n    if __name__ == &quot;__main__&quot;:\r\n        uninstall()\r\n\r\nIn this updated version, after uninstalling the application and removing the installation directory, the script attempts to delete itself using `os.remove(__file__)`. This line removes the file that is currently being executed (`uninstaller.py`).\r\n",
                    "title": "How to create an uninstaller for my python app?"
                }
            ],
            "owner": {
                "account_id": 29390266,
                "reputation": 3,
                "user_id": 22518813,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/siefp.jpg?s=256&g=1",
                "display_name": "fastattack",
                "link": "https://stackoverflow.com/users/22518813/fastattack"
            },
            "is_answered": true,
            "view_count": 40,
            "favorite_count": 0,
            "accepted_answer_id": 78070080,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709061556,
            "question_id": 78070052,
            "body_markdown": "I&#39;m currently developing a python application for windows and i want to share it to my friends.\r\nTo do so, I converted my python files in to an executable using pyinstaller.\r\nI then created an installer and an updater which retrieves the files in a github repository, downloads them and unzips them to be used.\r\n\r\nI now want to create an uninstaller so it is easier to delete the application but I cannot find a great way to do it.\r\n\r\nI tried to delete the directory containing the installation but I keep getting permission errors.\r\n\r\nIs there another great way to do it ?\r\n",
            "link": "https://stackoverflow.com/questions/78070052/how-to-create-an-uninstaller-for-my-python-app",
            "title": "How to create an uninstaller for my python app?"
        },
        {
            "tags": [
                "python",
                "numpy",
                "numpy-ndarray",
                "f-string"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 15983509,
                        "reputation": 6416,
                        "user_id": 12131013,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/2ca3cc0afaf24c7597cff635749204ec?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "jared",
                        "link": "https://stackoverflow.com/users/12131013/jared"
                    },
                    "is_accepted": false,
                    "score": 2,
                    "creation_date": 1709060458,
                    "answer_id": 78069965,
                    "question_id": 78069925,
                    "body_markdown": "When you perform `np.empty(0) == ...`, if the `...` is an iterable, then it will do an elementwise comparison. Since `np.empty(0)` is empty, there isn&#39;t anything to compare, so it produces an empty `np.ndarray` with `bool` datatype. It doesn&#39;t return `True`/`False` because it would normally produce an array of boolean values, but it is empty.\r\n\r\nRegarding the &quot;internal&quot;/&quot;external&quot; comparison, that part is a typo--you&#39;re missing the function call for `np.empty` in your &quot;internal&quot; version. Fix that typo and the results will be the same.\r\n",
                    "title": "Why does comparison between empty ndarrays and empty lists behave differently if done inside an f-string?"
                }
            ],
            "owner": {
                "account_id": 2100132,
                "reputation": 314,
                "user_id": 1867985,
                "user_type": "registered",
                "accept_rate": 100,
                "profile_image": "https://www.gravatar.com/avatar/52e6a539f8223ffe4f2bf731c8d4c551?s=256&d=identicon&r=PG",
                "display_name": "realityChemist",
                "link": "https://stackoverflow.com/users/1867985/realitychemist"
            },
            "is_answered": true,
            "view_count": 32,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709060000,
            "question_id": 78069925,
            "body_markdown": "I was messing around a bit with empty `ndarray`s and uncovered some unexpected behavior.  Minimal working example:\r\n\r\n```py\r\nimport numpy as np\r\n\r\nprint(f&quot;{np.empty(0)} :: {type(np.empty(0))}&quot;)\r\nprint(f&quot;{[]} :: {type([])}&quot;)\r\n\r\nprint(f&quot;internal -&gt; {np.empty(0) == []} :: {type(np.empty == [])}&quot;)\r\n\r\nexternal = np.empty(0) == []\r\nprint(f&quot;external -&gt; {external} :: {type(external)}&quot;)\r\n```\r\n\r\nGives the output:\r\n```\r\n[] :: &lt;class &#39;numpy.ndarray&#39;&gt;`\r\n[] :: &lt;class &#39;list&#39;&gt;\r\ninternal -&gt; [] :: &lt;class &#39;bool&#39;&gt;\r\nexternal -&gt; [] :: &lt;class &#39;numpy.ndarray&#39;&gt;\r\n```\r\n\r\nI have three questions about this, and I suspect that the answers are probably related:\r\n  1. Why does numpy return an empty array instead of a boolean when comparing an empty array with an empty list (or an empty tuple, or an empty dict, or an empty set, or another instance of an empty array)?  \r\n  2. Why _don&#39;t_ we get the same type result when evaluating this inside of an f-string?\r\n  3. Why does numpy _not_ return an empty array when comparing an empty array with an empty string (`np.empty(0) == &#39;&#39;` returns False)?\r\n\r\nBased on the `FutureWarning` that gets raised when trying out the comparison to an empty string, I&#39;m guessing that the answer to (1) probably has something to do with numpy performing an element-wise comparison between iterables with no elements, but I don&#39;t really get the details, nor why cases (2) and (3) seem to behave differently.",
            "link": "https://stackoverflow.com/questions/78069925/why-does-comparison-between-empty-ndarrays-and-empty-lists-behave-differently-if",
            "title": "Why does comparison between empty ndarrays and empty lists behave differently if done inside an f-string?"
        },
        {
            "tags": [
                "python",
                "error-handling"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 21626411,
                        "reputation": 1,
                        "user_id": 15950693,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/67e789800c63b5f1f5c2e371cd3514f5?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "kushal-rana",
                        "link": "https://stackoverflow.com/users/15950693/kushal-rana"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709059415,
                    "answer_id": 78069865,
                    "question_id": 78069809,
                    "body_markdown": "Make sure your &#39;src&#39; directory is in your Python path. You can add it dynamically in your main.py file using:\r\n\r\n    import sys\r\n    sys.path.append(&#39;/path/to/src&#39;)\r\n\r\n",
                    "title": "ModuleNotFoundError: No module named"
                }
            ],
            "owner": {
                "account_id": 21626411,
                "reputation": 1,
                "user_id": 15950693,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/67e789800c63b5f1f5c2e371cd3514f5?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "kushal-rana",
                "link": "https://stackoverflow.com/users/15950693/kushal-rana"
            },
            "is_answered": false,
            "view_count": 8,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -1,
            "creation_date": 1709058708,
            "question_id": 78069809,
            "body_markdown": "I am doing a modular programming for my nlp project in a vs code. I am facing a error of no module found.\r\n```\r\n`Traceback (most recent call last):\r\n  File &quot;D:\\Projects\\Text-summarization-project\\main.py&quot;, line 1, in &lt;module&gt;\r\n    from TextSummerization.pipeline.data_ingestion_stage1 import DataIngestionTrainingPipeline\r\nModuleNotFoundError: No module named &#39;TextSummerization&#39;`\r\n```\r\n\r\nMy file structre is like:\r\n```\r\nsrc\r\n|__TextSummerization\r\n   |__pipeline\r\n      |__data_ingestion_stage1.py\r\nmain.py\r\nsetup.py\r\napp.py\r\n```\r\nI don&#39;t understand what is a main cause of the problem here. Please help me to find out.\r\n\r\nI check the module name and fiel path all are okay.",
            "link": "https://stackoverflow.com/questions/78069809/modulenotfounderror-no-module-named",
            "title": "ModuleNotFoundError: No module named"
        },
        {
            "tags": [
                "python",
                "matplotlib",
                "google-colaboratory",
                "python-import",
                "tensorflow-model-garden"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 17886993,
                        "reputation": 1,
                        "user_id": 12994446,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/rOpn0.png?s=256&g=1",
                        "display_name": "Hamid",
                        "link": "https://stackoverflow.com/users/12994446/hamid"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709059453,
                    "answer_id": 78069870,
                    "question_id": 78069760,
                    "body_markdown": "if you don&#39;t install the requires packages, first you have to install the package for imported modules by code below\r\n\r\n    !pip install tf-models-official\r\n\r\n\r\nand next you must add a line for matplotlib in colab, see below\r\n\r\n    %matplotlib inline # line to add!\r\n    import tensorflow_models\r\n    import matplotlib.pyplot as plt\r\n    plt.plot([1,2,3,4])\r\n    plt.show()",
                    "title": "why importing tensorflow_models interrupt matplotlib in colab?"
                }
            ],
            "owner": {
                "account_id": 17060186,
                "reputation": 33,
                "user_id": 13142115,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/72e1e668a3be7bec6fa6f15df203cc28?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "J. Doe",
                "link": "https://stackoverflow.com/users/13142115/j-doe"
            },
            "is_answered": false,
            "view_count": 12,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709058194,
            "question_id": 78069760,
            "body_markdown": "Running\r\n``` python\r\nimport matplotlib.pyplot as plt\r\nplt.plot([1,2,3,4])\r\nplt.show()\r\n```\r\nplots the plot with no problem, but \r\n```python\r\nimport tensorflow_models\r\nimport matplotlib.pyplot as plt\r\nplt.plot([1,2,3,4])\r\nplt.show()\r\n```\r\ndoesn&#39;t plot anythig. I use colab notebook. Why is this happan?",
            "link": "https://stackoverflow.com/questions/78069760/why-importing-tensorflow-models-interrupt-matplotlib-in-colab",
            "title": "why importing tensorflow_models interrupt matplotlib in colab?"
        },
        {
            "tags": [
                "python",
                "pandas",
                "time-series"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 22084389,
                        "reputation": 223378,
                        "user_id": 16343464,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/7kTic.png?s=256&g=1",
                        "display_name": "mozway",
                        "link": "https://stackoverflow.com/users/16343464/mozway"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709062934,
                    "answer_id": 78070171,
                    "question_id": 78069726,
                    "body_markdown": "First identify the chunks of \u226530s of 0s, mask them, then form groups in between and determine if the duration is \u226530s:\r\n```\r\n# identify null values\r\nm = df[&#39;Value&#39;].eq(0)\r\n# group consecutive\r\ngroup = (~m).cumsum()\r\n\r\n# compute the duration of the chunks of zeros\r\nzero_chunks = df.loc[m, &#39;Timestamp&#39;].groupby(group).agg(np.ptp)\r\n\r\n# identify chunks \u2265 30s\r\nzero_chunks_gt_30s = zero_chunks[zero_chunks.ge(&#39;30s&#39;)].index\r\n\r\n# identify external zeros\r\nexternal_zeros = m.cummin() | m[::-1].cummin()\r\n\r\n# exclude 0s that are external or part of a chunks \u2265 30s\r\nexcluded = group.isin(drop)&amp;m|external_zeros\r\n\r\n# form groups in between, identify those \u2265 30s\r\ndf[&#39;Events&#39;] = (df.loc[~excluded, &#39;Timestamp&#39;]\r\n                   .groupby(excluded.cumsum())\r\n                   .transform(lambda x: np.ptp(x)&gt;=pd.Timedelta(&#39;30s&#39;))\r\n                   .reindex(df.index, fill_value=0)\r\n                   .astype(int)\r\n                )\r\n```\r\n*NB. the output is identical to the provided one.*\r\n\r\nOutput:\r\n```\r\n             Timestamp  Value  Events\r\n0  2023-11-30 23:54:00    0.5       1\r\n1  2023-11-30 23:54:05    0.5       1\r\n2  2023-11-30 23:54:10    0.5       1\r\n3  2023-11-30 23:54:15    0.5       1\r\n4  2023-11-30 23:54:20    0.5       1\r\n5  2023-11-30 23:54:25    0.5       1\r\n6  2023-11-30 23:54:30    0.5       1\r\n7  2023-11-30 23:54:35    0.5       1\r\n8  2023-11-30 23:54:40    0.0       1\r\n9  2023-11-30 23:54:45    0.0       1\r\n10 2023-11-30 23:54:50    0.0       1\r\n11 2023-11-30 23:54:55    0.5       1\r\n12 2023-11-30 23:55:00    0.5       1\r\n13 2023-11-30 23:55:05    0.5       1\r\n14 2023-11-30 23:55:10    0.5       1\r\n15 2023-11-30 23:55:15    0.5       1\r\n16 2023-11-30 23:55:20    0.5       1\r\n17 2023-11-30 23:55:25    0.5       1\r\n18 2023-11-30 23:55:30    0.0       1\r\n19 2023-11-30 23:55:35    0.0       1\r\n20 2023-11-30 23:55:40    0.5       1\r\n21 2023-11-30 23:55:45    0.5       1\r\n22 2023-11-30 23:55:50    0.5       1\r\n23 2023-11-30 23:55:55    0.5       1\r\n24 2023-11-30 23:56:00    0.5       1\r\n25 2023-11-30 23:56:05    0.5       1\r\n26 2023-11-30 23:56:10    0.0       0\r\n27 2023-11-30 23:56:15    0.0       0\r\n28 2023-11-30 23:56:20    0.0       0\r\n29 2023-11-30 23:56:25    0.0       0\r\n30 2023-11-30 23:56:30    0.0       0\r\n31 2023-11-30 23:56:35    0.0       0\r\n32 2023-11-30 23:56:40    0.0       0\r\n33 2023-11-30 23:56:45    0.0       0\r\n34 2023-11-30 23:56:50    0.0       0\r\n35 2023-11-30 23:56:55    0.0       0\r\n36 2023-11-30 23:57:00    0.5       0\r\n37 2023-11-30 23:57:05    0.5       0\r\n38 2023-11-30 23:57:10    0.0       0\r\n39 2023-11-30 23:57:15    0.0       0\r\n40 2023-11-30 23:57:20    0.0       0\r\n41 2023-11-30 23:57:25    0.0       0\r\n42 2023-11-30 23:57:30    0.0       0\r\n43 2023-11-30 23:57:35    0.0       0\r\n44 2023-11-30 23:57:40    0.0       0\r\n45 2023-11-30 23:57:45    0.0       0\r\n46 2023-11-30 23:57:50    0.0       0\r\n47 2023-11-30 23:57:55    0.0       0\r\n48 2023-11-30 23:58:00    0.5       1\r\n49 2023-11-30 23:58:05    0.5       1\r\n50 2023-11-30 23:58:10    0.5       1\r\n51 2023-11-30 23:58:15    0.5       1\r\n52 2023-11-30 23:58:20    0.5       1\r\n53 2023-11-30 23:58:25    0.5       1\r\n54 2023-11-30 23:58:30    0.5       1\r\n55 2023-11-30 23:58:35    0.5       1\r\n56 2023-11-30 23:58:40    0.5       1\r\n57 2023-11-30 23:58:45    0.5       1\r\n58 2023-11-30 23:58:50    0.5       1\r\n59 2023-11-30 23:58:55    0.0       0\r\n60 2023-11-30 23:59:00    0.0       0\r\n61 2023-11-30 23:59:05    0.0       0\r\n62 2023-11-30 23:59:10    0.0       0\r\n```",
                    "title": "Identifying events in timeseries Pandas dataframe"
                }
            ],
            "owner": {
                "account_id": 14845066,
                "reputation": 1,
                "user_id": 10720603,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/2269396129760798/picture?type=large",
                "display_name": "Sam",
                "link": "https://stackoverflow.com/users/10720603/sam"
            },
            "is_answered": false,
            "view_count": 57,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709057894,
            "question_id": 78069726,
            "body_markdown": "I am trying to identify events in a timeseries Pandas dataframe. An event is when a value is non-zero for more than 30 seconds. An event can contain values that equal 0 as long as the values are not 0 for a consecutive 30 seconds or longer. If an event is shorter than 30 seconds and is surrounded by zeroes, it is not an event. An event ends at the last non-zero value where the following values are zero for 30 seconds or more. I want the output to look something like the Events column in the reprex. \r\n\r\nReprex:\r\n\r\n```\r\nimport pandas as pd\r\n\r\n\r\nTimestamp = pd.date_range(&quot;11-30-2023 23:54:00&quot;, periods = 63, freq = &quot;5s&quot;)\r\nValue=[0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.0,0.0,0.0,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.0,0.0,0.5,0.5,0.5,0.5,0.5,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.0,0.0,0.0,0.0]\r\nEvents = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0] \r\ndf = pd.DataFrame({&quot;Timestamp&quot;:Timestamp, &quot;Value&quot;:Value, &quot;Events&quot;:Events})\r\n```",
            "link": "https://stackoverflow.com/questions/78069726/identifying-events-in-timeseries-pandas-dataframe",
            "title": "Identifying events in timeseries Pandas dataframe"
        },
        {
            "tags": [
                "python",
                "google-drive-api",
                "service-accounts"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30637768,
                        "reputation": 9,
                        "user_id": 23486802,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKnnb7TSno_-VFHaBghuN2INDWrdVxLM23aT0sVKS-TQg=k-s256",
                        "display_name": "WissamH",
                        "link": "https://stackoverflow.com/users/23486802/wissamh"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709059815,
                    "answer_id": 78069903,
                    "question_id": 78069598,
                    "body_markdown": "As u said u can use the oauth method but here&#39;s how it works:\r\n\r\n--&gt;Initially, you authenticate your application using OAuth 2.0, which involves obtaining an access token and a refresh token.The access token is used to make requests to the Google Drive API on behalf of the user.\r\n\r\n--&gt;Everytime the access token expires, you use the refresh token to obtain a new access token without needing the user to re-authenticate.You continue using the new access token to make requests to the Google Drive API.\r\n\r\n--&gt;If the refresh token expires (which is after a long time), you&#39;ll need to re-authenticate your application with the user.",
                    "title": "google drive upload via python api unattended"
                }
            ],
            "owner": {
                "account_id": 18605945,
                "reputation": 43,
                "user_id": 13559571,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/5bb5eeaa74fd2225a2c38e345cc59a26?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "New Dev",
                "link": "https://stackoverflow.com/users/13559571/new-dev"
            },
            "is_answered": true,
            "view_count": 34,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709056522,
            "question_id": 78069598,
            "body_markdown": "i have a requirement to upload video files to google drive unattended. i want to use google drive api.  but the problem is that \r\n1) if i use service account, googe is creating a service account email and asking me to share a folder to upload files. So my google drive is not the owner of the file. And we are not sure where these files are being stored\r\n2) if i use oauth method its populating a webpage for login and tokens are perishing quickly which can&#39;t be useful for unattended execution.\r\n\r\nWhen i ran below code to impersonate email i am getting error.\r\n\r\n```import os\r\nimport googleapiclient.discovery\r\nfrom google.oauth2.service_account import Credentials\r\n\r\n# Load service account credentials from JSON key file\r\nSERVICE_ACCOUNT_KEY_FILE = &#39;apikeys.json&#39;\r\nSCOPES = [&#39;https://www.googleapis.com/auth/drive&#39;]\r\n\r\ndef impersonate_user(user_email):\r\n    credentials = Credentials.from_service_account_file(SERVICE_ACCOUNT_KEY_FILE, scopes=SCOPES)\r\n    credentials = credentials.with_subject(user_email)\r\n    return credentials\r\n\r\ndef upload_file_to_drive(credentials, file_path, folder_id):\r\n    drive_service = googleapiclient.discovery.build(&#39;drive&#39;, &#39;v3&#39;, credentials=credentials)\r\n\r\n    file_metadata = {&#39;name&#39;: &#39;my_video.mp4&#39;, &#39;parents&#39;: [folder_id]}\r\n    media = googleapiclient.http.MediaFileUpload(file_path, mimetype=&#39;video/mp4&#39;)\r\n    uploaded_file = drive_service.files().create(\r\n        body=file_metadata, media_body=media, fields=&#39;id&#39;).execute()\r\n\r\n    print(f&#39;File uploaded with ID: {uploaded_file[&quot;id&quot;]}&#39;)\r\n\r\nif __name__ == &#39;__main__&#39;:\r\n    # Replace with the user&#39;s email and target folder ID\r\n    user_email = &#39;osara.jenkins.rt@gmail.com&#39;\r\n    target_folder_id = &#39;1unzEKIYnXnBlYEaJxIEiWpHM2MA-Du6D&#39;\r\n    video_file_path = r&#39;C:\\Users\\M000747\\OneDrive - Osara Technologies Limited\\Desktop\\coding\\zoom_download\\2024-02-27_17-44-15\\CSEC Integrated Science\\CSEC Integrated Science_shared_screen_with_speaker_view_2024-02-24T22_35_06Z.mp4&#39;\r\n\r\n    user_credentials = impersonate_user(user_email)\r\n    upload_file_to_drive(user_credentials, video_file_path, target_folder_id)```\r\n\r\nError:\r\n raise exceptions.RefreshError(\r\ngoogle.auth.exceptions.RefreshError: (&#39;unauthorized_client: Client is unauthorized to retrieve access tokens using this method, or client not authorized for any of the scopes requested.&#39;, {&#39;error&#39;: &#39;unauthorized_client&#39;, &#39;error_description&#39;: &#39;Client is unauthorized to retrieve access tokens using this method, or client not authorized for any of the scopes requested.&#39;})\r\n\r\nkindly help\r\n\r\n",
            "link": "https://stackoverflow.com/questions/78069598/google-drive-upload-via-python-api-unattended",
            "title": "google drive upload via python api unattended"
        },
        {
            "tags": [
                "python",
                "amazon-web-services",
                "aws-lambda"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 5320278,
                        "reputation": 1366,
                        "user_id": 4875300,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/v92OG.jpg?s=256&g=1",
                        "display_name": "Hugo Barona",
                        "link": "https://stackoverflow.com/users/4875300/hugo-barona"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709058551,
                    "answer_id": 78069787,
                    "question_id": 78069588,
                    "body_markdown": "In summary, both approaches have their merits, and the choice depends on factors such as cold start time sensitivity, resource management, and the nature of your Lambda workload. To reuse connections, consider using connection pooling and ensuring proper scoping to mitigate potential issues.\r\n\r\n**First Version (Connection Created Inside lambda_handler):**\r\n\r\n - Pros:\r\n\r\n    - Resource Management: Ensures proper closure of the database connection after each Lambda invocation.\r\n    - Isolation: Each invocation gets a new connection, ensuring isolation.\r\n\r\n- Cons:\r\n\r\n    - Overhead: Establishing a new connection may introduce some overhead.\r\n\r\n**Second Version (Connection Created Outside lambda_handler):**\r\n\r\n- Pros:\r\n\r\n    - Reuse: Reuses the same connection, potentially reducing the overhead of connection setup.\r\n    - Faster Cold Starts: May result in faster cold starts if connection setup is a significant portion.\r\n\r\n- Cons:\r\n\r\n    - Resource Leaks: Keep connection scope limited to Lambda execution; global connections can lead to resource leaks.\r\n\r\n    - Concurrency Issues: Ensure thread safety if multiple invocations modify the same global connection.\r\n\r\n**Recommendations:**\r\n- Limited Connection Scope: If reusing connections, limit the connection scope to the Lambda execution.\r\n- Use Connection Pooling: Consider using connection pooling for efficient connection management.\r\n- Lambda Concurrency: Be aware of Lambda concurrency limits and ensure thread safety or use connection pooling.",
                    "title": "Implications of querying database before lambda_handler"
                },
                {
                    "owner": {
                        "account_id": 18369,
                        "reputation": 4199,
                        "user_id": 2574178,
                        "user_type": "registered",
                        "accept_rate": 89,
                        "profile_image": "https://www.gravatar.com/avatar/3deb9b445b44293d8852a1efd932a0b9?s=256&d=identicon&r=PG",
                        "display_name": "Christian Loris",
                        "link": "https://stackoverflow.com/users/2574178/christian-loris"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709059899,
                    "answer_id": 78069916,
                    "question_id": 78069588,
                    "body_markdown": "When working with a database connection in a Lambda function, it is best to follow [AWS best practices][1] and use INIT code (which is where you are almost heading) to load expensive resources. \r\n\r\n&gt; Take advantage of execution environment reuse to improve the performance of your function. Initialize SDK clients and database connections outside of the function handler, and cache static assets locally in the /tmp directory. Subsequent invocations processed by the same instance of your function can reuse these resources. This saves cost by reducing function run time.\r\n\r\nLambda can run from either a COLD or WARM start.  On COLD start, the code outside the lambda handler is executed.  When a Lambda is run from a WARM start, the resources loading during COLD start will be available.  By including resources like database connection opening in the COLD start, subsequent WARM starts will not have to re-execute the same expensive operation.  Getting to reuse the WARM start requires that calls to the specific Lambda be within a short period of time.  This can greatly reduce the execution time on your Lambda functions and this reduce costs!\r\n\r\nBased on where you were going, I would say to rewrite it as such:\r\n\r\n    import pandas\r\n    import pymysql\r\n    \r\n    con = pymysql.connect()\r\n     \r\n    def get_db_data(con_):\r\n        query = &quot;SELECT * FROM mytable&quot;\r\n        data = pandas.read_sql(query, con_)\r\n        return data\r\n        \r\n    def lambda_handler(event, context):\r\n        data = get_db_data(con)\r\n        &quot;&quot;&quot;\r\n        do other things with event\r\n        &quot;&quot;&quot;\r\n        con.close()\r\n\r\nThis concept is also explained well in the AWS Lambda docs [here][2].\r\n\r\n\r\n  [1]: https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html#function-code\r\n  [2]: https://docs.aws.amazon.com/lambda/latest/operatorguide/static-initialization.html",
                    "title": "Implications of querying database before lambda_handler"
                }
            ],
            "owner": {
                "account_id": 8505828,
                "reputation": 32228,
                "user_id": 7128934,
                "user_type": "registered",
                "accept_rate": 97,
                "profile_image": "https://i.stack.imgur.com/oI2SB.jpg?s=256&g=1",
                "display_name": "d.b",
                "link": "https://stackoverflow.com/users/7128934/d-b"
            },
            "is_answered": true,
            "view_count": 22,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 0,
            "creation_date": 1709056398,
            "question_id": 78069588,
            "body_markdown": "Here is the pseudo-code for what current lambda function looks like;\r\n\r\n```python\r\nimport pandas\r\nimport pymysql\r\n\r\n\r\ndef get_db_data(con_):\r\n    query = &quot;SELECT * FROM mytable&quot;\r\n    data = pandas.read_sql(query, con_)\r\n    return data\r\n\r\n\r\ndef lambda_handler(event, context):\r\n    con = pymysql.connect()\r\n    data = get_db_data(con)\r\n    &quot;&quot;&quot;\r\n    do other things with event\r\n    &quot;&quot;&quot;\r\n    con.close()\r\n```\r\n\r\nI am debating if I can do this instead:\r\n\r\n```python\r\nimport pandas\r\nimport pymysql\r\n\r\ncon = pymysql.connect()\r\n\r\n\r\ndef get_db_data(con_):\r\n    query = &quot;SELECT * FROM mytable&quot;\r\n    data = pandas.read_sql(query, con_)\r\n    return data\r\n\r\n\r\ndata = get_db_data(con)\r\n\r\n\r\ndef lambda_handler(event, context):\r\n    &quot;&quot;&quot;\r\n    do other things with event\r\n    &quot;&quot;&quot;\r\n    con.close()\r\n\r\n```\r\n\r\nBut I am not sure if it is a good practice. What implications would the second option have on run-time and cost? Is it against the recommended way?",
            "link": "https://stackoverflow.com/questions/78069588/implications-of-querying-database-before-lambda-handler",
            "title": "Implications of querying database before lambda_handler"
        },
        {
            "tags": [
                "python",
                "linux",
                "windows",
                "windows-subsystem-for-linux"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 1281728,
                        "reputation": 73871,
                        "user_id": 1235698,
                        "user_type": "registered",
                        "accept_rate": 100,
                        "profile_image": "https://www.gravatar.com/avatar/90fd9ad4efef8eb93209f42183c48f3e?s=256&d=identicon&r=PG",
                        "display_name": "Marcin Orlowski",
                        "link": "https://stackoverflow.com/users/1235698/marcin-orlowski"
                    },
                    "is_accepted": false,
                    "score": 2,
                    "creation_date": 1709056877,
                    "answer_id": 78069640,
                    "question_id": 78069577,
                    "body_markdown": "As Python uses underlying operating system features, some of its behaviors will differ depending on what OS fuels your runtime environment. And while  your test is bit flawed because you use different Python versions, unifying these would most likely yield to similar results.\r\n\r\nWindows has historically had issues with time granularity, where the clock update frequency is not as high as on some Linux configurations. The precision of time measurements and the resolution of system time updates can significantly vary, leading to differences in how frequently `datetime.now()` returns a new value. The addition of `time.sleep(0.000001)` in your script likely forces the Python interpreter to yield execution long enough for the system clock to update, thus avoiding duplicates. This workaround is generally acceptable but should be used judiciously, understanding that it introduces a small overhead to each loop iteration which might be not really needed if such detailed time granularity is not really necessary.",
                    "title": "datetime.now() in Windows vs WSL vs Linux?"
                }
            ],
            "owner": {
                "account_id": 2742384,
                "reputation": 11,
                "user_id": 2363629,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/rCSxz.jpg?s=256&g=1",
                "display_name": "JakeJ",
                "link": "https://stackoverflow.com/users/2363629/jakej"
            },
            "is_answered": true,
            "view_count": 32,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709056288,
            "question_id": 78069577,
            "body_markdown": "I see a difference in the datetime.now() function in Windows Python 3.11 vs WSL Python 3.10 and Linux Python 3.10. On Windows, I get duplicate entries. On WSL and Linux, I don&#39;t.\r\n\r\nI am converting a test system from primarily being used with Python in WSL to using Python in Windows natively and hit a kind of weird issue. At one place the previous author was recording the datetime.now() at the outset of the script, then checking its delta later to see if it was still the same (I&#39;m legit not sure why, but this is what was going on). This suddenly broke with Python in Windows. After some digging, it seems that it&#39;s because there is literally no delta in the two datetime.now() calls most of the time. I tried it with WSL and it still worked. Here&#39;s an example of what I&#39;m talking about in germ:\r\n```\r\nfrom datetime import datetime as dt\r\nfor i in range(0,10):\r\n    print(f&quot;date and time is: {dt.now()}&quot;)\r\n```\r\n\r\nWith Windows, this is what it prints out:\r\n```\r\ndate and time is: 2024-02-26 17:09:39.393765\r\ndate and time is: 2024-02-26 17:09:39.393765\r\ndate and time is: 2024-02-26 17:09:39.408956\r\ndate and time is: 2024-02-26 17:09:39.408956\r\ndate and time is: 2024-02-26 17:09:39.408956\r\ndate and time is: 2024-02-26 17:09:39.409962\r\ndate and time is: 2024-02-26 17:09:39.409962\r\ndate and time is: 2024-02-26 17:09:39.409962\r\ndate and time is: 2024-02-26 17:09:39.409962\r\ndate and time is: 2024-02-26 17:09:39.410971\r\n```\r\n\r\nAs you can see, multiple entries are identical.\r\n\r\nSame system and code with WSL:\r\n```\r\ndate and time is: 2024-02-26 17:10:58.658753\r\ndate and time is: 2024-02-26 17:10:58.658802\r\ndate and time is: 2024-02-26 17:10:58.658828\r\ndate and time is: 2024-02-26 17:10:58.658837\r\ndate and time is: 2024-02-26 17:10:58.658857\r\ndate and time is: 2024-02-26 17:10:58.658880\r\ndate and time is: 2024-02-26 17:10:58.658888\r\ndate and time is: 2024-02-26 17:10:58.658892\r\ndate and time is: 2024-02-26 17:10:58.658911\r\ndate and time is: 2024-02-26 17:10:58.658935\r\n```\r\n\r\nNo duplicates.\r\n\r\nMy original assumption was that this was because of the overhead of WSL being a VM, but I&#39;m not really sure. I just found it odd and couldn&#39;t really find any help with it online as it seems like usually the reason people run into datetime.now() &quot;not updating&quot; is because they&#39;re assigning the output to a variable and not rerunning it, but I am running it again each time.\r\n\r\nI was curious, so I just ran it again on a Linux box I have set up (Ubuntu 22.04), and it never saw any duplicates either.\r\n```\r\ndate and time is: 2024-02-27 09:38:16.767813\r\ndate and time is: 2024-02-27 09:38:16.767853\r\ndate and time is: 2024-02-27 09:38:16.767860\r\ndate and time is: 2024-02-27 09:38:16.767864\r\ndate and time is: 2024-02-27 09:38:16.767869\r\ndate and time is: 2024-02-27 09:38:16.767873\r\ndate and time is: 2024-02-27 09:38:16.767878\r\ndate and time is: 2024-02-27 09:38:16.767882\r\ndate and time is: 2024-02-27 09:38:16.767889\r\ndate and time is: 2024-02-27 09:38:16.767894\r\n```\r\nI checked the Python versions in each and do see a difference:\r\nWindows: Python 3.11.8\r\nWSL: Python 3.10.12\r\nUbuntu: Python 3.10.12\r\n\r\nThe CPU&#39;s are different, too, if that matters in this case: \r\n\r\nWindows:\r\ni7-8700 CPU @ 3.20GHz, 3192 Mhz, 6 Core(s), 12 Logical Processor(s)\r\n\r\nLinux:\r\nlscpu\r\nArchitecture:            x86_64\r\n  CPU op-mode(s):        32-bit, 64-bit\r\n  Address sizes:         39 bits physical, 48 bits virtual\r\n  Byte Order:            Little Endian\r\nCPU(s):                  8\r\n  On-line CPU(s) list:   0-7\r\nVendor ID:               GenuineIntel\r\n  Model name:            Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz\r\n    CPU family:          6\r\n    Model:               94\r\n    Thread(s) per core:  2\r\n    Core(s) per socket:  4\r\n    Socket(s):           1\r\n    Stepping:            3\r\n    CPU max MHz:         3400.0000\r\n    CPU min MHz:         800.0000\r\n\r\nIt&#39;s easy to get the code I was working with to work with Windows&#39; Python by adding a time.sleep(0.000001), and I&#39;m not sure if the offending code is even needed, but I&#39;m just curious why this is happening and wondered if anyone could shed any light on it.\r\n\r\nThanks!",
            "link": "https://stackoverflow.com/questions/78069577/datetime-now-in-windows-vs-wsl-vs-linux",
            "title": "datetime.now() in Windows vs WSL vs Linux?"
        },
        {
            "tags": [
                "python",
                "function",
                "loops"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 20780824,
                        "reputation": 30990,
                        "user_id": 15261315,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/a9cb18689f8216a39642728ffebd47be?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Chris",
                        "link": "https://stackoverflow.com/users/15261315/chris"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709056563,
                    "answer_id": 78069602,
                    "question_id": 78069497,
                    "body_markdown": "If you insist on using recursion, you need to accumulate points somewhere. A local variable&#39;s value is unique to the function call currently happening. Global variables could work, but _don&#39;t go down that road_.\r\n\r\nSo the answer is to use a function argument to convey that information from one function call to the next.\r\n\r\n```\r\ndef questionmaker(PlayerPoints=0):\r\n    LocalWDC = ((WDCs[randrange(73)]))\r\n    print(f&quot;Who won the World Championship in {LocalWDC[0]}? &quot;)\r\n    PlayerResponse = input(str())\r\n    if PlayerResponse == LocalWDC[1]:\r\n        PlayerPoints += 5\r\n        print(&quot;That&#39;s Correct!&quot;)\r\n        print(f&quot;Your score is {PlayerPoints}!&quot;)\r\n        return questionmaker(PlayerPoints)\r\n    else:\r\n        print(f&quot;Wrong! The Champion that year was {LocalWDC[1]}.&quot;)\r\n        print(f&quot;Your Final Score is {PlayerPoints}!&quot;)\r\n```\r\n\r\nBetter would be to use an explicit loop rather than recursion.",
                    "title": "Adding to a Variable in a Loop. Variable keeps resetting to 0"
                },
                {
                    "owner": {
                        "account_id": 23535348,
                        "reputation": 22467,
                        "user_id": 17580381,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/0h7Fj.jpg?s=256&g=1",
                        "display_name": "CtrlZ",
                        "link": "https://stackoverflow.com/users/17580381/ctrlz"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709056724,
                    "answer_id": 78069624,
                    "question_id": 78069497,
                    "body_markdown": "You need a loop. Recursion is not appropriate.\r\n\r\nYou can also simplify the (pseudo)random selection of the question by utilising the *choice()* function from the *random* module.\r\n\r\nA simple technique for breaking the loop would be to test for empty input - i.e., player just hits Return and the *input()* function will then return an empty string.\r\n\r\n    from random import choice\r\n    \r\n    WDCs = ((2023, &quot;Max Verstappen&quot;), \r\n            (2022, &quot;Max Verstappen&quot;),\r\n            (2021, &quot;Max Verstappen&quot;),\r\n            (2020, &quot;Lewis Hamilton&quot;),\r\n            (2019, &quot;Lewis Hamilton&quot;),\r\n            (2018, &quot;Lewis Hamilton&quot;),\r\n            (2017, &quot;Lewis Hamilton&quot;),\r\n            (2016, &quot;Nico Rosberg&quot;),\r\n            (2015, &quot;Lewis Hamilton&quot;),\r\n            (2014, &quot;Lewis Hamilton&quot;),\r\n            (2013, &quot;Sebastian Vettel&quot;),\r\n            (2012, &quot;Sebastian Vettel&quot;),\r\n            (2011, &quot;Sebastian Vettel&quot;),\r\n            (2010, &quot;Sebastian Vettel&quot;),\r\n            (2009, &quot;Jenson Button&quot;),\r\n            (2008, &quot;Lewis Hamilton&quot;),\r\n            (2007, &quot;Kimi Raikkonen&quot;),\r\n            (2006, &quot;Fernando Alonso&quot;),\r\n            (2005, &quot;Fernando Alonso&quot;),\r\n            (2004, &quot;Michael Schumacher&quot;),\r\n            (2003, &quot;Michael Schumacher&quot;),\r\n            (2002, &quot;Michael Schimacher&quot;),\r\n            (2001, &quot;Michael Schumacher&quot;),\r\n            (2000, &quot;Michael Schumacher&quot;),\r\n            (1999, &quot;Mike Hakkinen&quot;),\r\n            (1998, &quot;Mika Hakkinen&quot;),\r\n            (1997, &quot;Jaques Villeneuve&quot;),\r\n            (1996, &quot;Damon Hill&quot;),\r\n            (1995, &quot;Michael Schumacher&quot;),\r\n            (1994, &quot;Michael Schumacher&quot;),\r\n            (1993, &quot;Alain Prost&quot;),\r\n            (1992, &quot;Nigel Mansell&quot;),\r\n            (1991, &quot;Ayrton Senna&quot;),\r\n            (1990, &quot;Ayrton Senna&quot;),\r\n            (1989, &quot;Alain Prost&quot;),\r\n            (1988, &quot;Ayrton Senna&quot;),\r\n            (1987, &quot;Nelson Piquet&quot;),\r\n            (1986, &quot;Alain Prost&quot;),\r\n            (1986, &quot;Alain Prost&quot;),\r\n            (1985, &quot;Alain Prost&quot;),\r\n            (1984, &quot;Niki Lauda&quot;),\r\n            (1983, &quot;Nelson Piquet&quot;),\r\n            (1982, &quot;Keke Rosberg&quot;),\r\n            (1981, &quot;Nelson Piquet&quot;),\r\n            (1980, &quot;Alan Jones&quot;),\r\n            (1979, &quot;Jody Scheckter&quot;),\r\n            (1978, &quot;Mario Andretti&quot;),\r\n            (1977, &quot;Niki Lauda&quot;),\r\n            (1976, &quot;James Hunt&quot;),\r\n            (1975, &quot;Niki Lauda&quot;),\r\n            (1974, &quot;Emerson Fittipaldi&quot;),\r\n            (1973, &quot;Jackie Stewart&quot;),\r\n            (1972, &quot;Emerson Fittipaldi&quot;),\r\n            (1971, &quot;Jackie Stewart&quot;),\r\n            (1970, &quot;Jochen Rindt&quot;),\r\n            (1969, &quot;Jackie Stewart&quot;),\r\n            (1968, &quot;Graham Hill&quot;),\r\n            (1967, &quot;Denny Hulme&quot;),\r\n            (1966, &quot;Jack Brabham&quot;),\r\n            (1965, &quot;Jim Clark&quot;),\r\n            (1964, &quot;John Surtees&quot;),\r\n            (1963, &quot;Jim Clark&quot;),\r\n            (1962, &quot;Graham Hill&quot;),\r\n            (1961, &quot;Phil Hill&quot;),\r\n            (1960, &quot;Jack Brabham&quot;),\r\n            (1959, &quot;Jack Brabham&quot;),\r\n            (1958, &quot;Jack Hawthorn&quot;),\r\n            (1957, &quot;Juan Manuel Fangio&quot;),\r\n            (1956, &quot;Juan Manuel Fangio&quot;),\r\n            (1955, &quot;Juan Manuel Fangio&quot;),\r\n            (1954, &quot;Juan Manuel Fangio&quot;),\r\n            (1953, &quot;Alberto Ascari&quot;),\r\n            (1952, &quot;ALberto Ascari&quot;),\r\n            (1951, &quot;Juan Manuel Fangio&quot;),\r\n            (1950, &quot;Giusepe Farina&quot;)\r\n            )\r\n    \r\n    def questionmaker():\r\n        score = 0\r\n        while True:\r\n            year, driver = choice(WDCs)\r\n            answer = input(f&quot;Who won the world championship in {year}? &quot;)\r\n            if answer:\r\n                if answer == driver:\r\n                    print(&quot;That&#39;s correct&quot;)\r\n                    score += 5\r\n                else:\r\n                    print(f&quot;Wrong! The champion that year was {driver}&quot;)\r\n                print(f&quot;Your current score is {score}&quot;)\r\n            else:\r\n                break # empty input breaks the loop\r\n        print(f&quot;Your final score is {score}&quot;)\r\n    \r\n    if __name__ == &quot;__main__&quot;:\r\n        questionmaker()\r\n\r\n**Note:**\r\n\r\nA better (and more concise) way of managing the drivers and their winning years would be to use a dictionary keyed on driver name with each driver&#39;s value being a sequence of years (list or tuple). You would then need to make 2 random selections. Driver first then a year from his value. That also solves the problem of typos (as you have in your code) for the driver names although you could consider normalising to upper/lower case",
                    "title": "Adding to a Variable in a Loop. Variable keeps resetting to 0"
                }
            ],
            "owner": {
                "account_id": 29324182,
                "reputation": 11,
                "user_id": 22467098,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/BZK7O.png?s=256&g=1",
                "display_name": "Dan",
                "link": "https://stackoverflow.com/users/22467098/dan"
            },
            "is_answered": true,
            "view_count": 57,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 0,
            "creation_date": 1709055541,
            "question_id": 78069497,
            "body_markdown": "I&#39;m working on a small trivia game that adds 5 points for every question you get right. I have a function that has a loop where it asks you a question. If the answer is right then it adds 5 points and prints your score along with a message and then loops back to ask you a question. Otherwise it prints the correct answer and gives you a final score.\r\n\r\nMy problem is that the way I am making my loop the value of PlayerPoints is getting set to 0  every time the loop restarts. So while the points are being added the PlayerPoints value is being equaled to 0 every iteration.\r\n\r\nHere is my code:\r\n\r\n```\r\nfrom random import randrange\r\nWDCs = ((2023, &quot;Max Verstappen&quot;), (2022, &quot;Max Verstappen&quot;),\r\n        (2021, &quot;Max Verstappen&quot;), (2020, &quot;Lewis Hamilton&quot;),\r\n        (2019, &quot;Lewis Hamilton&quot;), (2018, &quot;Lewis Hamilton&quot;),\r\n        (2017, &quot;Lewis Hamilton&quot;), (2016, &quot;Nico Rosberg&quot;),\r\n        (2015, &quot;Lewis Hamilton&quot;), (2014, &quot;Lewis Hamilton&quot;),\r\n        (2013, &quot;Sebastian Vettel&quot;), (2012, &quot;Sebastian Vettel&quot;),\r\n        (2011, &quot;Sebastian Vettel&quot;), (2010, &quot;Sebastian Vettel&quot;),\r\n        (2009, &quot;Jenson Button&quot;), (2008, &quot;Lewis Hamilton&quot;),\r\n        (2007, &quot;Kimi Raikkonen&quot;), (2006, &quot;Fernando Alonso&quot;),\r\n        (2005, &quot;Fernando Alonso&quot;), (2004, &quot;Michael Schumacher&quot;),\r\n        (2003, &quot;Michael Schumacher&quot;), (2002, &quot;Michael Schimacher&quot;),\r\n        (2001, &quot;Michael Schumacher&quot;), (2000, &quot;Michael Schumacher&quot;),\r\n        (1999, &quot;Mike Hakkinen&quot;), (1998, &quot;Mika Hakkinen&quot;),\r\n        (1997, &quot;Jaques Villeneuve&quot;), (1996, &quot;Damon Hill&quot;),\r\n        (1995, &quot;Michael Schumacher&quot;), (1994, &quot;Michael Schumacher&quot;),\r\n        (1993, &quot;Alain Prost&quot;), (1992, &quot;Nigel Mansell&quot;),\r\n        (1991, &quot;Ayrton Senna&quot;), (1990, &quot;Ayrton Senna&quot;),\r\n        (1989, &quot;Alain Prost&quot;), (1988, &quot;Ayrton Senna&quot;),\r\n        (1987, &quot;Nelson Piquet&quot;), (1986, &quot;Alain Prost&quot;),\r\n        (1986, &quot;Alain Prost&quot;), (1985, &quot;Alain Prost&quot;),\r\n        (1984, &quot;Niki Lauda&quot;), (1983, &quot;Nelson Piquet&quot;),\r\n        (1982, &quot;Keke Rosberg&quot;), (1981, &quot;Nelson Piquet&quot;),\r\n        (1980, &quot;Alan Jones&quot;), (1979, &quot;Jody Scheckter&quot;),\r\n        (1978, &quot;Mario Andretti&quot;), (1977, &quot;Niki Lauda&quot;),\r\n        (1976, &quot;James Hunt&quot;), (1975, &quot;Niki Lauda&quot;),\r\n        (1974, &quot;Emerson Fittipaldi&quot;), (1973, &quot;Jackie Stewart&quot;),\r\n        (1972, &quot;Emerson Fittipaldi&quot;), (1971, &quot;Jackie Stewart&quot;),\r\n        (1970, &quot;Jochen Rindt&quot;), (1969, &quot;Jackie Stewart&quot;),\r\n        (1968, &quot;Graham Hill&quot;), (1967, &quot;Denny Hulme&quot;),\r\n        (1966, &quot;Jack Brabham&quot;), (1965, &quot;Jim Clark&quot;),\r\n        (1964, &quot;John Surtees&quot;), (1963, &quot;Jim Clark&quot;),\r\n        (1962, &quot;Graham Hill&quot;), (1961, &quot;Phil hill&quot;),\r\n        (1960, &quot;Jack Brabham&quot;), (1959, &quot;Jack Brabham&quot;),\r\n        (1958, &quot;Jack Hawthorn&quot;), (1957, &quot;Juan Manuel Fangio&quot;),\r\n        (1956, &quot;Juan Manuel Fangio&quot;), (1955, &quot;Juan Manuel Fangio&quot;),\r\n        (1954, &quot;Juan Manuel Fangio&quot;), (1953, &quot;Alberto Ascari&quot;),\r\n        (1952, &quot;ALberto Ascari&quot;), (1951, &quot;Juan Manuel Fangio&quot;),\r\n        (1950, &quot;Giusepe Farina&quot;)\r\n        )\r\n\r\ndef questionmaker():\r\n    PlayerPoints = 0\r\n    LocalWDC = ((WDCs[randrange(73)]))\r\n    print(f&quot;Who won the World Championship in {LocalWDC[0]}? &quot;)\r\n    PlayerResponse = input(str())\r\n    if PlayerResponse == LocalWDC[1]:\r\n        PlayerPoints = PlayerPoints + 5\r\n        print(&quot;That&#39;s Correct!&quot;)\r\n        print(f&quot;Your score is {PlayerPoints}!&quot;)\r\n        return questionmaker()\r\n    else:\r\n        print(f&quot;Wrong! The Champion that year was {LocalWDC[1]}.&quot;)\r\n        print(f&quot;Your Final Score is {PlayerPoints}!&quot;)\r\n\r\nquestionmaker()\r\n```\r\n\r\n\r\nIt&#39;s probably something very simple but I&#39;m stumped and can&#39;t figure out how to do it properly. I&#39;ve tried doing a nested function and using a while loop to no results.\r\n\r\nI know python doesn&#39;t support the goto function so I am unsure what to do.",
            "link": "https://stackoverflow.com/questions/78069497/adding-to-a-variable-in-a-loop-variable-keeps-resetting-to-0",
            "title": "Adding to a Variable in a Loop. Variable keeps resetting to 0"
        },
        {
            "tags": [
                "python",
                "sql",
                "mysql",
                "flask",
                "flask-mysql"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30635679,
                        "reputation": 1,
                        "user_id": 23485167,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocLMcq19z8j7ieqzX3Go-0_7EVZu5aLEkvuEVVqycuJB3yU=k-s256",
                        "display_name": "Ayush",
                        "link": "https://stackoverflow.com/users/23485167/ayush"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709055944,
                    "answer_id": 78069536,
                    "question_id": 78069356,
                    "body_markdown": "The issue you&#39;re encountering seems to be related to how the MySQL Connector in Flask interprets the data returned from the database. The bytes-like object (b&#39;alex@email.com&#39;) suggests that the data is being returned as bytes instead of strings. To resolve this, you can explicitly decode the bytes into strings when fetching the results. Here&#39;s how you can modify your code to handle this:\r\n\r\n    cur = mysql.connection.cursor()\r\n    print(&#39;Connected to MySQL&#39;)\r\n    cur.execute(&quot;SELECT id, email FROM users;&quot;)\r\n    rv = cur.fetchall()\r\n    \r\n    # Decode bytes-like objects to strings\r\n    rv = [(id, email.decode(&#39;utf-8&#39;)) for id, email in rv]\r\n    \r\n    cur.close()\r\n\r\nIn the modified code snippet above, I assume that the encoding used by your database is UTF-8. If it&#39;s different, you should use the appropriate encoding.\r\n\r\nThis modification ensures that the email values are retrieved and handled as strings rather than bytes-like objects, resolving the ValueError you encountered.",
                    "title": "Issue with SELECT query in MySQL Connector: Attempted conversion to float for multiple arguments beyond the first"
                }
            ],
            "owner": {
                "account_id": 26447659,
                "reputation": 1,
                "user_id": 20091300,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/d3ef3b29a83abc8cd5b9a4327627d3f5?s=256&d=identicon&r=PG",
                "display_name": "markseco",
                "link": "https://stackoverflow.com/users/20091300/markseco"
            },
            "is_answered": false,
            "view_count": 15,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709054168,
            "question_id": 78069356,
            "body_markdown": "I&#39;m facing an issue when executing a SELECT query in Python (Flask) using the MySQL Connector (From the flask_mysqldb). Specifically, when I include more than one argument in the SELECT statement, starting from the second argument, it attempts to convert the values to float. When I do the same SELECT from the MySQL CLI It works fine.\r\n\r\nHere is the table schema:\r\n\r\n```\r\nCREATE TABLE users (\r\n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\r\n    email VARCHAR(255) NOT NULL UNIQUE,\r\n    hashed_password VARCHAR(255) NOT NULL\r\n);\r\n\r\n```\r\nAnd here is the code snippet:\r\n\r\n```\r\ncur = mysql.connection.cursor()\r\nprint(&#39;Connected to MySQL&#39;)\r\ncur.execute(&quot;SELECT id, email FROM users;&quot;)  # This is where the issue occurs\r\nrv = cur.fetchall()\r\ncur.close()\r\n\r\n```\r\nThe error message I&#39;m encountering on the localhost page is:\r\n\r\nValueError: could not convert string to float: b&#39;alex@email.com&#39;\r\n\r\nIt seems that the values retrieved from the email column are being represented as byte strings (b&#39;...&#39;), causing the conversion error.\r\n\r\nHow can I resolve this issue and ensure that the SELECT query correctly retrieves and handles string values from the MySQL database?\r\n\r\n\r\nI&#39;ve tried testing the queries through the MySQL CLI and they work but they don&#39;t work here if theres more than one statement and the second one is not a number.",
            "link": "https://stackoverflow.com/questions/78069356/issue-with-select-query-in-mysql-connector-attempted-conversion-to-float-for-mu",
            "title": "Issue with SELECT query in MySQL Connector: Attempted conversion to float for multiple arguments beyond the first"
        },
        {
            "tags": [
                "python",
                "numpy"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 485561,
                        "reputation": 225743,
                        "user_id": 901925,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/8bbd70aaeb3a97d0087daf93c2be8804?s=256&d=identicon&r=PG",
                        "display_name": "hpaulj",
                        "link": "https://stackoverflow.com/users/901925/hpaulj"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709059513,
                    "answer_id": 78069876,
                    "question_id": 78069343,
                    "body_markdown": "    In [172]: a = np.ones((3,4),int)\r\n    \r\nSimple &#39;scalar&#39; insert - put `2` in all rows of a new column before `a[:,1]`:\r\n\r\n    In [175]: np.insert(a,1,2,axis=1)\r\n    Out[175]: \r\n    array([[1, 2, 1, 1, 1],\r\n           [1, 2, 1, 1, 1],\r\n           [1, 2, 1, 1, 1]])\r\n\r\nInsert 3 numbers in that column:\r\n    \r\n    In [176]: np.insert(a,1,[2,3,4],axis=1)\r\n    Out[176]: \r\n    array([[1, 2, 1, 1, 1],\r\n           [1, 3, 1, 1, 1],\r\n           [1, 4, 1, 1, 1]])\r\n    \r\nBut if there&#39;s a mismatch between rows and insert values:\r\n\r\n    In [177]: np.insert(a,1,[2,4],axis=1)\r\n    ---------------------------------------------------------------------------\r\n    ValueError                                Traceback (most recent call last)\r\n    Cell In[177], line 1\r\n    ----&gt; 1 np.insert(a,1,[2,4],axis=1)\r\n    \r\n    File &lt;__array_function__ internals&gt;:200, in insert(*args, **kwargs)\r\n    \r\n    File ~\\miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:5406, in insert(arr, obj, values, axis)\r\n       5404 new[tuple(slobj)] = arr[tuple(slobj)]\r\n       5405 slobj[axis] = slice(index, index+numnew)\r\n    -&gt; 5406 new[tuple(slobj)] = values\r\n       5407 slobj[axis] = slice(index+numnew, None)\r\n       5408 slobj2 = [slice(None)] * ndim\r\n    \r\n    ValueError: could not broadcast input array from shape (2,1) into shape (3,1)\r\n\r\nNote that this is a `broadcast` error.  It&#39;s taking the values as a (2,1) array, and trying to put it in a column that is (3,1).  When there are 3 values, it works: (3,1) into (3,1).\r\n    \r\nOn other hand if we specify a list insert location, it puts both values in:\r\n\r\n    In [178]: np.insert(a,[1],[2,4],axis=1)\r\n    Out[178]: \r\n    array([[1, 2, 4, 1, 1, 1],\r\n           [1, 2, 4, 1, 1, 1],\r\n           [1, 2, 4, 1, 1, 1]])\r\n\r\nOr with 2 columns:\r\n    \r\n    In [179]: np.insert(a,[1,0],[2,4],axis=1)\r\n    Out[179]: \r\n    array([[4, 1, 2, 1, 1, 1],\r\n           [4, 1, 2, 1, 1, 1],\r\n           [4, 1, 2, 1, 1, 1]])\r\n\r\nBut 2 columns, and 3 values don&#39;t `broadcast`:\r\n    \r\n    In [180]: np.insert(a,[1,0],[2,4,3],axis=1)\r\n    ---------------------------------------------------------------------------\r\n    ValueError                                Traceback (most recent call last)\r\n    Cell In[180], line 1\r\n    ----&gt; 1 np.insert(a,[1,0],[2,4,3],axis=1)\r\n    \r\n    File &lt;__array_function__ internals&gt;:200, in insert(*args, **kwargs)\r\n    \r\n    File ~\\miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:5432, in insert(arr, obj, values, axis)\r\n       5430 slobj[axis] = indices\r\n       5431 slobj2[axis] = old_mask\r\n    -&gt; 5432 new[tuple(slobj)] = values\r\n       5433 new[tuple(slobj2)] = arr\r\n       5435 if wrap:\r\n    \r\n    ValueError: shape mismatch: value array of shape (3,) could not be broadcast to indexing result of shape (3,2)\r\n    \r\nWe/I could examine the code to see how it constructs the `slobj` index array, and how it tweaks the `values` list/array.\r\n\r\n\r\nIn two of the above cases, we can &#39;recover&#39; the `values` with the matching scalar/list indexing:\r\n\r\n    In [187]: np.insert(a,1,[2,3,4],axis=1)[:,1]\r\n    Out[187]: array([2, 3, 4])\r\n    \r\n    In [188]: np.insert(a,[1,0],[2,4],axis=1)[:,[2,0]]\r\n    Out[188]: \r\n    array([[2, 4],\r\n           [2, 4],\r\n           [2, 4]])\r\n\r\nThe docs makes a note of this common pattern\r\n\r\n    Note that for higher dimensional \r\n    inserts obj=0 behaves very \r\n    different from obj=[0] just like \r\n    arr[:,0,:] = values is different \r\n    from arr[:,[0],:] = values\r\n\r\n\r\n\r\nedit\r\n---\r\n\r\nCuriously when I try to insert 2 columns with the scalar or list, I have to specify different `values` shapes:\r\n\r\n    In [193]: np.insert(a, 1, np.zeros((2,3),int), axis=1)\r\n    Out[193]: \r\n    array([[1, 0, 0, 1, 1, 1],\r\n           [1, 0, 0, 1, 1, 1],\r\n           [1, 0, 0, 1, 1, 1]])\r\n    \r\n    In [194]: np.insert(a, [1], np.zeros((3,2),int), axis=1)\r\n    Out[194]: \r\n    array([[1, 0, 0, 1, 1, 1],\r\n           [1, 0, 0, 1, 1, 1],\r\n           [1, 0, 0, 1, 1, 1]])\r\n\r\nUltimately, the answer to `why` questions is - because the developer(s) chose to do it that way.  We (non-developers) can only look for patterns and/or consistency, we can&#39;t give a definitive answer.\r\n",
                    "title": "Why is numpy np.insert method behaves differently when the obj parameter is an integer or a sequence?"
                }
            ],
            "owner": {
                "account_id": 21653874,
                "reputation": 11,
                "user_id": 15974033,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a-/AOh14GgSWP7fkIEamAShuY52pPmhSaFXnpt-pQGrCGbY=k-s256",
                "display_name": "Paritosh Sharma Ghimire",
                "link": "https://stackoverflow.com/users/15974033/paritosh-sharma-ghimire"
            },
            "is_answered": false,
            "view_count": 59,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709054038,
            "question_id": 78069343,
            "body_markdown": "The np.insert function is used to insert values along a specified axis in an array.\r\n\r\nI am trying to understand why the outputs are different when I use a sequence instead of integer for the obj parameter.\r\n\r\n   \r\n\r\n       arr_a = np.random.randint(1,10, size=(3,3), dtype=np.int64)\r\n       arr_a\r\n       &gt;&gt;&gt; array([[2, 3, 8],\r\n                 [6, 7, 2],\r\n                 [1, 9, 4]])\r\n       \r\n       arr = np.insert(arr_a, [1], [[5],[5],[5]], axis=1)\r\n       arr\r\n       &gt;&gt;&gt;array([[2, 5, 3, 8],\r\n                 [6, 5, 7, 2],\r\n                 [1, 5, 9, 4]])\r\n\r\n       arr_b = np.insert(arr_a, 0, [[5],[6],[7]], axis=1)\r\n       arr_b\r\n       &gt;&gt;&gt;array([[5, 6, 7, 2, 3, 8],\r\n                [5, 6, 7, 6, 7, 2],\r\n                [5, 6, 7, 1, 9, 4]])\r\n\r\nI understand that,\r\n\r\nUsing a list allows you to specify multiple indices at which values will be inserted.\r\nUsing a single value allows you to specify a single index at which values will be inserted.",
            "link": "https://stackoverflow.com/questions/78069343/why-is-numpy-np-insert-method-behaves-differently-when-the-obj-parameter-is-an-i",
            "title": "Why is numpy np.insert method behaves differently when the obj parameter is an integer or a sequence?"
        },
        {
            "tags": [
                "python",
                "asynchronous",
                "python-asyncio"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 8260894,
                        "reputation": 2799,
                        "user_id": 6212350,
                        "user_type": "registered",
                        "accept_rate": 70,
                        "profile_image": "https://i.stack.imgur.com/qXnGn.jpg?s=256&g=1",
                        "display_name": "TheHungryCub",
                        "link": "https://stackoverflow.com/users/6212350/thehungrycub"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709054212,
                    "answer_id": 78069361,
                    "question_id": 78069302,
                    "body_markdown": "The issue is that when you use `asyncio.create_task`, it returns a single future object representing the task. If you want to unpack multiple values from the result of `Functions.getData`, you should do it after awaiting the task.\r\n\r\n    import asyncio\r\n    \r\n    async def get_data(session, id):\r\n        # Simulating some asynchronous operation\r\n        await asyncio.sleep(1)\r\n        return &quot;result1&quot;, &quot;result2&quot;\r\n\r\n    async def get_tasks(session, id):\r\n        task = asyncio.create_task(get_data(session, id))\r\n        result = await task  # Wait for the task to complete\r\n        var1, var2 = result\r\n        return var1, var2\r\n\r\n    async def main():\r\n        session = None  # Replace with your session\r\n        id = 123  # Replace with your id\r\n        var1, var2 = await get_tasks(session, id)\r\n        print(var1, var2)\r\n\r\n    asyncio.run(main())\r\n\r\nThis way, you await the task and then unpack the results",
                    "title": "Set Async Create Task to two Variables"
                }
            ],
            "owner": {
                "account_id": 16910019,
                "reputation": 29,
                "user_id": 12229305,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/68c7bd7b960b807c478d91b5c5e84754?s=256&d=identicon&r=PG",
                "display_name": "Nathan Allan",
                "link": "https://stackoverflow.com/users/12229305/nathan-allan"
            },
            "is_answered": true,
            "view_count": 24,
            "favorite_count": 0,
            "accepted_answer_id": 78069361,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709053685,
            "question_id": 78069302,
            "body_markdown": "I&#39;m repurposing some synchronous python code to be asynchronous. It is working really well, but when I change this line of code\r\n\r\n        l = asyncio.create_task(Functions.getData(session, id))\r\n\r\nto this\r\n\r\n        l, i = asyncio.create_task(Functions.getData(session, id))\r\n\r\nI get a RuntimeError that says this.\r\n\r\n    &quot;Exception has occurred: RuntimeError\r\n    await wasn&#39;t used with future\r\n      File &#39;test.py&#39;, line 46, in get_tasks\r\n        l, i = asyncio.create_task(Functions.getData(session, id))\r\n        ^^^^\r\n      File &#39;test.py&#39;, line 79, in get_data\r\n        a, b, c = get_tasks(session)\r\n                                   ^^^^^^^^^^^^^^^^^^\r\n      File &#39;test.py&#39;, line 108, in &lt;module&gt;\r\n        asyncio.run(get_data())\r\n    RuntimeError: await wasn&#39;t used with future&quot;\r\n\r\nMy getData function returns a tuple (var1, var2), but for some reason asyncio does not like it.",
            "link": "https://stackoverflow.com/questions/78069302/set-async-create-task-to-two-variables",
            "title": "Set Async Create Task to two Variables"
        },
        {
            "tags": [
                "python",
                "parsing",
                "beautifulsoup",
                "rss"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 13900216,
                        "reputation": 184517,
                        "user_id": 10035985,
                        "user_type": "registered",
                        "profile_image": "https://lh4.googleusercontent.com/-1WgJ_2yA-78/AAAAAAAAAAI/AAAAAAAAAOA/0CBOlYqYe7M/photo.jpg?sz=256",
                        "display_name": "Andrej Kesely",
                        "link": "https://stackoverflow.com/users/10035985/andrej-kesely"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709062568,
                    "answer_id": 78070133,
                    "question_id": 78069239,
                    "body_markdown": "Some `&lt;item&gt;` don&#39;t have `&lt;description&gt;` tag so you need to handle that:\r\n\r\n```py\r\nimport requests\r\nfrom bs4 import BeautifulSoup\r\n\r\n\r\ndef get_data(url):\r\n    resp = requests.get(url)\r\n    soup = BeautifulSoup(resp.content, features=&quot;xml&quot;)\r\n    soup.prettify()\r\n    items = soup.findAll(&quot;item&quot;)\r\n\r\n    news_items = []\r\n    for item in items:\r\n        news_item = {}\r\n        news_item[&quot;title&quot;] = item.title.text\r\n        news_item[&quot;link&quot;] = item.link.text\r\n        news_item[&quot;pubDate&quot;] = item.pubDate.text\r\n        news_items.append(news_item)\r\n\r\n        if item.description:\r\n            description_content = BeautifulSoup(item.description.text, &quot;html.parser&quot;)\r\n\r\n            # Remove the img tag\r\n            img_tag = description_content.find(&quot;img&quot;)\r\n            if img_tag:\r\n                img_tag.decompose()\r\n\r\n            description_content = str(description_content)\r\n        else:\r\n            description_content = &quot;&quot;\r\n\r\n        # Assuming you want to keep the rest of the content as HTML\r\n        news_item[&quot;description&quot;] = description_content\r\n\r\n    return news_items\r\n\r\n\r\nprint(get_data(&quot;https://rss.app/feeds/6BJraU9Ff0IeqC3c.xml&quot;))\r\n```",
                    "title": "Getting none when trying to parse description tag of rss feed"
                }
            ],
            "owner": {
                "account_id": 23676845,
                "reputation": 23,
                "user_id": 17702984,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/7315e21c31c469f82f6a7e856ebe1de1?s=256&d=identicon&r=PG",
                "display_name": "NoIdea",
                "link": "https://stackoverflow.com/users/17702984/noidea"
            },
            "is_answered": false,
            "view_count": 10,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709053078,
            "question_id": 78069239,
            "body_markdown": "so i&#39;m acessing this rss feed \r\n[![enter image description here](https://i.stack.imgur.com/LQY7S.png)](https://i.stack.imgur.com/LQY7S.png)\r\nas you can see there is a description tag. when i&#39;m parsing the feed it returns back none for the description tag\r\n\r\n\r\nand this is the error message i get \r\n\r\n```\r\n\r\n\r\n\r\nAttributeError: &#39;NoneType&#39; object has no attribute &#39;text&#39;\r\nTraceback:\r\nFile &quot;C:\\Users\\User\\Desktop\\news-recommendation\\env\\lib\\site-packages\\streamlit\\runtime\\scriptrunner\\script_runner.py&quot;, line 535, in _run_script\r\n    exec(code, module.__dict__)\r\nFile &quot;C:\\Users\\User\\Desktop\\news-recommendation\\app.py&quot;, line 66, in &lt;module&gt;\r\n    data=parseRSS(&#39;https://rss.app/feeds/6BJraU9Ff0IeqC3c.xml&#39;)\r\nFile &quot;C:\\Users\\User\\Desktop\\news-recommendation\\parseRSS.py&quot;, line 23, in parseRSS\r\n    description_content = BeautifulSoup(item.description.text, &quot;html.parser&quot;\r\n\r\n```\r\n\r\n\r\nthis is the code i&#39;m using \r\n\r\n\r\n```\r\n    resp=requests.get(url)\r\n    soup = BeautifulSoup(resp.content, features=&quot;xml&quot;)\r\n    soup.prettify()\r\n    items = soup.findAll(&#39;item&#39;)\r\n\r\n    news_items = []\r\n    for item in items:\r\n        news_item={}\r\n        news_item[&#39;title&#39;]=item.title.text\r\n        news_item[&#39;link&#39;]=item.link.text\r\n        news_item[&#39;pubDate&#39;]=item.pubDate.text\r\n        news_items.append(news_item)\r\n     \r\n        description_content = BeautifulSoup(item.description.text, &quot;html.parser&quot;)\r\n        # Remove the img tag\r\n        img_tag = description_content.find(&#39;img&#39;)\r\n        if img_tag:\r\n         img_tag.decompose()\r\n    \r\n         # Assuming you want to keep the rest of the content as HTML\r\n        news_item[&#39;description&#39;] = str(description_content)\r\n```\r\n\r\n",
            "link": "https://stackoverflow.com/questions/78069239/getting-none-when-trying-to-parse-description-tag-of-rss-feed",
            "title": "Getting none when trying to parse description tag of rss feed"
        },
        {
            "tags": [
                "python",
                "algorithm",
                "sorting",
                "merge"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 1642419,
                        "reputation": 46673,
                        "user_id": 5349916,
                        "user_type": "registered",
                        "accept_rate": 25,
                        "profile_image": "https://i.stack.imgur.com/QovYv.jpg?s=256&g=1",
                        "display_name": "MisterMiyagi",
                        "link": "https://stackoverflow.com/users/5349916/mistermiyagi"
                    },
                    "is_accepted": false,
                    "score": 3,
                    "creation_date": 1709053916,
                    "answer_id": 78069332,
                    "question_id": 78069220,
                    "body_markdown": "This is a convoluted way of writing bubblesort.\r\n\r\n`merge(it, it)` means sorting all pairs as `it[0]` against `it[1]`, then the pair of the larger of that against `it[2]` and so on.\r\n - The &quot;`it[0]` against `it[1]` against `it[2]` \u2026&quot; part comes from double-iterating the same iterator, which forces each step to fetch the next element regardless of which &quot;end&quot; is iterated.\r\n - The pairwise sort comes directly from what `merge` does, which looks at the head of each iterator and emits the smaller one while keeping the larger one for the next step. \r\n\r\n`any(x &gt; y for x, y in pairwise(a))` tests for sorted&#39;ness, i.e. if the next iteration would perform any swaps to ensure pairwise sorting.\r\n\r\n[This is practically a textbook definition of bubblesort:][1]\r\n\r\n&gt; Bubble sort, sometimes referred to as sinking sort, is a simple sorting algorithm that **repeatedly steps through the input list element by element, comparing the current element with the one after it, swapping their values if needed. These passes through the list are repeated until no swaps have to be performed during a pass**, meaning that the list has become fully sorted.\r\n\r\nNote that the &quot;current element&quot; in bubblesort is next position but the  larger element of the previous pair. This is because the swap is performed before the next pairwise comparison. \r\n\r\n\r\n  [1]: https://en.wikipedia.org/wiki/Bubble_sort",
                    "title": "What sorting algorithm is this? (&quot;merge iterator with itself&quot;)"
                },
                {
                    "owner": {
                        "account_id": 1281728,
                        "reputation": 73871,
                        "user_id": 1235698,
                        "user_type": "registered",
                        "accept_rate": 100,
                        "profile_image": "https://www.gravatar.com/avatar/90fd9ad4efef8eb93209f42183c48f3e?s=256&d=identicon&r=PG",
                        "display_name": "Marcin Orlowski",
                        "link": "https://stackoverflow.com/users/1235698/marcin-orlowski"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709054184,
                    "answer_id": 78069358,
                    "question_id": 78069220,
                    "body_markdown": "No. it&#39;s not equivalent to any commonly known sorting algorithm, however some may see similarities to bubble sort. It&#39;s more of a curiosity and an interesting use of Python&#39;s standard library functions rather than a practical sorting method. Something to show off and confuse your fellow team members ;)\r\n\r\nWhat might be counterintuitive at the first look is the iterator merge step. The `heapq.merge()` expects two (or more) sorted inputs from which it returns a single sorted data set. But we use the same iterator, so each time `merge()` requests the next item from either input, it in fact advances the same iterator. This means that the first request for an item pulls the first element, and the immediate next request (which would conceptually be from the &quot;other&quot; sorted list if they were distinct) also tries to pull the next item from the same sequence. \r\n\r\nThe &quot;sorting&quot; effect in this case is more a byproduct of repeatedly interleaving and checking for sortedness until the list happens to be sorted. That&#39;s also the reason why merging iterator more times than 2 times (i.e. `merge(it, it, it)` would increase the complexity of how elements are interleaved, potentially leading to more iterations needed before the list becomes sorted, slowing down the whole process instead of speeding it up.",
                    "title": "What sorting algorithm is this? (&quot;merge iterator with itself&quot;)"
                },
                {
                    "owner": {
                        "account_id": 8409207,
                        "reputation": 21,
                        "user_id": 6311732,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/8ea04dd379d9de6a69d48b13154993b6?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Kyle Westran",
                        "link": "https://stackoverflow.com/users/6311732/kyle-westran"
                    },
                    "is_accepted": false,
                    "score": -5,
                    "creation_date": 1709054510,
                    "answer_id": 78069389,
                    "question_id": 78069220,
                    "body_markdown": "I&#39;d rather use pythons built-in function **sort()** function\r\n    \r\n    from random import shuffle\r\n\r\n    # Create test data\r\n    a = list(range(100))\r\n\r\n    # Shuffle data\r\n    shuffle(a)\r\n   \r\n    # Sort\r\n    a.sort()\r\n\r\n    print(a)\r\n\r\nFar more Efficient!",
                    "title": "What sorting algorithm is this? (&quot;merge iterator with itself&quot;)"
                },
                {
                    "owner": {
                        "account_id": 22573228,
                        "reputation": 6519,
                        "user_id": 16759116,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/n2u4t.png?s=256&g=1",
                        "display_name": "no comment",
                        "link": "https://stackoverflow.com/users/16759116/no-comment"
                    },
                    "is_accepted": false,
                    "score": 2,
                    "creation_date": 1709054982,
                    "answer_id": 78069449,
                    "question_id": 78069220,
                    "body_markdown": "It&#39;s indeed bubble sort implemented weirdly.\r\n\r\nBubble sort repeatedly does this until the list is sorted:\r\n- Slide a two-item window over the list. At each position, sort the two items in the window, then slide the window one position to the right. This leaves the smaller item behind, the larger item remains in the window, and the next item enters the window.\r\n\r\nThe `merge` with the same iterator twice does effectively the same thing. Its &quot;two-item window&quot; is the two &quot;current values&quot;, the `x` and `y` in the question&#39;s `merge` implementation. Like in bubble sort, the smaller one is &quot;left behind&quot; (gets yielded, becomes the next item in the output). The larger one remains in the &quot;window&quot; (remains `x` or `y`). And the next item from the input list enters the window (becomes the other one of `x` and `y`).\r\n\r\nThinking of Knuth&#39;s *&quot;[Beware ... I have only proved it ... not tried it](https://www-cs-faculty.stanford.edu/~knuth/faq.html)&quot;*, let&#39;s also try it, checking experimentally whether the behavior is indeed identical to ordinary bubble sort. Sorting a shuffled list with 1000 elements both with my question&#39;s sort and with bubble sort, and recording the state of the list after each &quot;round&quot;. They&#39;re identical for both sorts.\r\n\r\n```python\r\nfrom random import shuffle\r\nfrom heapq import merge\r\nfrom itertools import pairwise\r\n\r\n# Create test data\r\na = list(range(1000))\r\nshuffle(a)\r\n\r\ndef mysort_steps(a):\r\n    steps = []\r\n    while any(x &gt; y for x, y in pairwise(a)):\r\n        it = iter(a)\r\n        a = list(merge(it, it))\r\n        steps.append(a[:])\r\n    return steps\r\n\r\ndef bubblesort_steps(a):\r\n    steps = []\r\n    n = len(a)\r\n    for i in range(n - 1):\r\n        swapped = False\r\n        for j in range(n - 1 - i):\r\n            if a[j] &gt; a[j+1]:\r\n                a[j], a[j+1] = a[j+1], a[j]\r\n                swapped = True\r\n        if not swapped:\r\n            break\r\n        steps.append(a[:])\r\n    return steps\r\n\r\nprint(mysort_steps(a[:]) == bubblesort_steps(a[:]))\r\n```\r\n\r\n[Attempt This Online!](https://ato.pxeger.com/run?1=lVJLasMwEIUudYqBbmyalGRXAumm0BN0F0yR8ThWYsuqNCbxWbrJpj1FT9LTdCRb-bSFUoGRNG-e3pvxvL6bnqpWHw5vHZXTu8-rj9K2DVipC95UY1pL4KquLGsUAapQmpeINGjXY1wRWmrb2kXMSGV3yqEQ1_BgURICoSMoJEkhYQm1cpSw0hqT-Ww2S1MxCiUyFaLAEpre8UvPjtA4Di4E8Ao3pq-ycN1VqkaQuk_2cA89lK2F_YQPSh8tMHck-6WI2d6u14nBo6FQUqJowinpCQ-qt9IY1EUiV4tsgCxSZ_WADp7zLs9r_Nu39oKoowdvW3nPQ0M0TGF-5tntvHTBnEdZc09j3NM232j8qTNqKLkEudpk3CDebubZJRrqZ3gyoqwyHEIg-5F7MvNku5MXFtEtRfRSIucB2P6vmcYqzb_jYgR8KiyXvzTZI-kwxOMsx5n-Ag)",
                    "title": "What sorting algorithm is this? (&quot;merge iterator with itself&quot;)"
                }
            ],
            "owner": {
                "account_id": 22573228,
                "reputation": 6519,
                "user_id": 16759116,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/n2u4t.png?s=256&g=1",
                "display_name": "no comment",
                "link": "https://stackoverflow.com/users/16759116/no-comment"
            },
            "is_answered": true,
            "view_count": 125,
            "favorite_count": 0,
            "answer_count": 4,
            "score": 4,
            "creation_date": 1709052819,
            "question_id": 78069220,
            "body_markdown": "As long as the list isn&#39;t sorted, keep replacing it with a merge of an iterator with itself. Is that (equivalent to) one of the commonly known sorting algorithms, just implemented weirdly, or is it something new?\r\n\r\n```python\r\nfrom random import shuffle\r\nfrom heapq import merge\r\nfrom itertools import pairwise\r\n\r\n# Create test data\r\na = list(range(100))\r\nshuffle(a)\r\n\r\n# Sort\r\nwhile any(x &gt; y for x, y in pairwise(a)):\r\n    it = iter(a)\r\n    a = list(merge(it, it))\r\n\r\nprint(a)\r\n```\r\n\r\n[Attempt This Online!](https://ato.pxeger.com/run?1=PZAxDsIwDEX3nMISSyqBBBtCgoUjcAJLONRSmwTHFfQsLCxwJy7BGXChxYstf-c_O7dn7rVO8X5_dBoW69c7SGpBMB4tcZuTKJS6C6Eh95VqwnyelJbkNPZZSTSlpkxaRpYLF3JuBnshVAKlonBERYewhYaLeiOdyK-Wy6pyI8djNbw5mIm71NwQYOz9FXbQQ0gC17kVHP8Am682DixYzXZYZLAYGn_Md1HPOjfZSC4LR7Wp39Xj8dMnfAA)\r\n\r\n`heapq.merge` does merge two inputs in the &quot;standard&quot; way, but it&#39;s an implementation detail and its inputs are supposed to be sorted, which they aren&#39;t here (and they&#39;re also not independent, as they use the same source). To eliminate it being an implementation detail, let `merge` actually be this (the standard way, always comparing the two &quot;current&quot; values, yielding the smaller one and fetching a replacement for it):\r\n```\r\ndef merge(xs, ys):\r\n    none = object()\r\n    x = next(xs, none)\r\n    y = next(ys, none)\r\n    while (x is not none) and (y is not none):\r\n        if x &lt;= y:\r\n            yield x\r\n            x = next(xs, none)\r\n        else:\r\n            yield y\r\n            y = next(ys, none)\r\n    if x is not none:\r\n        yield x\r\n    if y is not none:\r\n        yield y\r\n    yield from xs\r\n    yield from ys\r\n```",
            "link": "https://stackoverflow.com/questions/78069220/what-sorting-algorithm-is-this-merge-iterator-with-itself",
            "title": "What sorting algorithm is this? (&quot;merge iterator with itself&quot;)"
        },
        {
            "tags": [
                "python",
                "string"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 10517125,
                        "reputation": 608,
                        "user_id": 7750891,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/e8a9ca9a5539f1ecbc75f02b024b9fa8?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Anonymous",
                        "link": "https://stackoverflow.com/users/7750891/anonymous"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709053591,
                    "answer_id": 78069296,
                    "question_id": 78069167,
                    "body_markdown": "Split the date part, convert to datetime or not, sort.\r\n\r\n    import os\r\n    from datetime import datetime\r\n    \r\n    filelist = [\r\n        &quot;QA558_20240223154745500.json&quot;,\r\n        &quot;QA558_19990223165244591.json&quot;,\r\n        &quot;QA558_20240223165244591.json&quot;,\r\n        &quot;QA558_19940223165244591.json&quot;,\r\n    ]\r\n    \r\n    # Datetime not really needed I guess\r\n    # datelist = [datetime.strptime(os.path.splitext(x)[0].split(&quot;_&quot;)[-1], &quot;%Y%m%d%H%M%S%f&quot;) for x in filelist]\r\n\r\n    datelist = [os.path.splitext(x)[0].split(&quot;_&quot;)[-1] for x in filelist]\r\n    sorted_datelist = sorted(datelist)\r\n\r\nOutput:\r\n\r\n    [&#39;19940223165244591&#39;,\r\n     &#39;19990223165244591&#39;,\r\n     &#39;20240223154745500&#39;,\r\n     &#39;20240223165244591&#39;]",
                    "title": "Python: Opening specific file with latest timestamp in name"
                },
                {
                    "owner": {
                        "account_id": 24576000,
                        "reputation": 402,
                        "user_id": 19932351,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/e9832c9331d8145befa39df7195975b0?s=256&d=identicon&r=PG",
                        "display_name": "Leon",
                        "link": "https://stackoverflow.com/users/19932351/leon"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709053772,
                    "answer_id": 78069310,
                    "question_id": 78069167,
                    "body_markdown": "I could not reproduce your exact behaviour so I used an array instead but you should get a hint for your code since this worked out pretty well for me, with a .json file in the same folder.\r\n```python\r\ndef get_file(name):\r\n\r\n    files = [&#39;P2096_20240221114151310.json&#39;,&#39;QA558_20240223154745500.json&#39;,&#39;QA558_20240223165244593.json&#39;, &#39;QA558_20240223165244591.json&#39;]\r\n    correct_files = &quot;&quot;\r\n    for file in files:\r\n        file = file.strip(&#39;.\\\\&#39;)\r\n\r\n        # Check for correct name and if correct file is empty or if the current file is newer than the correct file\r\n        if file.startswith(name) and (not correct_files or file &gt; correct_files):\r\n            correct_files = file\r\n\r\n    # Open the file with read\r\n    with open(correct_files, &#39;r&#39;) as f:\r\n        print(f.read())\r\n\r\n    print(correct_files)\r\n\r\nget_file(&#39;QA558&#39;)\r\n```\r\nAs an output, I receive my sample json and the highest .json file found.\r\n```bash\r\n{\r\n  &quot;name&quot;: &quot;John Doe&quot;,\r\n  &quot;age&quot;: 30,\r\n  &quot;city&quot;: &quot;New York&quot;\r\n}\r\n\r\nQA558_20240223165244593.json\r\n```",
                    "title": "Python: Opening specific file with latest timestamp in name"
                },
                {
                    "owner": {
                        "account_id": 1143565,
                        "reputation": 510708,
                        "user_id": 1126841,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/fa05233b2357f8d11c22ef4cfc7bb85c?s=256&d=identicon&r=PG",
                        "display_name": "chepner",
                        "link": "https://stackoverflow.com/users/1126841/chepner"
                    },
                    "is_accepted": false,
                    "score": 2,
                    "creation_date": 1709054464,
                    "answer_id": 78069383,
                    "question_id": 78069167,
                    "body_markdown": "Start by embedding the name in the pattern itself. Then use `max` to get the largest value according to an appropriate key function.\r\n\r\n    import glob\r\n    \r\n    def get_file(name):\r\n    \r\n        files = glob.glob(f&#39;./{name}_*.json&#39;))\r\n        if files:\r\n            return max(files,\r\n                       key=lambda x: x.split(&#39;_&#39;)[0].remove_suffix(&#39;.json&#39;)\r\n                      )\r\n        else:\r\n            return None\r\n            # or raise an exception, or something\r\n\r\nIf you are happy with returning `None`, you can simply return `max(files, default=None, key=...)` without checking if `files` is empty or not. If you are going to raise an exception, you can either let the `ValueError` raised by `max([], key=...)` bubble up, or catch it and raise a different exception of your own.\r\n\r\n",
                    "title": "Python: Opening specific file with latest timestamp in name"
                }
            ],
            "owner": {
                "account_id": 5603640,
                "reputation": 3714,
                "user_id": 4439019,
                "user_type": "registered",
                "accept_rate": 91,
                "profile_image": "https://www.gravatar.com/avatar/09af2c6ab57c138ef59e8ed80896a9a0?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "JD2775",
                "link": "https://stackoverflow.com/users/4439019/jd2775"
            },
            "is_answered": true,
            "view_count": 51,
            "favorite_count": 0,
            "accepted_answer_id": 78069310,
            "answer_count": 3,
            "score": 1,
            "creation_date": 1709052335,
            "question_id": 78069167,
            "body_markdown": "I have set of JSON files in my directory that look like this:\r\n\r\n    P2096_20240221114151310.json\r\n    QA558_20240223154745500.json\r\n    QA558_20240223165244591.json\r\n\r\nwhat I want to do is pass the string to the left of the underscore as an argument, and then open the json file with the latest timestamp in the name.\r\n\r\nThis is what I have so far:\r\n\r\n    import glob\r\n\r\n    def get_file(name):\r\n    \r\n        files = glob.glob(&#39;./*.json&#39;)\r\n        correct_files = []\r\n        for file in files:\r\n            file = file.strip(&#39;.\\\\&#39;)\r\n            \r\n            if file.startswith(name):\r\n                correct_files.append(file)\r\n    \r\n        print(correct_files)\r\n    \r\n    get_file(&#39;QA558&#39;)\r\n\r\nAnd that gets me to here:\r\n\r\n    [&#39;QA558_20240223154745500.json&#39;, &#39;QA558_20240223165244591.json&#39;]\r\n\r\n\r\n\r\nThat is where I am stuck.  I know after I find the max timestamp, I will add the `with` statement to load the file as data, I just don&#39;t know how to get to that point. \r\n\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/78069167/python-opening-specific-file-with-latest-timestamp-in-name",
            "title": "Python: Opening specific file with latest timestamp in name"
        },
        {
            "tags": [
                "python",
                "arrays"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 15089274,
                        "reputation": 40,
                        "user_id": 10889637,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/-h1IuOFUq7uE/AAAAAAAAAAI/AAAAAAAAALc/YdfH8ZeVv20/photo.jpg?sz=256",
                        "display_name": "Llew",
                        "link": "https://stackoverflow.com/users/10889637/llew"
                    },
                    "is_accepted": true,
                    "score": 0,
                    "creation_date": 1709053461,
                    "answer_id": 78069283,
                    "question_id": 78069135,
                    "body_markdown": "Your big issue is that you are doing a check on the first item in the grade list:\r\n`if grade[0] &lt; 20`\r\n\r\nwith this as long as someone enters the very first grade correctly (less than 20) then this will continue to accept other inputs. \r\n\r\nIf I understand your question correctly, you do not want a user to be able to input anything greater than 20. It&#39;s not clear if the program should exit, throw it away or ask for it again. \r\n\r\nBut what would likely work here is to do a for loop with a while loop that validates if the input is valid. \r\nsomething like this:\r\n\r\n    last_input = 0\r\n    for item in range(0, len(grade)):\r\n        while last_input &lt;= 0 or last_input &gt; 20:\r\n            last_input = float(input(&quot;Insert grade:&quot;))\r\n            if last_input &gt; 20:\r\n                print(&quot;input must be less than or equal to 20&quot;)\r\n        grade[item] = last_input\r\n        last_input = 0\r\n\r\neffectively what this does is it starts to iterate over the grade list that was created at first with 5 zeros, then it tests the input inside the while loop by setting a tracking variable (last_input) to the user&#39;s input. As long as the input is below or equal to 20 it will move on to the next item in the loop. If not it will continue to ask the user to re-input the grade. Once a user added a acceptable input it will reset the last input to 0 after recording the user&#39;s input and grab the next input. \r\n\r\nThis is only one way of handling this. \r\n\r\nAlso, you may want to simplify the for loop by creating an empty list instead of creating a list of 5 zeros\r\n\r\n    grade = []\r\n\r\nand then in the for loop specify how many times it should iterate\r\n\r\n    for item in range(0, 5):\r\n\r\nThen instead of setting the value at an index with `grade[item] = last_input` append the value instead with\r\n`grade.append(last_input)`\r\n\r\n\r\n\r\n\r\n",
                    "title": "&quot;IF&quot; Condition For a Empty Array"
                }
            ],
            "owner": {
                "account_id": 30644047,
                "reputation": 13,
                "user_id": 23491889,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/I55Qi.jpg?s=256&g=1",
                "display_name": "user23491889",
                "link": "https://stackoverflow.com/users/23491889/user23491889"
            },
            "is_answered": true,
            "view_count": 69,
            "favorite_count": 0,
            "accepted_answer_id": 78069283,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709052039,
            "question_id": 78069135,
            "body_markdown": "I write a code to give 5 numbers and save them in an array but grades are between 0-20\r\nhow to write conditions in for loop without saving any false number\r\n\r\n**Basic Code:**\r\n```\r\nimport numpy as np\r\ngrade=np.zeros(5)\r\nfor item in range(len(grade)):\r\n                    grade[item]=float(input(&quot;Inser grade:&quot;))\r\nprint(f&quot;list of grade : {grade}&quot;)\r\nmingrade=lambda grade:np.amin(grade)\r\nmaxgrade=lambda grade:np.amax(grade)\r\nprint(&quot;min Grade is :&quot;,mingrade(grade))\r\nprint(&quot;max grade us :&quot;,maxgrade(grade))\r\n```\r\n**now I add condition:**\r\n\r\n```\r\nimport numpy as np\r\ngrade=np.zeros(5,dtype=float)\r\ngrade[0]=float(input(&quot;Inser grade:&quot;))\r\nif grade[0] &lt; 20 :\r\n                    for item in range(1,len(grade)):\r\n                                     if grade[0] and grade[item] &lt; 20:\r\n                                             grade[item]=float(input(&quot;Inser grade:&quot;))\r\nprint(f&quot;list of grade : {grade}&quot;)\r\nmingrade=lambda grade:np.amin(grade)\r\nmaxgrade=lambda grade:np.amax(grade)\r\nprint(&quot;min Grade is :&quot;,mingrade(grade))\r\nprint(&quot;max grade us :&quot;,maxgrade(grade))\r\n```\r\nresult is:\r\nInser grade:15\r\nInser grade:13\r\nInser grade:20\r\nInser grade:23\r\nInser grade:25\r\nlist of grade : [15. 13. 20. 23. 25.]\r\n\r\nI need to code dont save any higher of 20\r\n\r\nThanks , im new in python \r\n\r\n\r\n\r\n\r\n\r\nNo accept and save number higher of 20",
            "link": "https://stackoverflow.com/questions/78069135/if-condition-for-a-empty-array",
            "title": "&quot;IF&quot; Condition For a Empty Array"
        },
        {
            "tags": [
                "python",
                "discord"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 20393143,
                        "reputation": 1,
                        "user_id": 14960607,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a-/AOh14GjAhYlNfnft28wHPl9fM9Xquy_WmnqE7qIACcdIPQ=k-s256",
                        "display_name": "Tathya Garg",
                        "link": "https://stackoverflow.com/users/14960607/tathya-garg"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709054692,
                    "answer_id": 78069414,
                    "question_id": 78069100,
                    "body_markdown": "I&#39;m assuming you want the bot to send a message, given by the person who invoked the command, to all people with a certain role? If so, here&#39;s the code for that:\r\n```py\r\n@bot.command()  \r\nasync def lol(ctx, *, msg):\r\n    for guild in bot.guilds:  # all servers of the bot\r\n        role = discord.utils.find(lambda r: r.name == &#39;new role&#39;, guild.roles)\r\n        for member in guild.members:\r\n            if role in member.roles:\r\n                await member.send(msg)\r\n```",
                    "title": "how can i make a discord bot send the message the author says discord py"
                }
            ],
            "owner": {
                "account_id": 30644119,
                "reputation": 1,
                "user_id": 23491942,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKLU8VDFsursSUOZqeq1WgUtaLR5nhkGcl_X-etCPxk=k-s256",
                "display_name": "hijacked",
                "link": "https://stackoverflow.com/users/23491942/hijacked"
            },
            "is_answered": false,
            "view_count": 20,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -1,
            "creation_date": 1709051696,
            "question_id": 78069100,
            "body_markdown": "```\r\n@bot.command()  \r\nasync def lol(ctx):\r\n    for guild in bot.guilds:  # all servers of the bot\r\n        role = discord.utils.find(lambda r: r.name == &#39;new role&#39;, guild.roles)\r\n        for member in guild.members:\r\n            if role in member.roles:\r\n                await member.send(word)\r\n    word = &quot;&quot;\r\n```\r\nthis is it so far \r\n\r\nif you are feeling generous can you tell me how to use the role the author says\r\n\r\n",
            "link": "https://stackoverflow.com/questions/78069100/how-can-i-make-a-discord-bot-send-the-message-the-author-says-discord-py",
            "title": "how can i make a discord bot send the message the author says discord py"
        },
        {
            "tags": [
                "python",
                "django",
                "django-models"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 26078,
                        "reputation": 457439,
                        "user_id": 67579,
                        "user_type": "registered",
                        "accept_rate": 81,
                        "profile_image": "https://i.stack.imgur.com/3vVAT.png?s=256&g=1",
                        "display_name": "willeM_ Van Onsem",
                        "link": "https://stackoverflow.com/users/67579/willem-van-onsem"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709051253,
                    "answer_id": 78069064,
                    "question_id": 78069036,
                    "body_markdown": "Likely the best way is to work with a manager in this case:\r\n\r\n&lt;pre&gt;&lt;code&gt;class &lt;b&gt;PostManager&lt;/b&gt;(models.Manager):\r\n    def get_queryset(self, *args, **kwargs):\r\n        return (\r\n            super()\r\n            .get_queryset(*args, **kwargs)\r\n            .alias(num_likes=Count(&#39;likes&#39;))\r\n            .order_by(&#39;-num_likes&#39;)\r\n        )\r\n\r\n\r\nclass Post(models.Model):\r\n    likes = models.ManyToManyField(User)\r\n\r\n    &lt;b&gt;objects = PostManager()&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;",
                    "title": "Django order by number of related objects in class Meta"
                }
            ],
            "owner": {
                "account_id": 21320174,
                "reputation": 21,
                "user_id": 15693482,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/mPcxz.png?s=256&g=1",
                "display_name": "DNIIBOY",
                "link": "https://stackoverflow.com/users/15693482/dniiboy"
            },
            "is_answered": false,
            "view_count": 23,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709050926,
            "question_id": 78069036,
            "body_markdown": "In Django, i want to set the default model ordering to be by the number of related objects. In my case i would like to order the objects by the number of likes, where likes is a `ManyToManyField` of users that have liked the post:\r\n\r\n```python\r\nclass Post(models.Model):\r\n    likes = models.ManyToManyField(User)\r\n\r\n    class Meta:\r\n        ordering = []  # What can i put here?\r\n```\r\n\r\nThe common solution seems to be [django aggregation](https://docs.djangoproject.com/en/5.0/topics/db/aggregation/):\r\n\r\n\r\n```python\r\nfrom django.db.models import Count\r\n\r\ntop_posts = Post.objects.annotate(num_likes=Count(&#39;likes&#39;)).order_by(&#39;-num_likes&#39;)\r\n```\r\n\r\nBut this is called on the queryset, and doesn&#39;t seem like an option when defining the model.\r\nI also read about [expressions](https://docs.djangoproject.com/en/5.0/ref/models/expressions/), where the `F` expression seems like it may be of use.",
            "link": "https://stackoverflow.com/questions/78069036/django-order-by-number-of-related-objects-in-class-meta",
            "title": "Django order by number of related objects in class Meta"
        },
        {
            "tags": [
                "python",
                "markdown"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 18575,
                        "reputation": 8912,
                        "user_id": 42659,
                        "user_type": "registered",
                        "accept_rate": 95,
                        "profile_image": "https://www.gravatar.com/avatar/387fa5005e15bca282d440aefcc0adac?s=256&d=identicon&r=PG",
                        "display_name": "Thomas",
                        "link": "https://stackoverflow.com/users/42659/thomas"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709050243,
                    "answer_id": 78068964,
                    "question_id": 78068888,
                    "body_markdown": "You need to download the **raw** file:\r\n\r\n```python\r\nimport urllib.request\r\n\r\nfrom pathlib import Path\r\n\r\nREPO_URL = &quot;https://gitlab.com/quanzhang/cloud-deploy-component-prod&quot;\r\n\r\nDOC_URL = f&quot;{REPO_URL}/-/raw/main/README.md&quot;\r\n\r\nDOWNLOAD_FOLDER = r&quot;c:\\temp&quot;  \r\n\r\nwith urllib.request.urlopen(DOC_URL) as response:\r\n    with (Path(DOWNLOAD_FOLDER) / Path(DOC_URL).name).open(&quot;wb&quot;) as file:\r\n        file.write(response.read())\r\n```\r\n\r\nSide note: Depending on your needs consider using [`requests`](https://requests.readthedocs.io/en/latest/) instead of `urllib`.",
                    "title": "Load remote markdown file from python"
                }
            ],
            "owner": {
                "account_id": 15857808,
                "reputation": 55,
                "user_id": 11441747,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/8c6be1b1d2f07e5d1ea01cba1761a452?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Diego",
                "link": "https://stackoverflow.com/users/11441747/diego"
            },
            "is_answered": true,
            "view_count": 55,
            "favorite_count": 0,
            "accepted_answer_id": 78068964,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709049577,
            "question_id": 78068888,
            "body_markdown": "I need to read an .md file with python and store the content somewhere else.\r\nWhen I use this code, I get HTML, but I only need the markdown code.\r\n\r\n```\r\ndoc_url = &#39;https://gitlab.com/quanzhang/cloud-deploy-component-prod/-/blob/main/README.md&#39;  \r\nwith urllib.request.urlopen(doc_url) as url:\r\n  text = url.read()\r\n```",
            "link": "https://stackoverflow.com/questions/78068888/load-remote-markdown-file-from-python",
            "title": "Load remote markdown file from python"
        },
        {
            "tags": [
                "python",
                "dataframe",
                "python-polars"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 13299305,
                        "reputation": 866,
                        "user_id": 9601258,
                        "user_type": "registered",
                        "profile_image": "https://graph.facebook.com/598621350480798/picture?type=large",
                        "display_name": "Cem Ko&#231;ak",
                        "link": "https://stackoverflow.com/users/9601258/cem-ko%c3%a7ak"
                    },
                    "is_accepted": false,
                    "score": -2,
                    "creation_date": 1709049710,
                    "answer_id": 78068902,
                    "question_id": 78068806,
                    "body_markdown": "Ofcourse, you can use a dictionary to match desired operation for any column like this:\r\n\r\n```\r\ndata = {\r\n    &quot;A&quot;: [1, 2, 3, 4],\r\n    &quot;B&quot;: [5, 6, 7, 8],\r\n    &quot;C&quot;: [9, 10, 11, 11]\r\n}\r\ndf = pd.DataFrame(data)\r\n\r\naggregations = {\r\n    &quot;A&quot;: &quot;sum&quot;,\r\n    &quot;B&quot;: &quot;mean&quot;,\r\n    &quot;C&quot;: &quot;max&quot;\r\n}\r\nresult = df.agg(aggregations)\r\n\r\nprint(result)\r\n```\r\noutput:\r\n\r\n[![enter image description here][1]][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/x1Ijo.png\r\n\r\nOr simply this one liner would also work:\r\n```\r\ndf.agg({&quot;A&quot;: &quot;sum&quot;,&quot;B&quot;: &quot;mean&quot;,&quot;C&quot;: &quot;max&quot;})\r\n```\r\n\r\n\r\n**With polars library:**\r\n```\r\ndf.select(pl.col(&quot;A&quot;).sum(),pl.col(&quot;B&quot;).mean(),pl.col(&quot;C&quot;).max())\r\n```",
                    "title": "Polars aggregate without a groupby"
                },
                {
                    "owner": {
                        "account_id": 8103570,
                        "reputation": 2124,
                        "user_id": 12978930,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/GCxoQ.jpg?s=256&g=1",
                        "display_name": "Hericks",
                        "link": "https://stackoverflow.com/users/12978930/hericks"
                    },
                    "is_accepted": true,
                    "score": 3,
                    "creation_date": 1709049836,
                    "answer_id": 78068915,
                    "question_id": 78068806,
                    "body_markdown": "When all expressions within a `select` context are aggregations, the resulting dataframe only has a single row. \r\n\r\n```python\r\nimport polars as pl\r\n\r\ndf = pl.DataFrame({\r\n    &quot;a&quot;: [1, 2, 3, 4, 5],\r\n    &quot;b&quot;: [0, 0, 1, 1, 1],\r\n})\r\n```\r\n\r\n```python\r\ndf.select(pl.col(&quot;a&quot;).mean(), pl.col(&quot;b&quot;).first())\r\n```\r\n\r\n```\r\nshape: (1, 2)\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 a   \u2506 b   \u2502\r\n\u2502 --- \u2506 --- \u2502\r\n\u2502 f64 \u2506 i64 \u2502\r\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\r\n\u2502 3.0 \u2506 0   \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\r\n```",
                    "title": "Polars aggregate without a groupby"
                }
            ],
            "owner": {
                "account_id": 19455135,
                "reputation": 387,
                "user_id": 14230633,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a-/AOh14GgeKboycp61M3zamG8mpO09vnTL4C9LGMB_RZC0=k-s256",
                "display_name": "dfried",
                "link": "https://stackoverflow.com/users/14230633/dfried"
            },
            "is_answered": true,
            "view_count": 64,
            "favorite_count": 0,
            "accepted_answer_id": 78068915,
            "answer_count": 2,
            "score": 2,
            "creation_date": 1709048749,
            "question_id": 78068806,
            "body_markdown": "Is there a way to call `.agg()` without grouping first? I want to perform standard aggregations but only want one row in the response, rather than separate rows for separate groups.\r\n\r\nI could do something like\r\n\r\n```\r\ndf.with_columns(dummy_col=pl.lit(&quot;dummy_col&quot;)).group_by(&#39;dummy_col&#39;).agg(&lt;aggregateion&gt;)\r\n```\r\n\r\nbut I&#39;m wondering if there&#39;s a way without the dummy stuff",
            "link": "https://stackoverflow.com/questions/78068806/polars-aggregate-without-a-groupby",
            "title": "Polars aggregate without a groupby"
        },
        {
            "tags": [
                "python",
                "tensorflow",
                "opencv",
                "pytorch",
                "ocr"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 29677440,
                        "reputation": 1,
                        "user_id": 22744995,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocLmiN-bzsL5GZYD4hKoQjLwn2G_lizQi2NS7rfv0kmp=k-s256",
                        "display_name": "Muhammad Arslan Shahzad",
                        "link": "https://stackoverflow.com/users/22744995/muhammad-arslan-shahzad"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709049094,
                    "answer_id": 78068838,
                    "question_id": 78068804,
                    "body_markdown": "For enhancing OCR accuracy on corrupted text-images, you can consider using DeblurGAN for image deblurring and SRGAN for super-resolution. Additionally, You should consider applying image processing techniques like histogram equalization and non-local means denoising to further enhance image quality and improve text extraction accuracy.",
                    "title": "Seeking ML Model Recommendations for Enhancing OCR on Corrupted Text Images"
                }
            ],
            "owner": {
                "account_id": 18398437,
                "reputation": 77,
                "user_id": 13402191,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a-/AOh14GhVLFVoMfI9OFnblLiVyxll150us1DuWYR3JI3ESw=k-s256",
                "display_name": "Nurbek Ss",
                "link": "https://stackoverflow.com/users/13402191/nurbek-ss"
            },
            "is_answered": false,
            "view_count": 37,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709048719,
            "question_id": 78068804,
            "body_markdown": "I am working on a project where I need to perform Optical Character Recognition (OCR) on text-based images. However, these images are corrupted in various ways (e.g., blurred, distorted, low resolution), which significantly diminishes the accuracy of the OCR results.\r\n\r\nI have already tried several preprocessing steps, such as dialation/erosion on binary image and also crimmins speckle_= removal , but the outcomes are still not satisfactory. My goal is to enhance the quality or clarity of these corrupted images before applying OCR to improve the accuracy of the text extraction.\r\n\r\nI came across a model named OCR-VQGAN, which seems close to what I need, but it&#39;s not entirely suited to my specific use case. I am looking for recommendations on machine learning models or approaches that could assist in this scenario. Ideally, I am seeking models that have been successful in:\r\n\r\n- Image restoration or enhancement for text-based images.\r\n- Deblurring or denoising text in images.\r\n- Improving the quality of images to enhance OCR accuracy.\r\n\r\nAny guidance on existing models, research papers, or GitHub repositories that could aid in resolving this issue would be greatly appreciated. Also, if there are any specific strategies or techniques in image processing or machine learning that you think might be beneficial, I would be very interested to hear about them.\r\n\r\nHere is one type of image with what I am working .[![enter image description here][1]][1]\r\n\r\nThank you in advance for your help!\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/FnRKu.png",
            "link": "https://stackoverflow.com/questions/78068804/seeking-ml-model-recommendations-for-enhancing-ocr-on-corrupted-text-images",
            "title": "Seeking ML Model Recommendations for Enhancing OCR on Corrupted Text Images"
        },
        {
            "tags": [
                "python",
                "global-variables",
                "python-module"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 20669561,
                        "reputation": 531,
                        "user_id": 15175627,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/1c1d40b44bd8e42f2d2bb39d1521d52b?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "konstanze",
                        "link": "https://stackoverflow.com/users/15175627/konstanze"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709050223,
                    "answer_id": 78068958,
                    "question_id": 78068797,
                    "body_markdown": "Alright, here is the answer based on the comment by [Barmar][1]:\r\n\r\n```python\r\n#params.py\r\nout_path = &#39;plots&#39;\r\n\r\ndef set_outpath(fname):\r\n    global out_path\r\n    out_path = fname\r\n```\r\n\r\n```python\r\n# plots.py\r\nfrom my_package import params\r\n\r\ndef get_outpath():\r\n    return params.out_path\r\n\r\ndef mkdir_plots(func):\r\n    @functools.wraps(func)\r\n    def wrapper_mkdir_plots(*args, **kwargs):\r\n        try:\r\n            os.makedirs(get_outpath())\r\n        except:\r\n            pass\r\n        func(*args, **kwargs)\r\n    return wrapper_mkdir_plots\r\n\r\n@mkdir_plots\r\ndef plot_fun1(vars):\r\n    # ...\r\n    plt.savefig(os.path.join(out_path, fname))\r\n```\r\n\r\nworks like a charm!\r\n\r\n\r\n  [1]: https://stackoverflow.com/users/1491895/barmar",
                    "title": "User-defined &quot;global&quot; variable in a python package"
                },
                {
                    "owner": {
                        "account_id": 29104359,
                        "reputation": 55,
                        "user_id": 22295508,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/AAcHTtfFNvn22sqSvArlB3fc9BbehSDUQqK8NnDh19C_QuRG=k-s256",
                        "display_name": "Technoeed",
                        "link": "https://stackoverflow.com/users/22295508/technoeed"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709051431,
                    "answer_id": 78069079,
                    "question_id": 78068797,
                    "body_markdown": "There are two issues with your current code:\r\n\r\n 1. Decorator Scope: The `mkdir_plots` decorator creates a new scope around the decorated function and doesn&#39;t access changes made outside its scope to the `out_path` variable.\r\n 2. Global Variable: While it&#39;s generally discouraged to use global variables, modifying `out_path` globally in `set_outpath` might not be reflected in other modules due to Python&#39;s module import behavior.\r\n\r\nSo here are two approaches:\r\n\r\n 1. Nonlocal Variable:\r\n  . Modify `mkdir_plots` to use a `nonlocal` keyword to access the `out_path` variable defined in the outer scope:\r\n\r\n        # plots.py\r\n\r\n        from my_package.params import out_path\r\n\r\n        def mkdir_plots(func):\r\n\r\n            @functools.wraps(func)\r\n            def wrapper(*args, **kwargs):\r\n                nonlocal out_path # Access nonlocal variable\r\n                if not os.path.exists(out_path):\r\n                    os.mkdir(out_path)\r\n                func(*args, **kwargs)\r\n            return wrapper_mkdir_plots\r\n\r\n        @mkdir_plots\r\n        def plot_fun1(vars):\r\n             # ...\r\n             plt.savefig(os.path.join(out_path, fname))\r\n 2. Module-Level Attribute:\r\n  . Define `out_path` as a module-level attribute in `params.py` and access it directly in other modules:\r\n\r\n        # params.py\r\n        class Params:\r\n            out_path = &#39;plots&#39;\r\n            \r\n            def set_outpath(self, fname):\r\n                self.oout_path = fname\r\n\r\n\r\n        # plots.py\r\n        from my_package.params import Params\r\n\r\n        # Access module-level attribute\r\n        out_path = Params.out_path\r\n     \r\n        @mkdir_plots\r\n        def plot_fun1(vars):\r\n            # ...\r\n            plt.savefig(os.path.join(out_path, fname))\r\n       \r\n        # calc.py\r\n        from my_package.params import Params\r\n\r\n        out_path = Params.out_path\r\n \r\n        # ... perform calculations",
                    "title": "User-defined &quot;global&quot; variable in a python package"
                }
            ],
            "owner": {
                "account_id": 20669561,
                "reputation": 531,
                "user_id": 15175627,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/1c1d40b44bd8e42f2d2bb39d1521d52b?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "konstanze",
                "link": "https://stackoverflow.com/users/15175627/konstanze"
            },
            "is_answered": true,
            "view_count": 52,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 1,
            "creation_date": 1709048634,
            "question_id": 78068797,
            "body_markdown": "I wrote a package that does all sorts of calculations and also provides several plotting functions with options to save the plots as .jpg or .png in a folder set by the user. I ensure that the folder exists with a decorator:\r\n\r\n```python\r\n# plots.py\r\nfrom my_package.params import out_path\r\n\r\ndef mkdir_plots(func):\r\n    @functools.wraps(func)\r\n    def wrapper_mkdir_plots(*args, **kwargs):\r\n        if not os.path.exists(out_path):\r\n            os.makedirs(out_path)\r\n        func(*args, **kwargs)\r\n    return wrapper_mkdir_plots\r\n\r\n@mkdir_plots\r\ndef plot_fun1(vars):\r\n    # ...\r\n    plt.savefig(os.path.join(out_path, fname))\r\n```\r\n\r\n```python\r\n#params.py\r\nout_path = &#39;plots&#39;\r\n\r\ndef set_outpath(fname):\r\n    global out_path\r\n    out_path = fname\r\n```\r\nThe function `set_outpath()` is supposed to allow user to define the folder name themselves. The function `set_outpath()` sets global variable `params.out_path` to anything I like but the plotting module will always use `&#39;plots&#39;`.\r\n\r\n\r\nIdeally, the variable `out_path` set by the user is accessible not only from within the plotting module (`plot.py`) but also from other modules that are part of my package (`calc.py`), although this is not a must.",
            "link": "https://stackoverflow.com/questions/78068797/user-defined-global-variable-in-a-python-package",
            "title": "User-defined &quot;global&quot; variable in a python package"
        },
        {
            "tags": [
                "python"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 20780824,
                        "reputation": 30990,
                        "user_id": 15261315,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/a9cb18689f8216a39642728ffebd47be?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Chris",
                        "link": "https://stackoverflow.com/users/15261315/chris"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709049100,
                    "answer_id": 78068839,
                    "question_id": 78068790,
                    "body_markdown": "In the first example, you&#39;ve created a generator object that works on `file`, but at the conclusion of the `with` block, the file is closed, and thus cannot be read from. The generator is returned, but can&#39;t be used.\r\n\r\nIn the second, the file remains open for reading throughout the loop. Only at the end of the loop and thus the `with` block is the file closed.",
                    "title": "Difference between returning a Generator and yield values"
                },
                {
                    "owner": {
                        "account_id": 278595,
                        "reputation": 10099,
                        "user_id": 573255,
                        "user_type": "registered",
                        "accept_rate": 83,
                        "profile_image": "https://www.gravatar.com/avatar/41a9c3304eed6c695c3dfe70b4e4399c?s=256&d=identicon&r=PG",
                        "display_name": "Jasmijn",
                        "link": "https://stackoverflow.com/users/573255/jasmijn"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709049377,
                    "answer_id": 78068870,
                    "question_id": 78068790,
                    "body_markdown": "That is because your first sample is equivalent to\r\n\r\n```\r\ndef _generator(file):\r\n    for line in file:\r\n        yield line.strip()\r\n\r\ndef get_file_rows(path: str):\r\n    with open(path, &quot;r&quot;) as file:\r\n        return _generator(file)\r\n```\r\n\r\nAnd generator functions like `_generator`, when called, do not start their execution yet, they only return a generator iterator. That code only gets executed when it is iterated over, by which time control flow has left the `with`-statement and the file has been closed.\r\n\r\nBy contrast, in your second example, the `with` statement is only entered at the start of iteration over `lines` and only exits after the iterator is exhausted.",
                    "title": "Difference between returning a Generator and yield values"
                }
            ],
            "owner": {
                "account_id": 27940270,
                "reputation": 17,
                "user_id": 21336438,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/AGNmyxZ4PSjgEZUSBi9vCb1MwHoOOcI1Jn3RjJKTxKjq=k-s256",
                "display_name": "Daniel Aviv",
                "link": "https://stackoverflow.com/users/21336438/daniel-aviv"
            },
            "is_answered": true,
            "view_count": 53,
            "favorite_count": 0,
            "accepted_answer_id": 78068870,
            "answer_count": 2,
            "score": 0,
            "creation_date": 1709048574,
            "question_id": 78068790,
            "body_markdown": "I encountered a problem with two pieces of code: one successfully executed, while the other did not, resulting in a ValueError related to an I/O operation on a closed file. Can you explain why one code snippet failed and the other succeeded, highlighting the differences between them?\r\n\r\n# Invalid\r\n```python\r\ndef get_file_rows(path: str):\r\n    with open(path, &quot;r&quot;) as file:\r\n        lines = (line.strip() for line in file)\r\n    return lines\r\n\r\nlines = get_file_rows(&quot;test.txt&quot;)\r\nfor line in lines:\r\n    print(line)\r\n```\r\n*ValueError: I/O operation on closed file.*\r\n\r\n# Valid\r\n```python\r\ndef get_file_rows(path: str):\r\n    with open(path, &quot;r&quot;) as file:\r\n        for line in file:\r\n            yield line.strip()\r\n\r\nlines = get_file_rows(&quot;test.txt&quot;)\r\nfor line in lines:\r\n    print(line)\r\n```",
            "link": "https://stackoverflow.com/questions/78068790/difference-between-returning-a-generator-and-yield-values",
            "title": "Difference between returning a Generator and yield values"
        },
        {
            "tags": [
                "python",
                "database",
                "sqlite",
                "flask"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 19224931,
                        "reputation": 194,
                        "user_id": 14608129,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/-exGfRhW-RoY/AAAAAAAAAAI/AAAAAAAAAAA/AMZuucnZ1Rqv5nehzRUZlFfWWsQ7q8jB2w/photo.jpg?sz=256",
                        "display_name": "Raphael Moral Piazera",
                        "link": "https://stackoverflow.com/users/14608129/raphael-moral-piazera"
                    },
                    "is_accepted": false,
                    "score": -1,
                    "creation_date": 1709063849,
                    "answer_id": 78070264,
                    "question_id": 78068763,
                    "body_markdown": "You have to change in Class User.username to User.user",
                    "title": "issue with connecting flask app with sqlite database"
                }
            ],
            "owner": {
                "account_id": 30273780,
                "reputation": 1,
                "user_id": 23200798,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJYH0RcNBfNVrmjlCLCaZEFgONvJYbMQ5qujMzZxZuk50U=k-s256",
                "display_name": "Rishi Kapadia",
                "link": "https://stackoverflow.com/users/23200798/rishi-kapadia"
            },
            "is_answered": false,
            "view_count": 31,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709048313,
            "question_id": 78068763,
            "body_markdown": "i am facing issue with connecting flask web app to sqlite database \r\nplease help me solve this. \r\ni tried doing recommendations given by chatgpt and gemini chat bot but the issue still persist!!\r\n\r\n        sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: user\r\n    [SQL: SELECT user.id AS user_id, user.username AS user_username, user.email AS user_email, user.image_file AS user_image_file, user.password AS user_password\r\n    FROM user\r\n    WHERE user.email = ?\r\n    LIMIT ? OFFSET ?]\r\n    [parameters: (&#39;data@gmail.com&#39;, 1, 0)]\r\n    (Background on this error at: https://sqlalche.me/e/20/e3q8)\r\n\r\n\r\nthis is the. code which i am facing error in\r\n\r\n    from flask import Flask, render_template, url_for, flash, redirect\r\n    from form import RegistrationForm, LoginForm, BookForm, UploadBook, Contact, DeleteBook\r\n    from recomm import recom\r\n    from flask_sqlalchemy import SQLAlchemy\r\n    from PIL import Image\r\n    import os\r\n    import pandas as pd\r\n    import numpy as np\r\n    from flask_table import Table, Col\r\n    \r\n    class Results(Table):\r\n        id = Col(&#39;Id&#39;, show=False)\r\n        title = Col(&#39;TOP RECOMMENDATIONS&#39;)\r\n    \r\n    app=Flask(__name__)\r\n    \r\n    SECRET_KEY = os.urandom(32)\r\n    app.config[&#39;SECRET_KEY&#39;] = SECRET_KEY\r\n    app.config[&#39;SQLALCHEMY_DATABASE_URI&#39;]=&#39;sqlite:///site.db&#39;\r\n    db=SQLAlchemy(app)\r\n    \r\n    class User(db.Model):\r\n        id = db.Column(db.Integer, primary_key=True)\r\n        username = db.Column(db.String(20), unique=True, nullable=False)\r\n        email = db.Column(db.String(120), unique=True, nullable=False)\r\n        image_file = db.Column(db.String(20), nullable=False, default=&#39;default.jpg&#39;)\r\n        password = db.Column(db.String(60), nullable=False)\r\n    \r\n        def __repr__(self):\r\n            return f&quot;User(&#39;{self.username}&#39;, &#39;{self.email}&#39;)&quot;\r\n    \r\n    posts = [\r\n        {\r\n        &#39;author&#39; : &#39;Eshita Jain&#39;,\r\n        &#39;title&#39; : &#39;International Institute of Information Technology&#39;\r\n        }\r\n    ]\r\n    \r\n    @app.route(&quot;/&quot;)\r\n    @app.route(&quot;/home&quot;)\r\n    def home():\r\n        return render_template(&#39;home.html&#39;,posts=posts,title=&quot;Home&quot;)\r\n    \r\n    \r\n    @app.route(&quot;/about&quot;)\r\n    def about():\r\n        return render_template(&#39;about.html&#39;,posts=posts,title=&quot;About&quot;)\r\n    \r\n    \r\n    @app.route(&quot;/register&quot;, methods=[&#39;GET&#39;,&#39;POST&#39;])\r\n    def register():\r\n        form = RegistrationForm()\r\n        if form.validate_on_submit():\r\n            flash(f&#39;Account Created for { form.username.data } !&#39;, &#39;success&#39;)\r\n            return redirect(url_for(&#39;home&#39;))\r\n        return render_template(&#39;register.html&#39;,title=&#39;Register&#39;,form=form)\r\n    \r\n    \r\n    @app.route(&quot;/login&quot;, methods=[&#39;GET&#39;,&#39;POST&#39;])\r\n    def login():\r\n        form = LoginForm()\r\n        if form.validate_on_submit():\r\n            if form.email.data == &#39;admin@blog.com&#39; and form.password.data == &#39;password&#39;:\r\n                flash(f&#39;You have been logged in !&#39;, &#39;success&#39;)\r\n                return redirect(url_for(&#39;home&#39;))\r\n            else:\r\n                flash(f&#39;Login Unsuccessful. Please check login details again.&#39;, &#39;danger&#39;)\r\n        return render_template(&#39;login.html&#39;,title=&#39;Login&#39;,form=form)\r\n    \r\n    \r\n    @app.route(&quot;/recommender&quot;,methods=[&#39;GET&#39;,&#39;POST&#39;])\r\n    def recommender():\r\n        form=BookForm()\r\n        df=pd.read_csv(&#39;Book.csv&#39;)\r\n        if form.validate_on_submit():\r\n            if form.bookname.data in list(df[&#39;Title&#39;]):\r\n                flash(f&#39;Here are the following recommendations for you&#39;, &#39;success&#39;)\r\n                isbn=[]\r\n                year=[]\r\n                publisher=[]\r\n                final_list=[]\r\n                book=form.bookname.data\r\n                output, index = recom(book)\r\n                for i in index:\r\n                    isbn.append(df[&quot;ISBN&quot;][i-1])\r\n                    year.append(df[&quot;Year&quot;][i-1])\r\n                    publisher.append(df[&quot;Publisher&quot;][i-1])\r\n                for i in range(len(index)):\r\n                    temp=[]\r\n                    temp.append(output[i])\r\n                    temp.append(isbn[i])\r\n                    temp.append(year[i])\r\n                    temp.append(publisher[i])\r\n                    final_list.append(temp)\r\n            \r\n                return render_template(&#39;recommender.html&#39;,title=&#39;Recommender&#39;,form=form,final=final_list)\r\n            else:\r\n                flash(f&#39;Name not clearly mentioned or does not exist in the database. Please try again.&#39;, &#39;danger&#39;)\r\n                return redirect(url_for(&#39;recommender&#39;))\r\n        return render_template(&#39;recommender.html&#39;,title=&#39;Recommender&#39;,form=form)\r\n    \r\n    @app.route(&quot;/uploadbook&quot;,methods=[&#39;GET&#39;,&#39;POST&#39;])\r\n    def uploadbook():\r\n        form=UploadBook()\r\n        df=pd.read_csv(&#39;Book.csv&#39;)\r\n        if form.validate_on_submit():\r\n            flash(f&#39;Book Uploaded Succesfully&#39;, &#39;success&#39;)\r\n            return redirect(url_for(&#39;home&#39;))\r\n        return render_template(&#39;uploadbook.html&#39;,title=&#39;Upload Book&#39;,form=form)\r\n    \r\n    \r\n    @app.route(&quot;/contact&quot;,methods=[&#39;GET&#39;,&#39;POST&#39;])\r\n    def contact():\r\n        form=Contact()\r\n        if form.validate_on_submit():\r\n            flash(f&#39;Query Submission Succesful&#39;, &#39;success&#39;)\r\n            return redirect(url_for(&#39;contact&#39;))\r\n        return render_template(&#39;contact.html&#39;,title=&#39;Upload Book&#39;,form=form)\r\n    \r\n    \r\n    @app.route(&quot;/deletebook&quot;,methods=[&#39;GET&#39;,&#39;POST&#39;])\r\n    def deletebook():\r\n        form=DeleteBook()\r\n        if form.validate_on_submit():\r\n            flash(f&#39;Book is Deleted&#39;, &#39;success&#39;)\r\n            return redirect(url_for(&#39;home&#39;))\r\n        return render_template(&#39;deletebook.html&#39;,title=&#39;Delete Book&#39;,form=form)\r\n    \r\n    \r\n    @app.route(&quot;/account&quot;)\r\n    def account():\r\n        image_file = url_for(&#39;static&#39;, filename=&#39;profile_pics/&#39; + current_user.image_file)\r\n        return render_template(&#39;account.html&#39;, title=&#39;Account&#39;,image_file=image_file, form=form)\r\n    \r\n    \r\n    if __name__ == &#39;__main__&#39;:\r\n        app.run(debug=True)\r\n\r\n\r\nthis is book recommendation systems code which i want to run but facing issues like the above error. Please help me solve this\r\n",
            "link": "https://stackoverflow.com/questions/78068763/issue-with-connecting-flask-app-with-sqlite-database",
            "title": "issue with connecting flask app with sqlite database"
        },
        {
            "tags": [
                "python",
                "if-statement",
                "while-loop",
                "game-development"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 25244438,
                        "reputation": 4399,
                        "user_id": 19077881,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/201b6c35e32b5629090d0652c5d60bd7?s=256&d=identicon&r=PG",
                        "display_name": "user19077881",
                        "link": "https://stackoverflow.com/users/19077881/user19077881"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709052155,
                    "answer_id": 78069146,
                    "question_id": 78068720,
                    "body_markdown": "If I understand your intention, I think this is what you need to use:\r\n\r\n    while True:\r\n        try:\r\n            question1 = int(input(&quot;1. oui 2. non \\n&quot;))\r\n        except ValueError:\r\n            slow_type(&quot;essai un nombre ou de r&#233;pondre la question.&quot;)\r\n            continue\r\n      \r\n       #slow_type the following two strings if condition is met.\r\n        if question1 == 1:\r\n            slow_type(&quot;Alors, voici mon histoire...&quot;)\r\n            \r\n        elif question1 == 2:\r\n           slow_type(&quot;D&#39;accord.&quot;)\r\n        else:\r\n            break",
                    "title": "Making a terminal game in python and I&#39;m having trouble with a while loop"
                }
            ],
            "owner": {
                "account_id": 30491170,
                "reputation": 1,
                "user_id": 23366362,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/GcceP.png?s=256&g=1",
                "display_name": "Beans",
                "link": "https://stackoverflow.com/users/23366362/beans"
            },
            "is_answered": false,
            "view_count": 35,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -2,
            "creation_date": 1709047947,
            "question_id": 78068720,
            "body_markdown": "I started making this game a little while ago for a school project and I wanted to make a while loop that checks for invalid answers and asks the question again but in doing so my if statements that are supposed to give a response to the question simply won&#39;t and I&#39;m not sure where to look.\r\n\r\n\r\nhere&#39;s what I tried but whenever I type 1 or 2 in the input the code just ends. I tried putting the if statements inside the loop but nothing changed\r\n\r\n```\r\n#Add while loop to accept non int answers and recall input.\r\nwhile True:\r\n    try:\r\n        question1 = int(input(&quot;1. oui 2. non \\n&quot;))\r\n    except ValueError:\r\n        slow_type(&quot;essai un nombre ou de r&#233;pondre la question.&quot;)\r\n        continue\r\n    \r\n    else:\r\n        break\r\n\r\n#slow_type the following two strings if condition is met.\r\nif question1 == &quot;1&quot;:\r\n    slow_type(&quot;Alors, voici mon histoire...&quot;)\r\n    \r\nif question1 == &quot;2&quot;:\r\n   slow_type(&quot;D&#39;accord.&quot;)\r\n```\r\n",
            "link": "https://stackoverflow.com/questions/78068720/making-a-terminal-game-in-python-and-im-having-trouble-with-a-while-loop",
            "title": "Making a terminal game in python and I&#39;m having trouble with a while loop"
        },
        {
            "tags": [
                "python",
                "mysql",
                "sqlalchemy",
                "fastapi"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 15298321,
                        "reputation": 767,
                        "user_id": 11037648,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/s0Dxo.jpg?s=256&g=1",
                        "display_name": "hmn Falahi",
                        "link": "https://stackoverflow.com/users/11037648/hmn-falahi"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709054863,
                    "answer_id": 78069428,
                    "question_id": 78068714,
                    "body_markdown": "The issue you\u2019re facingis because the session you\u2019re querying in is closed once you exit the context manager ``with session_scope() as sess:``. This means, when you\u2019re trying to access ``user.__dict__`` outside the session, SQLAlchemy can\u2019t lazy load any data because the session is no longer active.\r\n\r\nTo solve this issue, you can try to return the ``user.__dict__``:\r\n``` python\r\n@router.get(&quot;/me&quot;)\r\ndef getusers(dependencies=Depends(JWTBearer())):\r\n    user = None\r\n    with session_scope() as sess:\r\n        x = sess.query(TokenTable).where(TokenTable.access_toke == dependencies).first()\r\n        user = sess.query(User).where(User.id == x.user_id).first()\r\n        user = user.__dict__ if user is not None else user\r\n        print(user)\r\n    print(user)\r\n    return user\r\n```",
                    "title": "Fastapi SqlAlchemy session returns an empty object?But when I print it its actual data there"
                }
            ],
            "owner": {
                "account_id": 29319477,
                "reputation": 1,
                "user_id": 22463386,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/AAcHTtfHX8B-UrwOU0KVR2-Idj_wTAjHHqPbBHqpPuHNr5X2=k-s256",
                "display_name": "Kaloyan Botev",
                "link": "https://stackoverflow.com/users/22463386/kaloyan-botev"
            },
            "is_answered": false,
            "view_count": 30,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709047911,
            "question_id": 78068714,
            "body_markdown": "My app uses `fastapi==0.109.2` with `SQLAlchemy==2.0.27`.  \r\nSo my sql connection and session worked fine but I got some errors from sqlalchemy and I changed the way im connecting to use contextmanager like so:   \r\n\r\n\r\n```\r\n\r\n\r\n@contextlib.contextmanager\r\ndef session_scope():\r\n    db_engine = create_engine(url) # echo=True if needed to see background SQL        \r\n    Session = sessionmaker(bind=db_engine)\r\n    session = Session()\r\n    try:\r\n        yield session\r\n        session.commit()\r\n    except:\r\n        print(&quot;Error&quot;)\r\n        session.rollback()\r\n        raise\r\n    finally:\r\n        session.close()\r\n\r\n```\r\nI then Import it and use it here, as you can see I have 2 prints there, the first one shows the actual data, the second one (which is what the endpoint is returning) is emtpy object and I cant seem to find the issue...    \r\n```\r\n@router.get(&quot;/me&quot;)\r\ndef getusers(dependencies=Depends(JWTBearer())):\r\n    user = None\r\n    with session_scope() as sess:\r\n        x = sess.query(TokenTable).where(TokenTable.access_toke == dependencies).first()\r\n        user = sess.query(User).where(User.id == x.user_id).first()\r\n        print(user.__dict__)\r\n    print(user.__dict__)\r\n    return user\r\n```\r\n\r\nThe logs:   \r\n\r\n```\r\nINFO:     127.0.0.1:40662 - &quot;GET /users/me HTTP/1.1&quot; 200 OK\r\n{&#39;_sa_instance_state&#39;: &lt;sqlalchemy.orm.state.InstanceState object at 0x7f11ef2bfc40&gt;, &#39;first&#39;: &#39;Deez&#39;, &#39;last&#39;: &#39;Nuts&#39;, &#39;email&#39;: &#39;test2@test.com&#39;, &#39;id&#39;: 2, &#39;is_active&#39;: True, &#39;coach&#39;: None}\r\n{&#39;_sa_instance_state&#39;: &lt;sqlalchemy.orm.state.InstanceState object at 0x7f11ef2bfc40&gt;}\r\nINFO:     127.0.0.1:40662 - &quot;GET /users/1/logs HTTP/1.1&quot; 200 OK\r\nINFO:     127.0.0.1:40656 - &quot;GET /users/me HTTP/1.1&quot; 200 OK\r\n```\r\n\r\n\r\nI read alot of the sqlachemy documentation, found a few questions here as well, but none of them covered this particular topic.",
            "link": "https://stackoverflow.com/questions/78068714/fastapi-sqlalchemy-session-returns-an-empty-objectbut-when-i-print-it-its-actua",
            "title": "Fastapi SqlAlchemy session returns an empty object?But when I print it its actual data there"
        },
        {
            "tags": [
                "python",
                "selenium-webdriver",
                "webdriver",
                "driver",
                "seleniumbase"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 9494775,
                        "reputation": 12240,
                        "user_id": 7058266,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/cGbc0.jpg?s=256&g=1",
                        "display_name": "Michael Mintz",
                        "link": "https://stackoverflow.com/users/7058266/michael-mintz"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709054969,
                    "answer_id": 78069445,
                    "question_id": 78068616,
                    "body_markdown": "It sounds like you&#39;re trying to compare this:\r\n\r\n```python\r\nfrom seleniumbase import Driver\r\ndriver = Driver()\r\n```\r\n\r\nwith:\r\n\r\n```python\r\nfrom selenium import webdriver\r\ndriver = webdriver.Chrome()\r\n```\r\n\r\nThe seleniumbase `driver` has more methods than the regular selenium one. The seleniumbase driver methods also have auto-selector detection, smart waiting, special assertion methods, allow truncated URLs, and support the `TAG:contains(&quot;TEXT&quot;)` selector. That means you can do this:\r\n\r\n```python\r\nfrom seleniumbase import Driver\r\n\r\ndriver = Driver()\r\ndriver.open(&quot;seleniumbase.io/simple/login&quot;)\r\ndriver.type(&quot;#username&quot;, &quot;demo_user&quot;)\r\ndriver.type(&quot;#password&quot;, &quot;secret_pass&quot;)\r\ndriver.click(&#39;a:contains(&quot;Sign in&quot;)&#39;)\r\ndriver.assert_exact_text(&quot;Welcome!&quot;, &quot;h1&quot;)\r\ndriver.assert_element(&quot;img#image1&quot;)\r\ndriver.highlight(&quot;#image1&quot;)\r\ndriver.click_link(&quot;Sign out&quot;)\r\ndriver.assert_text(&quot;signed out&quot;, &quot;#top_message&quot;)\r\ndriver.quit()\r\n```\r\n\r\nThere are some other differences, such as the way options are passed. SeleniumBase options are passed as args into the `Driver()` definition for the  `Driver()` Manager format (there are many other formats, such as `SB()`, `BaseCase`, etc.)\r\n\r\nSeleniumBase also has a UC Mode option, which has special methods for letting your bots bypass CAPTCHAs that block regular Selenium bots:\r\n\r\n```python\r\nfrom seleniumbase import Driver\r\n\r\ndriver = Driver(uc=True)\r\ndriver.uc_open_with_reconnect(&quot;https://top.gg/&quot;, 6)\r\ndriver.quit()\r\n```\r\n\r\nHere&#39;s a CAPTCHA-bypass example where clicking is required:\r\n\r\n```python\r\nfrom seleniumbase import Driver\r\n\r\ndriver = Driver(uc=True)\r\ndriver.uc_open_with_reconnect(&quot;https://seleniumbase.io/apps/turnstile&quot;, 3)\r\ndriver.uc_switch_to_frame(&quot;iframe&quot;)\r\ndriver.uc_click(&quot;span.mark&quot;)\r\ndriver.sleep(3)\r\ndriver.quit()\r\n```\r\n",
                    "title": "What is the difference between Driver and Webdriver (python selenium)?"
                }
            ],
            "owner": {
                "account_id": 22204162,
                "reputation": 71,
                "user_id": 16444336,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/c539658b7bee54a2f70ab2012c660e56?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Monday",
                "link": "https://stackoverflow.com/users/16444336/monday"
            },
            "is_answered": false,
            "view_count": 22,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709047043,
            "question_id": 78068616,
            "body_markdown": "About Selenium with Python... What is the difference between `from seleniumbase import Driver` (seleniumbase) and `from selenium import webdriver` (selenium, seleniumwire)? \r\nWhat is the difference in &quot;use cases&quot;?\r\n\r\n\r\n\r\nI see only constructor difference: seleniumbase Driver is harder to set options, then manipulaton with object are same. \r\n\r\n```python\r\nfrom seleniumbase import Driver\r\ndriver = Driver(uc=False, headless=True, proxy=proxy, incognito=None, user_data_dir=None, extension_dir=None, binary_location=None)\r\n```\r\n\r\n```python\r\nfrom selenium import webdriver as Driver\r\ndriver = Driver.Chrome(options=options)\r\n```",
            "link": "https://stackoverflow.com/questions/78068616/what-is-the-difference-between-driver-and-webdriver-python-selenium",
            "title": "What is the difference between Driver and Webdriver (python selenium)?"
        },
        {
            "tags": [
                "python",
                "import",
                "package",
                "structure",
                "init"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 17338337,
                        "reputation": 21,
                        "user_id": 12559692,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a-/AAuE7mBk9B4K1QoATJFOTbdjdmx7YK33x_bZK6GeLmUo=k-s256",
                        "display_name": "rajaa lebchiri",
                        "link": "https://stackoverflow.com/users/12559692/rajaa-lebchiri"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709046882,
                    "answer_id": 78068595,
                    "question_id": 78068510,
                    "body_markdown": "include it in your __init__.py file\r\n\r\n    from .package import *",
                    "title": "How to relative import a package create by me using python and strucure it better?"
                }
            ],
            "owner": {
                "account_id": 15263660,
                "reputation": 13,
                "user_id": 11012969,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/8dc34bc9eedcf5b4b502e7820041d671?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "andguez",
                "link": "https://stackoverflow.com/users/11012969/andguez"
            },
            "is_answered": false,
            "view_count": 22,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709046083,
            "question_id": 78068510,
            "body_markdown": "Hi I&#39;m creating a package/Module (hysysview), I have created some tests so that I can test the packages, therefore I need to import the module, however, I&#39;m getting this error when I import HysysCOM.py in testHysys.py\r\n\r\n**Importing in testHysys**\r\n\r\n    import sys\r\n    import os\r\n    from hysysview.HysysCOM import HysysReader\r\n    from enum import Enum\r\n\r\n**Error:**\r\n\r\n     line 3, in &lt;module&gt;\r\n        from ..hysysview.HysysCOM import HysysReader\r\n    ImportError: attempted relative import with no known parent package\r\n\r\n**Folder tree**\r\n\r\n```\r\n |-hysysview\r\n | |-HysysCOM.py\r\n | |-HysysOperations.py\r\n | |-HysysOperations_backup.py\r\n | |-HysysVariables.py\r\n | |-missingOperation.txt\r\n | |-__init__.py\r\n | |-__pycache__\r\n |-requirements.txt\r\n |-setup.py\r\n |-test\r\n | |-sampleApp\r\n | |-stored\r\n | |-test7.bat\r\n | |-test7.txt\r\n | |-test8.bat\r\n | |-test9.bat\r\n | |-testHysys.py\r\n | |-__init__.py\r\n```\r\nTried to solve this issue using a setup.py file but I&#39;m not very familiar with it!\r\n\r\nif someone can give me some advice about how to solve this issue and also structure my packages better will be welcome\r\n\r\nThanks you in advance\r\n",
            "link": "https://stackoverflow.com/questions/78068510/how-to-relative-import-a-package-create-by-me-using-python-and-strucure-it-bette",
            "title": "How to relative import a package create by me using python and strucure it better?"
        },
        {
            "tags": [
                "python",
                "tkinter",
                "treeview",
                "pyodbc"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30024600,
                        "reputation": 11,
                        "user_id": 23009165,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKp6m4U2oPWziWKl3nPy6U5Z8a-YI3NbAN8ntuTdWoX=k-s256",
                        "display_name": "Manu Sanchez",
                        "link": "https://stackoverflow.com/users/23009165/manu-sanchez"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709047884,
                    "answer_id": 78068709,
                    "question_id": 78068475,
                    "body_markdown": "I haven&#39;t used pyodbc, but as it seems in the picture you attached, you&#39;re inserting directly the result that you&#39;re retrieving from pyodbc.\r\n\r\nIn this case I&#39;ll recommend you to first unpack the values into different variables (as you&#39;re starting to use python) and then insert them in your treeview.\r\n\r\nIf your result variable contains a tuple like: (&#39;Dale&#39;, &#39;Doe&#39;, &#39;XXXXXX&#39;), just try doing the following:\r\n\r\n    for row in results:\r\n        first_name, last_name, phone_number = row\r\n        tree.insert(parent=&#39;&#39;, index=0, values=[first_name, last_name, phone_number])\r\n    \r\nThis is a little bit overkilling but as I told you, if you&#39;re not so much confident with python It can give you at least an idea of one of the most relevant feature, the packing, unpacking variables.\r\n\r\nSomething very important is that this will work if your rows are actually tuples, you can simply check this executing this:\r\n\r\n    print(type(row))\r\n\r\nBy the way in the worst case, if the actual type is not a tuple or it&#39;s a string you can go over two ways, I haven&#39;t worked with pyodbc, but mainly all the database frameworks work pretty simmilar, and I&#39;m very confident that if you make a little bit of research, you will find some kind of cursor to get a better formatted rows, or at least more suitable with what you want.\r\n\r\nBy the way, in the worst of the scenarios, if the row is an string like &quot;(&#39;Dale&#39;, &#39;Doe&#39;, &#39;XXXXXX&#39;)&quot; you can apply the following transformations to clean the string, at least to just start practising.\r\n\r\n    row = &quot;(&#39;Dale&#39;, &#39;Doe&#39;, &#39;XXXXXX&#39;)&quot;\r\n    first_name, last_name, phone_number = row.replace(&quot;(&quot;, &quot;&quot;).replace(&quot;)&quot;, &quot;&quot;).replace(&quot;&#39;&quot;, &quot;&quot;).split(&quot;,&quot;)\r\n\r\nHope it can help you :).\r\nHappy Codding.\r\n    \r\n\r\n\r\n",
                    "title": "Remove Quotes and Brackets from SQL Query in Python tkinter Treeview"
                }
            ],
            "owner": {
                "account_id": 24444200,
                "reputation": 1,
                "user_id": 18367430,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/f379bc0bea7e1377b08521bf92c6dba7?s=256&d=identicon&r=PG",
                "display_name": "user18367430",
                "link": "https://stackoverflow.com/users/18367430/user18367430"
            },
            "is_answered": true,
            "view_count": 46,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -3,
            "creation_date": 1709045750,
            "question_id": 78068475,
            "body_markdown": "I am wanting to clean up the formatting of a query result in a window that&#39;s been created using Treeview in tkinter (image attached) \r\n\r\n[Output Sample][1]\r\n\r\nSQL query uses pyodbc and the relevant python bits are:\r\n\r\n        \r\n        conn = pyodbc.connect(conn_str)\r\n        cursor = conn.cursor()\r\n        \r\n        # Use parameterized query to avoid SQL injection\r\n        cursor.execute(&#39;&#39;&#39;\r\n        SELECT First_Name,Name,Phone_1 FROM [Archive].[dbo].[Client_Tbl]\r\n        WHERE [Archive].[dbo].[Client_Tbl].First_Name = ? OR [Archive].[dbo].\r\n        [Client_Tbl].Name = ? OR [Archive].[dbo].[Client_Tbl].Phone_1 = ?\r\n        &#39;&#39;&#39;, first_name, last_name, phone_number)\r\n        result = cursor.fetchall()\r\n        cursor.close()\r\n        conn.close()\r\n        return result\r\n        \r\n        ....\r\n\r\n        # Function to update the Treeview with query results\r\n        def display_results(results):\r\n        for i in tree.get_children():\r\n        tree.delete(i)  # Clear existing entries in the treeview\r\n        for row in results:\r\n        tree.insert(&#39;&#39;, &#39;end&#39;, values=row)  # Insert new entries into the \r\n        treeview\r\n\r\n        .....\r\n        \r\n        # Results display (Treeview)\r\n\tcolumns = (&#39;First Name&#39;, &#39;Last Name&#39;, &#39;Phone Number&#39;)\r\n\ttree = ttk.Treeview(frame, columns=columns, show=&#39;headings&#39;)\r\n\ttree.heading(&#39;First Name&#39;, text=&#39;First Name&#39;)\r\n\ttree.heading(&#39;Last Name&#39;, text=&#39;Last Name&#39;)\r\n\ttree.heading(&#39;Phone Number&#39;, text=&#39;Phone Number&#39;)\r\n\t\r\n\ttree.grid(row=3, column=0, sticky=&#39;nsew&#39;)\r\n\t\r\n        .....\r\n\r\n\r\nAny suggestions? \r\n        \r\n\r\nI&#39;ve tried using tuple, but I can&#39;t seem to be able to get it to work properly. (admittedly I&#39;m fairly new to Python)\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/rM90A.png",
            "link": "https://stackoverflow.com/questions/78068475/remove-quotes-and-brackets-from-sql-query-in-python-tkinter-treeview",
            "title": "Remove Quotes and Brackets from SQL Query in Python tkinter Treeview"
        },
        {
            "tags": [
                "python",
                "azure",
                "visual-studio-code",
                "azure-functions"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 300810,
                        "reputation": 436,
                        "user_id": 608177,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/194eb9f82dcaf56bcf47444a99f5f5b6?s=256&d=identicon&r=PG",
                        "display_name": "DragonBe",
                        "link": "https://stackoverflow.com/users/608177/dragonbe"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709053235,
                    "answer_id": 78069260,
                    "question_id": 78068437,
                    "body_markdown": "It looks you try to use a single function instance for different function workloads. Independent from the language you use, you need to create a single function instance per workload.\r\n\r\nExample: I have 2 workloads:\r\n\r\n1. Accept an image via HTTP Request (imgUpload)\r\n2. Resize the image for different formats (imgResize)\r\n\r\nSo, I create two Azure Function instances in a single App Service Plan with a linked storage account.\r\n\r\n    # Create App Service Plan\r\n    az functionapp plan create --name myPlan --resource-group myRG --location &quot;West Europe&quot; --sku B1\r\n\r\n    # Create storage account\r\n    az storage account create --name myStorage --location &quot;West Europe&quot; --resource-group MyRG --sku Standard_LRS\r\n\r\n    # Create imgUpload function instance\r\n    az functionapp create --name imgUpload --storage-account myStorage --plan myPlan --resource-group myRG --os-type Linux --runtime python --runtime-version &quot;3.9&quot; --functions-version 4\r\n\r\n    # Create imgResize function instance\r\n    az functionapp create --name imgResize --storage-account myStorage --plan myPlan --resource-group myRG --os-type Linux --runtime python --runtime-version &quot;3.9&quot; --functions-version 4\r\n\r\nNow I can push code for image uploading to &quot;imgUpload&quot; and code for image resizing to &quot;imgResize&quot;. If necessary I can use deployment slots for a blue-green strategy, but that&#39;s not necessary in the beginning.\r\n\r\nIf you have 10 workloads you want to run in Azure Functions, you need to create 10 different Azure Function instances.",
                    "title": "Disable overwriting of all Azure Functions using Visual Studio Code (Python)"
                }
            ],
            "owner": {
                "account_id": 21431536,
                "reputation": 81,
                "user_id": 15787852,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/c53sT.jpg?s=256&g=1",
                "display_name": "Olgaraa",
                "link": "https://stackoverflow.com/users/15787852/olgaraa"
            },
            "is_answered": false,
            "view_count": 23,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709045349,
            "question_id": 78068437,
            "body_markdown": "I know that this question has been asked a lot, but I still haven&#39;t managed to find a satisfying solution. At my project we have a Python Function App and we would like to be able to deploy functions from different computers (ergo different local projects) without overwriting the existing functions. For the time being, each time we deploy something to the existing Function App, we get the following message:\r\n```\r\nAre you sure you want to deploy to &quot;functionapp&quot;? This will overwrite any previous deployment and cannot be undone.\r\n```\r\nAnd obviously - if we click on OK, the existing functions are getting overwritten.\r\nPeople suggest to create a new Function App for each function, but this is not possible, as we don&#39;t have the permissions to deploy any new resources on our own and requesting one each time, would simply take ages. Isn&#39;t there any other way to do that? Since the Python one can&#39;t be developed in the Portal, how are we supposed to create new functions from different computers, without overwriting the existing ones? Are you using any workarounds (Azure DevOps etc.)? Please advise.",
            "link": "https://stackoverflow.com/questions/78068437/disable-overwriting-of-all-azure-functions-using-visual-studio-code-python",
            "title": "Disable overwriting of all Azure Functions using Visual Studio Code (Python)"
        },
        {
            "tags": [
                "python",
                "macos",
                "dependencies"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 1479953,
                        "reputation": 195,
                        "user_id": 2311915,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/3893423fdf624b685528cd6a0f155d23?s=256&d=identicon&r=PG",
                        "display_name": "autopoietic",
                        "link": "https://stackoverflow.com/users/2311915/autopoietic"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709046475,
                    "answer_id": 78068552,
                    "question_id": 78068410,
                    "body_markdown": "This [pipdeptree][1] package is really helpful to see what is happening with your dependencies:\r\n\r\n`pip install pipdeptree`\r\n\r\nto run it once installed:\r\n\r\n`pipdeptree`\r\n\r\nHere is an example output:\r\n\r\n```\r\nDjango==5.0.2\r\n\u251c\u2500\u2500 asgiref [required: &gt;=3.7.0,&lt;4, installed: 3.7.2]\r\n\u2514\u2500\u2500 sqlparse [required: &gt;=0.3.1, installed: 0.4.4]\r\npip==23.2.1\r\npipdeptree==2.15.1\r\npygame==2.5.2\r\n```\r\n\r\nYou can see that Django depends on some other packages, but in fact `pygame` does not. If your version of pygame also has no dependencies then you should be safe to just:\r\n\r\n`pip uninstall pygame &amp;&amp; pip uninstall pipdeptree`\r\n\r\n\r\n  [1]: https://pypi.org/project/pipdeptree/",
                    "title": "How to remove user installed packages from system Python on macOS Sonoma safely?"
                }
            ],
            "owner": {
                "account_id": 12710636,
                "reputation": 23,
                "user_id": 9306370,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/bd759aad78d616cd9bfefc076754ec6b?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "irudnyts",
                "link": "https://stackoverflow.com/users/9306370/irudnyts"
            },
            "is_answered": true,
            "view_count": 15,
            "favorite_count": 0,
            "accepted_answer_id": 78068552,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709045087,
            "question_id": 78068410,
            "body_markdown": "I have accidentally installed Pygame for my system-wide Python (i.e., using `pip3` which has path `/usr/bin/pip3`). I have read somewhere that it is a good practice to keep system Python clean. I want to remove Pygame and all of its dependencies from my system Python. How can I do that safely? \r\n\r\nI find this solution `pip3 freeze &gt; to_delete.txt` and `pip3 uninstall -y -r to_delete.txt`, but I am afraid to accidentally remove packages that are actually needed by system (like perhaps `macholib` which is in my `to_delete.txt`). \r\n\r\nIs there a way to remove only user-installed packages from system Python on macOS safely? ",
            "link": "https://stackoverflow.com/questions/78068410/how-to-remove-user-installed-packages-from-system-python-on-macos-sonoma-safely",
            "title": "How to remove user installed packages from system Python on macOS Sonoma safely?"
        },
        {
            "tags": [
                "python",
                "networkx"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 6262892,
                        "reputation": 44,
                        "user_id": 4869496,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/YOs5W.jpg?s=256&g=1",
                        "display_name": "Michael K",
                        "link": "https://stackoverflow.com/users/4869496/michael-k"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709043656,
                    "answer_id": 78068259,
                    "question_id": 78068231,
                    "body_markdown": "You have a typo in your code - you&#39;ve named the variable &#39;shells&#39;, but you&#39;re trying to access it using &#39;k_shells&#39;.\r\n\r\nChange your code to this:\r\n\r\n\r\n    import networkx as nx\r\n    \r\n    # Create a digraph\r\n    G = nx.DiGraph()\r\n    G.add_edge(1, 2, weight=673)\r\n    G.add_edge(2, 4, weight=201)\r\n    G.add_edge(4, 1, weight=20)\r\n    G.add_edge(2, 3, weight=96)\r\n    G.add_edge(3, 4, weight=44)\r\n    G.add_edge(6, 3, weight=7)\r\n    G.add_edge(6, 4, weight=96)\r\n    G.add_edge(5, 6, weight=10)\r\n    G.add_edge(7, 6, weight=10)\r\n    G.add_edge(8, 6, weight=10)\r\n    \r\n    # Calculate k-shells\r\n    k_shells = nx.algorithms.core.k_shell(G)\r\n    \r\n    # Find the maximum k-shell value\r\n    max_k_shell = max(k_shells)\r\n    \r\n    # Get the nodes in the most inner core\r\n    inner_core_nodes = k_shells[max_k_shell]\r\n    \r\n    # Print the nodes in the most inner core\r\n    print(inner_core_nodes)\r\n\r\n",
                    "title": "Nodes in the most inner core of K-shell in Networkx"
                },
                {
                    "owner": {
                        "account_id": 22084389,
                        "reputation": 223378,
                        "user_id": 16343464,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/7kTic.png?s=256&g=1",
                        "display_name": "mozway",
                        "link": "https://stackoverflow.com/users/16343464/mozway"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709047221,
                    "answer_id": 78068641,
                    "question_id": 78068231,
                    "body_markdown": "[`k_shell`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.core.k_shell.html) returns a subgraph.\r\n\r\nIf you don&#39;t provide a value for `k`, then the outer shell is returned (which corresponds to the nodes of highest degree), you can also use [`k_core`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.core.k_core.html#networkx.algorithms.core.k_core) (those two are equivalent for `k=None` since there is no nodes of higher degree):\r\n```\r\nH = nx.k_shell(G)\r\n# or \r\nH = nx.k_core(G)\r\n\r\nH.nodes\r\n# NodeView((1, 2, 4, 3, 6))\r\n```\r\n\r\nNote that you could also use [`core_number`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.core.core_number.html#networkx.algorithms.core.core_number) to get the core numbers and manually filter those:\r\n```\r\nd = nx.core_number(G)\r\nmax_degree = max(d.values())\r\n\r\nnodes = {k for k, v in d.items() if v == max_degree}\r\n```\r\nOutput: `{1, 2, 3, 4, 6}`",
                    "title": "Nodes in the most inner core of K-shell in Networkx"
                }
            ],
            "owner": {
                "account_id": 21458866,
                "reputation": 43,
                "user_id": 16508241,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/MFdlP.png?s=256&g=1",
                "display_name": "Math Universe",
                "link": "https://stackoverflow.com/users/16508241/math-universe"
            },
            "is_answered": false,
            "view_count": 33,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 1,
            "creation_date": 1709043430,
            "question_id": 78068231,
            "body_markdown": "I want to obtain nodes in the most inner core of the k-shell algorithm corresponding to the highest degree using NetworkX in Python. I tried to get the nodes using the following code but I encountered the error &quot;AttributeError: &#39;DiGraph&#39; object has no attribute &#39;keys&#39;&quot; \r\n\r\n```python\r\n# Create a digraph\r\nG = nx.DiGraph()\r\nG.add_edge(1,2,weight=673)  \r\nG.add_edge(2,4,weight=201)  \r\nG.add_edge(4,1,weight=20)  \r\nG.add_edge(2,3,weight=96)  \r\nG.add_edge(3,4,weight=44)  \r\nG.add_edge(6,3,weight=7)  \r\nG.add_edge(6,4,weight=96)  \r\nG.add_edge(5,6,weight=10)  \r\nG.add_edge(7,6,weight=10)  \r\nG.add_edge(8,6,weight=10)  \r\n\r\n# Calculate k-shells\r\nshells = nx.algorithms.core.k_shell(g)\r\n\r\n# Find the maximum k-shell value\r\nmax_k_shell = max(k_shells.keys())\r\n\r\n# Get the nodes in the most inner core\r\ninner_core_nodes = k_shells[max_k_shell]\r\n\r\n# Print the nodes in the most inner core\r\nprint(inner_core_nodes)\r\n\r\n```\r\n",
            "link": "https://stackoverflow.com/questions/78068231/nodes-in-the-most-inner-core-of-k-shell-in-networkx",
            "title": "Nodes in the most inner core of K-shell in Networkx"
        },
        {
            "tags": [
                "python",
                "solana",
                "solana-transaction-instruction"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 4247916,
                        "reputation": 11,
                        "user_id": 3475995,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/f955aa7a1be1ff3c3be15f5b88975a60?s=256&d=identicon&r=PG",
                        "display_name": "Amir Abdollahi",
                        "link": "https://stackoverflow.com/users/3475995/amir-abdollahi"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709047801,
                    "answer_id": 78068698,
                    "question_id": 78068182,
                    "body_markdown": "I haven&#39;t used Solana myself, but this is what I found, hope it helps :)\r\n\r\n    from solana.rpc.async_api import AsyncClient\r\n    from spl.token.instructions import decode_transfer\r\n\r\n    async def main():\r\n        async with AsyncClient(&quot;https://api.mainnet-beta.solana.com&quot;) as client:\r\n            decoded_transfer = decode_transfer(instruction_data)\r\n            print(decoded_transfer)",
                    "title": "AsyncClient object has no attribute decode_transfer - solana.py"
                }
            ],
            "owner": {
                "account_id": 20024302,
                "reputation": 1,
                "user_id": 15687313,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/5b34f6d3fb566efd91c1a3c167aa197b?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "wolfaw",
                "link": "https://stackoverflow.com/users/15687313/wolfaw"
            },
            "is_answered": false,
            "view_count": 18,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709043024,
            "question_id": 78068182,
            "body_markdown": "I&#39;m trying to get the instruction data in solana.py.. \r\n\r\nhttps://michaelhly.com/solana-py/rpc/async_api/#solana.rpc.async_api.AsyncClient\r\n\r\nI use the above page in my program and work on the necessary details. Anyway I need some details from the &quot;instruction data&quot; so I&#39;m reading this docs, \r\n\r\nhttps://michaelhly.com/solana-py/spl/token/instructions/#spl.token.instructions.decode_transfer \r\n\r\nWhen I try to work on the below code, \r\n\r\n\r\n```\r\nasync def main():\r\n    async with AsyncClient(&quot;https://api.mainnet-beta.solana.com&quot;) as client:\r\n        v_a = (await client.decode_transfer(instruction)).value\r\n        print(v_a)\r\n```\r\n\r\nIt say AttributeError:\r\n\r\n    &#39;AsyncClient&#39; object has no attribute &#39;decode_transfer&#39;\r\n\r\nCan anyone help me and say what am I doing wrong here?  \r\n\r\n\r\nI tried to work on adding different import statements by reading the documentation and i cannot solve the problem..I want to get the details of the instruction data and get the &quot;amount in&quot; value..thanks in advance for any help!",
            "link": "https://stackoverflow.com/questions/78068182/asyncclient-object-has-no-attribute-decode-transfer-solana-py",
            "title": "AsyncClient object has no attribute decode_transfer - solana.py"
        },
        {
            "tags": [
                "python",
                "python-3.x",
                "python-imaging-library"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 14247854,
                        "reputation": 5158,
                        "user_id": 10292330,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/u5G8t.png?s=256&g=1",
                        "display_name": "OysterShucker",
                        "link": "https://stackoverflow.com/users/10292330/oystershucker"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709056630,
                    "answer_id": 78069614,
                    "question_id": 78068140,
                    "body_markdown": "You are almost there. The problem is that the frame needs to be converted to &quot;RGBA&quot; first.\r\n\r\nConsider that the avatar does not need a mask or an alpha channel. You are just pasting a solid image on the canvas image. It&#39;s the frame that needs attention in these regards.\r\n\r\n```python3\r\nfrom PIL import Image\r\n\r\n# fill a new image with fully transparent black\r\nimage = Image.new(&quot;RGBA&quot;, (512,512), &quot;#00000000&quot;)\r\n\r\n# you don&#39;t have to worry about an alpha channel or a mask for the avatar\r\nimage.paste(Image.open(f&quot;back.jpg&quot;), (80, 85))\r\n\r\n# convert the frame to RGBA so it&#39;s alpha channel can be used as a proper mask\r\nframe = Image.open(f&quot;front.png&quot;).convert(&#39;RGBA&#39;)\r\nimage.paste(frame, (0, 0), frame)\r\n\r\nimage.show()\r\n```\r\n\r\nThe background is white because the background of Windows Photo Viewer is white, and this image is a screen capture. The background is transparent.\r\n\r\n\r\n[![enter image description here][1]][1]\r\n\r\n\r\nAside: I&#39;m not familiar with most of PIL, and it actually took numerous attempts to get this correct. Even the data that I found that [directly shows you how to do this](https://www.tutorialspoint.com/how-to-merge-a-transparent-png-image-with-another-image-using-pil) is wrong (probably based on an older PIL). [This](https://www.geeksforgeeks.org/how-to-merge-a-transparent-png-image-with-another-image-using-pil/) may have been helpful if I would have considered it differently, but it isn&#39;t trying to do the exact same thing, and the slight difference threw me off. Eventually, it was [this post](https://stackoverflow.com/a/42232793/10292330) that finally gave me the information that I needed. It was that post that made it clear that, regardless of it being a `.png`, it still needs to be converted to `RGBA` mode.\r\n\r\n  [1]: https://i.stack.imgur.com/qGY6i.png",
                    "title": "Make one image out of avatar and frame in Python with Pillow"
                }
            ],
            "owner": {
                "account_id": 22067082,
                "reputation": 13,
                "user_id": 16328788,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a-/AOh14GiBrm1AP3bivx7pJMSQPnQgy4jBHP3LotREJx4E=k-s256",
                "display_name": "Rogtiz",
                "link": "https://stackoverflow.com/users/16328788/rogtiz"
            },
            "is_answered": false,
            "view_count": 43,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709042671,
            "question_id": 78068140,
            "body_markdown": "If I have \r\n\r\n[![enter image description here](https://i.stack.imgur.com/X4Gn9.jpg)](https://i.stack.imgur.com/X4Gn9.jpg)\r\n\r\nand\r\n\r\n[![enter image description here](https://i.stack.imgur.com/URruC.png)](https://i.stack.imgur.com/URruC.png)\r\n\r\nneed to get\r\n\r\n[![enter image description here](https://i.stack.imgur.com/o2luP.png)](https://i.stack.imgur.com/o2luP.png)\r\n\r\n\r\n\r\n```\r\ndef create_avatar(username):\r\n    avatar, frame, avatar_id = get_avatar(username)\r\n    if avatar is not None and frame is not None:\r\n        try:\r\n            image = Image.new(&quot;RGBA&quot;, size)\r\n            image.putalpha(0)\r\n\r\n            # Paste avatar onto background with positioning offset\r\n            image.paste(avatar, (157, 160), avatar)\r\n            # image.save(&#39;DEBUG-avatar-pasted.png&#39;)\r\n\r\n            # Paste frame over avatar and background retaining transarency\r\n            image.paste(frame, (0, 0), frame)\r\n        except Exception as e:\r\n            print(e)\r\n            image = Image.open(&quot;images/unknown_avatar.png&quot;).resize((512, 512))\r\n    elif avatar is not None:\r\n        image = Image.open(f&quot;images/{avatar_id}.png&quot;).resize((512, 512))\r\n    else:\r\n        image = Image.open(&quot;images/unknown_avatar.png&quot;).resize((512, 512))\r\n\r\n    image.save(f&#39;images/{username}.png&#39;, format=&#39;png&#39;)\r\n```\r\n\r\nI have a problem with Bad transperancy mask, but need to do that\r\n\r\nOutput image sizes needs to be 512x512\r\n",
            "link": "https://stackoverflow.com/questions/78068140/make-one-image-out-of-avatar-and-frame-in-python-with-pillow",
            "title": "Make one image out of avatar and frame in Python with Pillow"
        },
        {
            "tags": [
                "python",
                "pandas",
                "dataframe",
                "isin"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 6996016,
                        "reputation": 7336,
                        "user_id": 5363686,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/BdgYs.jpg?s=256&g=1",
                        "display_name": "Serge de Gosson de Varennes",
                        "link": "https://stackoverflow.com/users/5363686/serge-de-gosson-de-varennes"
                    },
                    "is_accepted": false,
                    "score": 4,
                    "creation_date": 1709043189,
                    "answer_id": 78068205,
                    "question_id": 78068133,
                    "body_markdown": "You cona use ``` apply()``` theis way:\r\n\r\n```\r\nimport pandas as pd\r\n\r\nmydataset = [{&quot;name&quot;: &quot;test&quot;, &quot;values&quot;: [&quot;3&quot;, &quot;7&quot;, &quot;2&quot;]}, {&quot;name&quot;: &quot;test2&quot;, &quot;values&quot;: [&quot;4&quot;, &quot;1&quot;, &quot;7&quot;]}]\r\nmyvar = pd.DataFrame.from_records(mydataset)\r\n\r\nfiltered_data = myvar[myvar[&quot;values&quot;].apply(lambda x: &quot;3&quot; in x)]\r\nprint(filtered_data)\r\n```\r\n\r\nwhich gives\r\n\r\n```\r\n   name     values\r\n0  test  [3, 7, 2]\r\n```",
                    "title": "Dataframe isin() on list of dicts which have list as property value"
                },
                {
                    "owner": {
                        "account_id": 22084389,
                        "reputation": 223378,
                        "user_id": 16343464,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/7kTic.png?s=256&g=1",
                        "display_name": "mozway",
                        "link": "https://stackoverflow.com/users/16343464/mozway"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709043195,
                    "answer_id": 78068206,
                    "question_id": 78068133,
                    "body_markdown": "You have to loop over the values.\r\n\r\nIf you have a single target:\r\n```\r\ntarget = &#39;3&#39;\r\n\r\nout = myvar[[any(val == target for val in l) for l in myvar[&#39;values&#39;]]]\r\n```\r\nOr, if you want to match several values (all of the targets):\r\n```\r\ntarget = {&#39;3&#39;, &#39;7&#39;}\r\n\r\nout = myvar[[target.issubset(l) for l in myvar[&#39;values&#39;]]]\r\n```\r\nany of the targets:\r\n```\r\ntarget = {&#39;3&#39;, &#39;10&#39;}\r\n\r\nout = myvar[[bool(target.intersection(l)) for l in myvar[&#39;values&#39;]]]\r\n```\r\nOutput:\r\n```\r\n   name     values\r\n0  test  [3, 7, 2]\r\n```",
                    "title": "Dataframe isin() on list of dicts which have list as property value"
                }
            ],
            "owner": {
                "account_id": 30643143,
                "reputation": 11,
                "user_id": 23491159,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocIjKMntFZNkP_Ae528m1cJI_f-aq-kk0S7woY4fG1F3=k-s256",
                "display_name": "Jo B",
                "link": "https://stackoverflow.com/users/23491159/jo-b"
            },
            "is_answered": true,
            "view_count": 59,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 1,
            "creation_date": 1709042610,
            "question_id": 78068133,
            "body_markdown": "i want to get the objects which contain a certain value stored in their property list &quot;value&quot; in this case.\r\n\r\n\r\n```\r\nimport pandas as pd\r\n\r\nmydataset = [{&quot;name&quot;: &quot;test&quot;, &quot;values&quot;: [&quot;3&quot;, &quot;7&quot;, &quot;2&quot;]}, {&quot;name&quot;: &quot;test2&quot;, &quot;values&quot;: [&quot;4&quot;, &quot;1&quot;, &quot;7&quot;]}]\r\n\r\nmyvar = pd.DataFrame.from_records(mydataset)\r\n\r\nprint(myvar[myvar[&quot;values&quot;].isin([&quot;3&quot;])])\r\n```\r\nThis codes gives an empty dataframe back.\r\n\r\n\r\nIf i initialize the dataframe with single object it works. How can i filter them when the list is a property value?",
            "link": "https://stackoverflow.com/questions/78068133/dataframe-isin-on-list-of-dicts-which-have-list-as-property-value",
            "title": "Dataframe isin() on list of dicts which have list as property value"
        },
        {
            "tags": [
                "python",
                "pydantic"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 4247916,
                        "reputation": 11,
                        "user_id": 3475995,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/f955aa7a1be1ff3c3be15f5b88975a60?s=256&d=identicon&r=PG",
                        "display_name": "Amir Abdollahi",
                        "link": "https://stackoverflow.com/users/3475995/amir-abdollahi"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709049915,
                    "answer_id": 78068919,
                    "question_id": 78068080,
                    "body_markdown": "Based on the two examples you provided (also as mentioned in the comments), I would suggest using different models.\r\n\r\nBut if you want to make any key optional in your model, you can use `Optional` from `typing`. Remember to set the default value for any optional key.\r\n\r\n    from typing import Optional\r\n    from pydantic import BaseModel\r\n\r\n    class TestModel(BaseModel):\r\n        type: str\r\n        url: Optional[str] = None\r\n",
                    "title": "how to handle if root level keys are dynamic in pydantic"
                },
                {
                    "owner": {
                        "account_id": 8260894,
                        "reputation": 2799,
                        "user_id": 6212350,
                        "user_type": "registered",
                        "accept_rate": 70,
                        "profile_image": "https://i.stack.imgur.com/qXnGn.jpg?s=256&g=1",
                        "display_name": "TheHungryCub",
                        "link": "https://stackoverflow.com/users/6212350/thehungrycub"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709050474,
                    "answer_id": 78068988,
                    "question_id": 78068080,
                    "body_markdown": "You can create a Pydantic model using Pydantic\u2019s Union and create_model functions to handle the dynamic keys based on the type field.\r\n\r\n    from typing import Union\r\n    from pydantic import BaseModel, create_model\r\n\r\n    # Define models for each type\r\n    class PostgresConfig(BaseModel):\r\n        type: str = &quot;postgres&quot;\r\n        host: str\r\n        id: str\r\n\r\n    class WebUrlConfig(BaseModel):\r\n        type: str = &quot;weburl&quot;\r\n        url: str\r\n\r\n    # Create a model dynamically based on the type field\r\n    def DynamicConfigType(type: str) -&gt; Union[PostgresConfig, WebUrlConfig]:\r\n        if type == &quot;postgres&quot;:\r\n            return PostgresConfig\r\n        elif type == &quot;weburl&quot;:\r\n            return WebUrlConfig\r\n        else:\r\n            raise ValueError(&quot;Invalid config type&quot;)\r\n\r\n    # Usage example:\r\n    data = {\r\n        &quot;type&quot;: &quot;postgres&quot;,\r\n        &quot;host&quot;: &quot;test&quot;,\r\n        &quot;id&quot;: &quot;88c8fo90&quot;\r\n    }\r\n\r\n    # Determine the model dynamically based on the &#39;type&#39; field\r\n    ConfigModel = DynamicConfigType(data[&quot;type&quot;])\r\n    config = ConfigModel(**data)\r\n    print(config)\r\n",
                    "title": "how to handle if root level keys are dynamic in pydantic"
                }
            ],
            "owner": {
                "account_id": 12570661,
                "reputation": 628,
                "user_id": 10927050,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/5f5550c8c6a21c5f2baeb5e3d1c726f7?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Prajna",
                "link": "https://stackoverflow.com/users/10927050/prajna"
            },
            "is_answered": false,
            "view_count": 36,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 0,
            "creation_date": 1709042226,
            "question_id": 78068080,
            "body_markdown": "    {\r\n          &quot;type&quot;: &quot;thirdparty&quot;,\r\n          &quot;key&quot;: &quot;postgres&quot;,\r\n          &quot;host&quot;: &quot;test&quot;,\r\n          &quot;id&quot;: &quot;88c8fo90&quot;\r\n    }\r\n\r\nor \r\n\r\n    {\r\n          &quot;type&quot;: &quot;weburl&quot;,\r\n          &quot;url&quot;: &quot;https://www.google.com&quot;\r\n    }\r\n\r\n\r\nHere the keys are changing based on type, how do I add a pydantic model for this?",
            "link": "https://stackoverflow.com/questions/78068080/how-to-handle-if-root-level-keys-are-dynamic-in-pydantic",
            "title": "how to handle if root level keys are dynamic in pydantic"
        },
        {
            "tags": [
                "python",
                "python-importlib"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 208953,
                        "reputation": 39029,
                        "user_id": 459745,
                        "user_type": "registered",
                        "accept_rate": 82,
                        "profile_image": "https://www.gravatar.com/avatar/08a2c6f16c0d4dad20d169d9d76848ac?s=256&d=identicon&r=PG",
                        "display_name": "Hai Vu",
                        "link": "https://stackoverflow.com/users/459745/hai-vu"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709054228,
                    "answer_id": 78069363,
                    "question_id": 78068060,
                    "body_markdown": "My guess is the Python interpreter determines which directories should be in the &quot;import path&quot; before hand and `os.chdir()` could not change that fact. A work-around is to fix up the import path (`sys.path`) before importing:\r\n\r\n```python\r\nimport pathlib\r\nimport sys\r\nimport tempfile\r\nfrom importlib import import_module\r\n\r\nBAR = &quot;&quot;&quot;\r\ndef bar():\r\n    print(&quot;this is bar&quot;)\r\n&quot;&quot;&quot;\r\n\r\nwith tempfile.TemporaryDirectory() as temp_dir:\r\n    # Create the package\r\n    tmp_dir = pathlib.Path(temp_dir)\r\n    (tmp_dir / &quot;foo&quot;).mkdir()\r\n    (tmp_dir / &quot;foo&quot; / &quot;__init__.py&quot;).write_text(BAR)\r\n\r\n    # Fix up the import path and import\r\n    sys.path.append(temp_dir)\r\n    foo = import_module(&quot;foo&quot;)\r\n    foo.bar()\r\n    sys.path.remove(temp_dir)\r\n```",
                    "title": "`importlib.import_module` not finding module in working directory"
                }
            ],
            "owner": {
                "account_id": 3127998,
                "reputation": 5795,
                "user_id": 2646505,
                "user_type": "registered",
                "accept_rate": 91,
                "profile_image": "https://i.stack.imgur.com/XGEyF.jpg?s=256&g=1",
                "display_name": "Tom de Geus",
                "link": "https://stackoverflow.com/users/2646505/tom-de-geus"
            },
            "is_answered": false,
            "view_count": 31,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709042021,
            "question_id": 78068060,
            "body_markdown": "I would like to import from the current working directory.\r\nFor example:\r\n```python\r\nimport os\r\nimport pathlib\r\nimport tempfile\r\nfrom importlib import import_module\r\n\r\nwith tempfile.TemporaryDirectory() as temp_dir:\r\n    tmp_dir = pathlib.Path(temp_dir)\r\n    (tmp_dir / &quot;foo&quot;).mkdir()\r\n    (tmp_dir / &quot;foo&quot; / &quot;__init__.py&quot;).write_text(&quot;def bar(): pass&quot;)\r\n    orig = os.getcwd()\r\n    os.chdir(tmp_dir)\r\n    print(import_module(&quot;foo&quot;))\r\n    os.chdir(orig)\r\n```\r\nHowever:\r\n```\r\nTraceback (most recent call last):\r\n  File &quot;/Users/tdegeus/data/prog/src/conda_envfile/t.py&quot;, line 12, in &lt;module&gt;\r\n    print(import_module(&quot;foo&quot;))\r\n          ^^^^^^^^^^^^^^^^^^^^\r\n  File &quot;/Users/tdegeus/miniforge3/envs/pre/lib/python3.11/importlib/__init__.py&quot;, line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1204, in _gcd_import\r\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1176, in _find_and_load\r\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1140, in _find_and_load_unlocked\r\nModuleNotFoundError: No module named &#39;foo&#39;\r\n```\r\n(It does work if the directory exists prior to execution.) ",
            "link": "https://stackoverflow.com/questions/78068060/importlib-import-module-not-finding-module-in-working-directory",
            "title": "`importlib.import_module` not finding module in working directory"
        },
        {
            "tags": [
                "python",
                "pandas",
                "series",
                "valueerror",
                "cox-regression"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 6996016,
                        "reputation": 7336,
                        "user_id": 5363686,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/BdgYs.jpg?s=256&g=1",
                        "display_name": "Serge de Gosson de Varennes",
                        "link": "https://stackoverflow.com/users/5363686/serge-de-gosson-de-varennes"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709042681,
                    "answer_id": 78068142,
                    "question_id": 78068046,
                    "body_markdown": "When you use the ```fit``` method of the ```CoxPHFitter``` class, it expects the datato include all necessary columns like CHOL, sex, and age) as well as the duration and event indicator columns.You are not doing this. you can solve it this way:\r\n\r\n```\r\nfrom lifelines import CoxPHFitter\r\nimport pandas as pd\r\n\r\ndata = {\r\n    &#39;CHOL&#39;: [4.9, 4.9, 4.1, 5.6, 4.9],\r\n    &#39;sex&#39;: [1, 1, 0, 0, 0],  \r\n    &#39;age&#39;: [95, 91, 50, 79, 57],\r\n    &#39;survival_time&#39;: [20, 40, 15, 10, 30], \r\n    &#39;event_occurred&#39;: [1, 0, 1, 0, 1]\r\n}\r\n\r\ndf = pd.DataFrame(data)\r\ncoxph = CoxPHFitter()\r\ncoxph.fit(df, duration_col=&#39;survival_time&#39;, event_col=&#39;event_occurred&#39;)\r\nsummary = coxph.summary\r\nprint(summary)\r\n``` \r\n\r\nwhich gives you what you wanted:\r\n\r\n```\r\n               coef  exp(coef)   se(coef)  coef lower 95%  coef upper 95%  \\\r\ncovariate                                                                   \r\nCHOL      -1.067889   0.343734   5.069700      -11.004319        8.868542   \r\nsex       -2.123784   0.119578  15.619846      -32.738120       28.490551   \r\nage        0.059477   1.061282   0.440625       -0.804131        0.923086   \r\n\r\n           exp(coef) lower 95%  exp(coef) upper 95%  cmp to         z  \\\r\ncovariate                                                               \r\nCHOL              1.662972e-05         7.104912e+03     0.0 -0.210641   \r\nsex               6.053620e-15         2.362051e+12     0.0 -0.135967   \r\nage               4.474764e-01         2.517045e+00     0.0  0.134984   \r\n\r\n                  p  -log2(p)  \r\ncovariate                      \r\nCHOL       0.833167  0.263322  \r\nsex        0.891847  0.165131  \r\nage        0.892625  0.163874  \r\n```",
                    "title": "Survival analysis using cox returns &quot;The truth value of a Series is ambiguous.&quot;"
                }
            ],
            "owner": {
                "account_id": 26961423,
                "reputation": 55,
                "user_id": 20529049,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/6bfa2cc31b43533cd17b75fe03064420?s=256&d=identicon&r=PG",
                "display_name": "Lucy Janssens",
                "link": "https://stackoverflow.com/users/20529049/lucy-janssens"
            },
            "is_answered": true,
            "view_count": 40,
            "favorite_count": 0,
            "accepted_answer_id": 78068142,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709041834,
            "question_id": 78068046,
            "body_markdown": "So I&#39;m working with a dataset of Stroke cases from an hospital, and I would like to use Cox regression to make a survival analysis using time of arrival in the hospital, time of leave and survival or not. I have also lab data, sex, and age of the patient. processing the data is pretty straight forward but the I&#39;m trying to use lifelines CoxPHFitter and fit it to the data I get the error : &quot;ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().&quot;\r\nI will paste down here some info about the data I&#39;m using : \r\n\r\n    X.info()\r\n    X.head()\r\n\r\n    &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\r\n    RangeIndex: 4552 entries, 0 to 4551\r\n    Data columns (total 3 columns):\r\n     #   Column  Non-Null Count  Dtype  \r\n    ---  ------  --------------  -----  \r\n     0   CHOL    4552 non-null   float64\r\n     1   sex     4552 non-null   int64  \r\n     2   age     4552 non-null   int64  \r\n    dtypes: float64(1), int64(2)\r\n\r\n|   | CHOL | Sex | Age | \r\n| - | ---- | --- | --- |\r\n|0|4.9|1|95\r\n|1|4.9|1|91\r\n|2|4.1|0|50\r\n|3|5.6|0|79\r\n|4|4.9|0|57\r\n\r\nI use T and E as:\r\n\r\n    T = df[&#39;survival_time&#39;]  # Time-to-event data\r\n    E = df[&#39;event_occurred&#39;]  # Censoring indicator\r\n\r\nwhere T is leave date of the hospital - admission to the hospital date in days\r\nand E is 1 for Death as a result or 0 for survival (also tried True and False)\r\n\r\nAnd this is how I use the CoxPHfitter : \r\n\r\n    from lifelines import CoxPHFitter\r\n    \r\n    # Fit Cox proportional hazards model\r\n    coxph = CoxPHFitter()\r\n    coxph.fit(X, duration_col=T, event_col=E)\r\n    \r\n    print(coxph.summary())\r\n\r\nThe line ```coxph.fit(X, duration_col=T, event_col=E)``` generates this error : ```ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().```\r\n\r\nAnyone has an idea of why I get this error ? \r\n\r\nfull error log:\r\n\r\n    ---------------------------------------------------------------------------\r\n    ValueError                                Traceback (most recent call last)\r\n    Cell In[150], line 5\r\n          3 # Fit Cox proportional hazards model\r\n          4 coxph = CoxPHFitter()\r\n    ----&gt; 5 coxph.fit(X, duration_col=T, event_col=E)\r\n          7 print(coxph.summary())\r\n    \r\n    File ~/anaconda3/lib/python3.11/site-packages/lifelines/utils/__init__.py:56, in CensoringType.right_censoring.&lt;locals&gt;.f(model, *args, **kwargs)\r\n         53 @wraps(function)\r\n         54 def f(model, *args, **kwargs):\r\n         55     cls.set_censoring_type(model, cls.RIGHT)\r\n    ---&gt; 56     return function(model, *args, **kwargs)\r\n    \r\n    File ~/anaconda3/lib/python3.11/site-packages/lifelines/fitters/coxph_fitter.py:290, in CoxPHFitter.fit(self, df, duration_col, event_col, show_progress, initial_point, strata, weights_col, cluster_col, robust, batch_mode, timeline, formula, entry_col, fit_options)\r\n        184 &quot;&quot;&quot;\r\n        185 Fit the Cox proportional hazard model to a right-censored dataset. Alias of `fit_right_censoring`.\r\n        186 \r\n       (...)\r\n        287 \r\n        288 &quot;&quot;&quot;\r\n        289 self.strata = utils._to_list_or_singleton(utils.coalesce(strata, self.strata))\r\n    --&gt; 290 self._model = self._fit_model(\r\n        291     df,\r\n        292     duration_col,\r\n        293     event_col=event_col,\r\n        294     show_progress=show_progress,\r\n        295     initial_point=initial_point,\r\n        296     strata=self.strata,\r\n        297     weights_col=weights_col,\r\n        298     cluster_col=cluster_col,\r\n        299     robust=robust,\r\n        300     batch_mode=batch_mode,\r\n        301     timeline=timeline,\r\n        302     formula=formula,\r\n        303     entry_col=entry_col,\r\n        304     fit_options=fit_options,\r\n        305 )\r\n        306 return self\r\n    \r\n    File ~/anaconda3/lib/python3.11/site-packages/lifelines/fitters/coxph_fitter.py:610, in CoxPHFitter._fit_model(self, *args, **kwargs)\r\n        608 def _fit_model(self, *args, **kwargs):\r\n        609     if self.baseline_estimation_method == &quot;breslow&quot;:\r\n    --&gt; 610         return self._fit_model_breslow(*args, **kwargs)\r\n        611     elif self.baseline_estimation_method == &quot;spline&quot;:\r\n        612         return self._fit_model_spline(*args, **kwargs)\r\n    \r\n    File ~/anaconda3/lib/python3.11/site-packages/lifelines/fitters/coxph_fitter.py:623, in CoxPHFitter._fit_model_breslow(self, *args, **kwargs)\r\n        619 model = SemiParametricPHFitter(\r\n        620     penalizer=self.penalizer, l1_ratio=self.l1_ratio, strata=self.strata, alpha=self.alpha, label=self._label\r\n        621 )\r\n        622 if utils.CensoringType.is_right_censoring(self):\r\n    --&gt; 623     model.fit(*args, **kwargs)\r\n        624     return model\r\n        625 else:\r\n    \r\n    File ~/anaconda3/lib/python3.11/site-packages/lifelines/utils/__init__.py:56, in CensoringType.right_censoring.&lt;locals&gt;.f(model, *args, **kwargs)\r\n         53 @wraps(function)\r\n         54 def f(model, *args, **kwargs):\r\n         55     cls.set_censoring_type(model, cls.RIGHT)\r\n    ---&gt; 56     return function(model, *args, **kwargs)\r\n    \r\n    File ~/anaconda3/lib/python3.11/site-packages/lifelines/fitters/coxph_fitter.py:1229, in SemiParametricPHFitter.fit(self, df, duration_col, event_col, show_progress, initial_point, strata, weights_col, cluster_col, robust, batch_mode, timeline, formula, entry_col, fit_options)\r\n       1226 self.formula = formula\r\n       1227 self.entry_col = entry_col\r\n    -&gt; 1229 X, T, E, weights, entries, original_index, self._clusters = self._preprocess_dataframe(df)\r\n       1231 self.durations = T.copy()\r\n       1232 self.event_observed = E.copy()\r\n    \r\n    File ~/anaconda3/lib/python3.11/site-packages/lifelines/fitters/coxph_fitter.py:1305, in SemiParametricPHFitter._preprocess_dataframe(self, df)\r\n       1303     df = df.set_index(self.strata)\r\n       1304 else:\r\n    -&gt; 1305     sort_by = [self.duration_col, self.event_col] if self.event_col else [self.duration_col]\r\n       1306     df = df.sort_values(by=sort_by)\r\n       1307     original_index = df.index.copy()\r\n    \r\n    File ~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:1527, in NDFrame.__nonzero__(self)\r\n       1525 @final\r\n       1526 def __nonzero__(self) -&gt; NoReturn:\r\n    -&gt; 1527     raise ValueError(\r\n       1528         f&quot;The truth value of a {type(self).__name__} is ambiguous. &quot;\r\n       1529         &quot;Use a.empty, a.bool(), a.item(), a.any() or a.all().&quot;\r\n       1530     )\r\n    \r\n    ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
            "link": "https://stackoverflow.com/questions/78068046/survival-analysis-using-cox-returns-the-truth-value-of-a-series-is-ambiguous",
            "title": "Survival analysis using cox returns &quot;The truth value of a Series is ambiguous.&quot;"
        },
        {
            "tags": [
                "python",
                "alignment",
                "dijkstra"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30408340,
                        "reputation": 43,
                        "user_id": 23303062,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocLdf1e6EoHhliH89J6Db2rjcqYVffKKKLYzx-36YuCc=k-s256",
                        "display_name": "Abaiz",
                        "link": "https://stackoverflow.com/users/23303062/abaiz"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709042032,
                    "answer_id": 78068061,
                    "question_id": 78068026,
                    "body_markdown": "I think the &quot;pm4py.algo.conformance.alignments.petri_net.variants.dijkstra_less_memory.apply &quot; function integrates the Dijkstra algorithm, which is intended to identify a single optimal alignment between a trace and a Petri net model and It isn&#39;t meant to offer every ideal alignment directly.\r\nYou may need to investigate alternative methods or expand the current ones in order to enable this feature if you must work with the PM4Py library and need to be able to extract all optimal alignments straight from the library. As an alternative, you can discover and return all alignments with the same cost as the best alignment by post-processing the Dijkstra algorithm results.",
                    "title": "How to find all optimal alignments with dijkstra"
                }
            ],
            "owner": {
                "account_id": 30642023,
                "reputation": 1,
                "user_id": 23490245,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocK6-B87KMS_2V1WnaIE7EOK2vmWrQyqSUleHiV66kxxy6U=k-s256",
                "display_name": "Edo",
                "link": "https://stackoverflow.com/users/23490245/edo"
            },
            "is_answered": false,
            "view_count": 27,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709041637,
            "question_id": 78068026,
            "body_markdown": "i&#39;m currently trying to find all best alignments with dijkstra algorithm given a trace model and a petri net model. Right now i&#39;m using the pm4py library, precisely pm4py.algo.conformance.alignments.petri_net.variants.dijkstra_less_memory.apply which help me find one optimal alignment. Is there some way to get all optimal alignments and not the first one?\r\n\r\nI created a method that can find all best alignments without using that method and i found out two optimal alignments\r\n[This is the model](https://i.stack.imgur.com/moT2k.jpg)\r\n[This is the trace](https://i.stack.imgur.com/tmkcD.jpg)\r\n\r\nOutput with my method:\r\n\r\n 1. [(&#39;T0&#39;, &#39;T0&#39;), (&#39;T1&#39;, &#39;T1&#39;), (&#39;T2&#39;, &#39;T2&#39;), (&#39;T4&#39;, &#39;T4&#39;), (&#39;&gt;&gt;&#39;, &#39;T5&#39;), (&#39;&gt;&gt;&#39;, &#39;T7&#39;), (&#39;T6&#39;, &#39;T6&#39;), (&#39;T8&#39;, &#39;T8&#39;)]\r\n 2. [(&#39;T0&#39;, &#39;T0&#39;), (&#39;T1&#39;, &#39;T1&#39;), (&#39;T2&#39;, &#39;T2&#39;), (&#39;T4&#39;, &#39;T4&#39;), (&#39;&gt;&gt;&#39;, &#39;T5&#39;), (&#39;T6&#39;, &#39;T6&#39;), (&#39;&gt;&gt;&#39;, &#39;T7&#39;), (&#39;T8&#39;, &#39;T8&#39;)]\r\n\r\n\r\n\r\nOutput with dijkstra_less_memory.apply:\r\n\r\n 1. [(&#39;T0&#39;, &#39;T0&#39;), (&#39;T1&#39;, &#39;T1&#39;), (&#39;T2&#39;, &#39;T2&#39;), (&#39;T4&#39;, &#39;T4&#39;), (&#39;&gt;&gt;&#39;, &#39;T5&#39;), (&#39;T6&#39;, &#39;T6&#39;), (&#39;&gt;&gt;&#39;, &#39;T7&#39;), (&#39;T8&#39;, &#39;T8&#39;)]\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/78068026/how-to-find-all-optimal-alignments-with-dijkstra",
            "title": "How to find all optimal alignments with dijkstra"
        },
        {
            "tags": [
                "python",
                "html",
                "datatable",
                "hyperlink",
                "plotly-dash"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 19255478,
                        "reputation": 8536,
                        "user_id": 14072498,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/a55d298fc2cb250243c15bd619f95613?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Roar S.",
                        "link": "https://stackoverflow.com/users/14072498/roar-s"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709063590,
                    "answer_id": 78070225,
                    "question_id": 78068017,
                    "body_markdown": "If you don&#39;t mind using something simpler just to illustrate how this can be done. I added comments in the code.\r\n\r\n```\r\napp = Dash(\r\n    name=__name__\r\n)\r\n\r\n# Sample data\r\ndata = [\r\n    {&#39;Name&#39;: &#39;John&#39;, &#39;Age&#39;: 30, &#39;Website&#39;: &#39;http://example.com/john&#39;},\r\n    {&#39;Name&#39;: &#39;Alice&#39;, &#39;Age&#39;: 25, &#39;Website&#39;: &#39;http://example.com/alice&#39;},\r\n    {&#39;Name&#39;: &#39;Bob&#39;, &#39;Age&#39;: 35, &#39;Website&#39;: &#39;http://example.com/bob&#39;}\r\n]\r\n\r\n# Add a new field to the data\r\nmodified_data = [\r\n    {\r\n        **row,  # spread in existing columns\r\n        &#39;link&#39;: f&quot;[Visit {row[&#39;Name&#39;]}]({row[&#39;Website&#39;]})&quot;  # add new link column\r\n    }\r\n    for row in data\r\n]\r\n\r\n# Define columns\r\n# Note: We&#39;re using a new column called link instead of col &#39;Website&#39; in dataset\r\ncolumns = [\r\n    {&#39;name&#39;: &#39;Name&#39;, &#39;id&#39;: &#39;Name&#39;},\r\n    {&#39;name&#39;: &#39;Age&#39;, &#39;id&#39;: &#39;Age&#39;},\r\n    {&#39;name&#39;: &#39;Website&#39;, &#39;id&#39;: &#39;link&#39;, &#39;presentation&#39;: &#39;markdown&#39;}\r\n]\r\n\r\n\r\napp.layout = html.Div(\r\n    dash_table.DataTable(\r\n        data=modified_data,\r\n        columns=columns\r\n    )\r\n)\r\n```\r\n\r\nAbove code will return something like this\r\n[![enter image description here][1]][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/E18yx.png",
                    "title": "Im trying to add hyperlink in a datatable, and they just wont render, Can someone help me with it?"
                }
            ],
            "owner": {
                "account_id": 30643027,
                "reputation": 1,
                "user_id": 23491060,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJFZHOxKMBAr0JC1GzDzdiMcc9dlrYqitflZHKTI1Q8=k-s256",
                "display_name": "Kobeni",
                "link": "https://stackoverflow.com/users/23491060/kobeni"
            },
            "is_answered": false,
            "view_count": 20,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709041550,
            "question_id": 78068017,
            "body_markdown": "here, I tried to wrap a hyper link to all sys_id&#39;s present in the df using generate_links, I&#39;m trying to display them in the ui as a datatable, but it just wont render\r\n\r\n```\r\n\r\n\r\ndef generate_link(sys_id):\r\n    base_url = &#39;some_url/{sys_id}&#39;\r\n    url = base_url + sys_id\r\n    return f&#39;&lt;a href=&quot;{url}&quot;&gt; {sys_id}&lt;/a&gt;&#39;\r\n\r\n@app.callback(\r\n    Output(&#39;datatable&#39;, &#39;children&#39;),\r\n    [Input(&#39;refresh-button&#39;, &#39;n_clicks&#39;),\r\n     Input(&#39;incident-date&#39;, &#39;value&#39;)]\r\n)\r\n\r\ndef data_table(n_clicks, incident_date):\r\n    if n_clicks is not None and n_clicks &gt; 0:\r\n        \r\n        # df=get_servicenow_info()\r\n        df = pd.read_csv(&#39;/Users/unraveldata/Documents/servicenow/servicenow/assets/state2.csv&#39;)\r\n    \r\n        if incident_date == &#39;option1&#39;:  # Today\r\n            filtered_df = df[df[&#39;created_at&#39;].str.startswith(timestamp)]\r\n        elif incident_date == &#39;option2&#39;:  # Last 7 days\r\n            filtered_df = df[df[&#39;created_at&#39;] &gt;= seven_days_ago_timestamp]\r\n        elif incident_date == &#39;option3&#39;:  # Last 30 days\r\n            filtered_df = df[df[&#39;created_at&#39;] &gt;= thirty_days_ago_timestamp]\r\n            \r\n        filtered_df[&#39;sys_id&#39;] = filtered_df[&#39;sys_id&#39;].apply(generate_link)\r\n        \r\n        layout = [\r\n                dbc.Col(\r\n                children=[\r\n                    dash_table.DataTable(\r\n                        data=filtered_df.to_dict(&#39;records&#39;),\r\n                        columns=[{&quot;name&quot;: i, &quot;id&quot;: i} for i in df.columns],       \r\n                        page_action=&#39;native&#39;,    \r\n                        page_size=10,\r\n                        style_table={&#39;overflowX&#39;: &#39;auto&#39;},\r\n                        unsafe_allow_html=True,\r\n                    )\r\n                ]\r\n            )\r\n        ]\r\n        return layout\r\n\r\n```\r\n\r\nhere is the what it look like in datatable\r\n&lt;a href=&quot;some_url.do?sys_id=0852031c47e002107622b979316d4355&quot;&gt; 0852031c47e002107622b979316d4355&lt;/a&gt;\r\n",
            "link": "https://stackoverflow.com/questions/78068017/im-trying-to-add-hyperlink-in-a-datatable-and-they-just-wont-render-can-someon",
            "title": "Im trying to add hyperlink in a datatable, and they just wont render, Can someone help me with it?"
        },
        {
            "tags": [
                "python",
                "pyspark",
                "mypy"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 1143565,
                        "reputation": 510708,
                        "user_id": 1126841,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/fa05233b2357f8d11c22ef4cfc7bb85c?s=256&d=identicon&r=PG",
                        "display_name": "chepner",
                        "link": "https://stackoverflow.com/users/1126841/chepner"
                    },
                    "is_accepted": true,
                    "score": 2,
                    "creation_date": 1709042748,
                    "answer_id": 78068148,
                    "question_id": 78068011,
                    "body_markdown": "`df.select(...)` returns a value of type `Row | None`, which means the actual return value might be a `Row`, or it might be `None`. You can&#39;t index `None`, so you can&#39;t index a value of type `Row | None` until you establish that it definitely isn&#39;t `None`. (Essentially, the interface of a union type is the *intersection* of the individual types: you can only do with `A | B` what you can do to `A` *and* `B`.)\r\n\r\nOne way to do that is to use type narrowing: by checking if the return value is `None`, you can branch into code where the static type is `NoneType`, or into code where the static type is `Row`.\r\n\r\n    # reveal_type(result) == Row | None\r\n    result = df.select(f.min(f.col(column_name))).first()\r\n\r\n    if result is None:\r\n        # reveal_type(result) == None\r\n        do what needs to be done if no row is returned\r\n    else:\r\n        # reveal_type(result) == Row\r\n        x = result[0]\r\n        return df.withColumn(&#39;new column&#39;, f.col(column_name) + x)\r\n\r\n*You* might know that the particular argument to `df.select` *cannot* fail, but `mypy` does not.\r\n\r\n---\r\n\r\nAnother option, if you are *absolutely* sure you will get a `Row` back, is to use `cast` to let `mypy` in on the secret.\r\n\r\n    x = typing.cast(Row, df.select(...))[0]\r\n    return df.withColumn(...)\r\n    \r\n\r\nThis is risky, though. `mypy` will believe the `cast`, and if `df.select(...)` *does* return `None`, you&#39;ll get a runtime error even though `mypy` says it&#39;s OK.",
                    "title": "How to solve mypy error &quot;value of type row | none is not indexable&quot; for pyspark dataframe?"
                }
            ],
            "owner": {
                "account_id": 30643039,
                "reputation": 3,
                "user_id": 23491073,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/bfb84ecf316613155b00dbb4a7e5337c?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "viwi",
                "link": "https://stackoverflow.com/users/23491073/viwi"
            },
            "is_answered": true,
            "view_count": 25,
            "favorite_count": 0,
            "accepted_answer_id": 78068148,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709041518,
            "question_id": 78068011,
            "body_markdown": "Mypy throws the error &quot;Value of type &#39;Row | None&#39; is not indexable&quot; for the line starting with &quot;x=&quot;: \r\n\r\n```\r\nfrom pyspark.sql import DataFrame\r\nfrom pyspark.sql import functions as f\r\n\r\ndef somefunction(df: DataFrame, column_name: str) -&gt; DataFrame:\r\n    x = df.select(f.min(f.col(column_name))).first()[0] \r\n    return df.withColumn(&#39;newcolumn&#39;, f.col(column_name) + x)\r\n```\r\n\r\n\r\nHow can I add a type check that passes mypy? ",
            "link": "https://stackoverflow.com/questions/78068011/how-to-solve-mypy-error-value-of-type-row-none-is-not-indexable-for-pyspark",
            "title": "How to solve mypy error &quot;value of type row | none is not indexable&quot; for pyspark dataframe?"
        },
        {
            "tags": [
                "python",
                "matplotlib",
                "windows-subsystem-for-linux"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 18003774,
                        "reputation": 163,
                        "user_id": 13085089,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/0f7fa3ed41382ea74023434dfe236c07?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Daniel N&#253;drle",
                        "link": "https://stackoverflow.com/users/13085089/daniel-n%c3%bddrle"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709042365,
                    "answer_id": 78068101,
                    "question_id": 78068008,
                    "body_markdown": "Noticed that the plot window contains &quot;[WARN: COPY MODE]&quot;, so searched for answers for this and I solved it with updating mesa like so: `sudo add-apt-repository ppa:kisak/kisak-mesa`.\r\nProps to [onomatopellan][1].\r\n\r\n\r\n  [1]: https://github.com/microsoft/wslg/discussions/312",
                    "title": "WSL Matplotlib artifacts"
                }
            ],
            "owner": {
                "account_id": 18003774,
                "reputation": 163,
                "user_id": 13085089,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/0f7fa3ed41382ea74023434dfe236c07?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Daniel N&#253;drle",
                "link": "https://stackoverflow.com/users/13085089/daniel-n%c3%bddrle"
            },
            "is_answered": false,
            "view_count": 18,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709041507,
            "question_id": 78068008,
            "body_markdown": "I am trying to run matplotlib.pyplot on WSL in a Conda environment, but on start some strange things happen to my pyplot window, there are weird lines (that sometimes hide on hover).\r\n\r\nWSL versions:\r\n```\r\nWSL version: 2.0.14.0\r\nKernel version: 5.15.133.1-1\r\nWSLg version: 1.0.59\r\nMSRDC version: 1.2.4677\r\nDirect3D version: 1.611.1-81528511\r\nDXCore version: 10.0.25131.1002-220531-1700.rs-onecore-base2-hyp\r\nWindows version: 10.0.22631.3155\r\n```\r\n\r\nConda versions (matplotlib &amp; python):\r\n```\r\nmatplotlib                3.8.0           py311h06a4308_0  \r\nmatplotlib-base           3.8.0           py311ha02d727_0  \r\nmatplotlib-inline         0.1.6              pyhd8ed1ab_0    conda-forge\r\npython                    3.11.7               h955ad1f_0 \r\n```\r\n\r\n[![Pyplot window][1]][1]\r\n\r\n\r\nAfter a click in the window, the window corrects itself:\r\n[![Corrected window][2]][2]\r\n\r\nBut after a hover into the plot in the window, there is still a line with artifacts:\r\n[![Window with a line of artifacts][3]][3]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/9ytS5.png\r\n  [2]: https://i.stack.imgur.com/8BviS.png\r\n  [3]: https://i.stack.imgur.com/yPWpc.png",
            "link": "https://stackoverflow.com/questions/78068008/wsl-matplotlib-artifacts",
            "title": "WSL Matplotlib artifacts"
        },
        {
            "tags": [
                "python",
                "pandas",
                "dataframe"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 13900216,
                        "reputation": 184517,
                        "user_id": 10035985,
                        "user_type": "registered",
                        "profile_image": "https://lh4.googleusercontent.com/-1WgJ_2yA-78/AAAAAAAAAAI/AAAAAAAAAOA/0CBOlYqYe7M/photo.jpg?sz=256",
                        "display_name": "Andrej Kesely",
                        "link": "https://stackoverflow.com/users/10035985/andrej-kesely"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709042448,
                    "answer_id": 78068106,
                    "question_id": 78067992,
                    "body_markdown": "If `df.set_index([&quot;doc_id&quot;, &quot;term_candidate&quot;])` is not what you want you can try:\r\n\r\n```py\r\ndf = df.sort_values(by=[&quot;doc_id&quot;, &quot;tfidf&quot;])\r\n\r\nmask = df.duplicated(subset=&quot;doc_id&quot;, keep=&quot;first&quot;)\r\n\r\ndf[&quot;doc_id&quot;] = df[&quot;doc_id&quot;].astype(str)\r\ndf.loc[mask, &quot;doc_id&quot;] = &quot;&quot;\r\n\r\nprint(df)\r\n```\r\n\r\nPrints:\r\n\r\n```none\r\n                doc_id term_candidate     tfidf\r\n0  1240600489869402113          space  0.057618\r\n1                            capacity  0.057618\r\n2                                idea  0.057618\r\n3  1340608455992815617       priority  0.064477\r\n4                       typical dates  0.064477\r\n5                                hope  0.064477\r\n```",
                    "title": "reindex and group dataframe using the repeated ids"
                }
            ],
            "owner": {
                "account_id": 348144,
                "reputation": 857,
                "user_id": 682661,
                "user_type": "registered",
                "accept_rate": 72,
                "profile_image": "https://www.gravatar.com/avatar/394398d1c2ac9044830c19ea850d9443?s=256&d=identicon&r=PG",
                "display_name": "Omnia",
                "link": "https://stackoverflow.com/users/682661/omnia"
            },
            "is_answered": false,
            "view_count": 30,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709041333,
            "question_id": 78067992,
            "body_markdown": "I have the following dataframe:\r\n\r\n        \tdoc_id\tterm_candidate\ttfidf\r\n    0\t1240600489869402113\tspace\t        0.057618\r\n    1\t1240600489869402113\tcapacity\t    0.057618\r\n    2\t1240600489869402113\tidea\t        0.057618\r\n    3\t1340608455992815617\tpriority\t    0.064477\r\n    4\t1340608455992815617\ttypical dates\t0.064477\r\n    5\t1340608455992815617\thope\t        0.064477\r\n\r\nAnd I would like to group by the doc_id as follows:\r\n\r\n    doc_id\tterm_candidate\ttfidf\r\n    1240600489869402113\tspace\t        0.057618\r\n    \t\t\t\t    capacity\t    0.057618\r\n    \t\t\t\t    idea\t        0.057618\r\n    1340608455992815617\tpriority\t    0.064477\r\n    \t\t\t\t    typical dates\t0.064477\r\n    \t\t\t\t    hope\t        0.064477\r\n\r\nI tried `groupby` but no luck, any ideas?\r\n\r\nalso to sort the tfidf values for each doc_id.",
            "link": "https://stackoverflow.com/questions/78067992/reindex-and-group-dataframe-using-the-repeated-ids",
            "title": "reindex and group dataframe using the repeated ids"
        },
        {
            "tags": [
                "python",
                "join",
                "indexing",
                "merge"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 13900216,
                        "reputation": 184517,
                        "user_id": 10035985,
                        "user_type": "registered",
                        "profile_image": "https://lh4.googleusercontent.com/-1WgJ_2yA-78/AAAAAAAAAAI/AAAAAAAAAOA/0CBOlYqYe7M/photo.jpg?sz=256",
                        "display_name": "Andrej Kesely",
                        "link": "https://stackoverflow.com/users/10035985/andrej-kesely"
                    },
                    "is_accepted": true,
                    "score": 0,
                    "creation_date": 1709041307,
                    "answer_id": 78067988,
                    "question_id": 78067971,
                    "body_markdown": "You can `pd.concat()` the two dataframes and sort the index as next step:\r\n\r\n```py\r\nout = pd.concat([df1, df2]).sort_index(kind=&quot;stable&quot;)\r\nprint(out)\r\n```\r\n\r\nPrints:\r\n\r\n```none\r\n       x   y\r\n0    one   1\r\n0    six   6\r\n1    two   2\r\n1  seven   7\r\n2  three   3\r\n2  eight   8\r\n3   four   4\r\n3   nine   9\r\n4   five   5\r\n4    ten  10\r\n```",
                    "title": "Two tables to join but keep index order"
                }
            ],
            "owner": {
                "account_id": 30642972,
                "reputation": 11,
                "user_id": 23491012,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/6406c11ee959e1d5127da1bb79e5645b?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "user23491012",
                "link": "https://stackoverflow.com/users/23491012/user23491012"
            },
            "is_answered": true,
            "view_count": 28,
            "favorite_count": 0,
            "accepted_answer_id": 78067988,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709041082,
            "question_id": 78067971,
            "body_markdown": "I have two tables that have the same column names. I want to merge them but need to keep the order of the index:\r\n\r\n    \tdf1\t\r\n    \tx\t    y\r\n    0\tone\t    1\r\n    1\ttwo\t    2\r\n    2\tthree\t3\r\n    3\tfour\t4\r\n    4\tfive\t5\r\n\r\n\r\n    \tdf2\t\r\n    \tx\t    y\r\n    0\tsix\t    6\r\n    1\tseven\t7\r\n    2\teight\t8\r\n    3\tnine\t9\r\n    4\tten\t    10\r\n\t\r\n\r\n\r\nthe order of the merge is very important as I need index 0 of df1 to be first and index 0 of df2 to be second and so on.The result I want is the following:\r\n\r\n\r\nThis is to create an excel file to integrate into SAP so the order is very important . Could you help me find the correct merge for this? \r\n\r\n\r\n\r\n    \tdf\t\r\n    \tx\t    y\r\n    0\tone \t1\r\n    0\tsix \t6\r\n    1\ttwo  \t2\r\n    1\tseven\t7\r\n    2\tthree\t3\r\n    2\teight\t8\r\n    3\tfour\t4\r\n    3\tnine\t9\r\n    4\tfive\t5\r\n    4\tten\t   10\r\n    ```\r\n\r\nI tried different merges but couldn&#39;t find one that respects the order of the index. \r\n\r\n\r\n  [1]: https://i.stack.imgur.com/wK1Kf.png\r\n  [2]: https://i.stack.imgur.com/fdT1Y.png\r\n  [3]: https://i.stack.imgur.com/zaPjp.png",
            "link": "https://stackoverflow.com/questions/78067971/two-tables-to-join-but-keep-index-order",
            "title": "Two tables to join but keep index order"
        },
        {
            "tags": [
                "python",
                "tensorflow",
                "machine-learning",
                "keras",
                "image-classification"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 23903429,
                        "reputation": 437,
                        "user_id": 17901307,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/NoPAx.png?s=256&g=1",
                        "display_name": "Cuartero",
                        "link": "https://stackoverflow.com/users/17901307/cuartero"
                    },
                    "is_accepted": false,
                    "score": 2,
                    "creation_date": 1709049344,
                    "answer_id": 78068866,
                    "question_id": 78067906,
                    "body_markdown": "As I said in comments, the error was because the model output (last layer) expected the labels in one hot encoding format. The layer had been defined as a dense layer of size `(None, num_classes)` (where None refers to the batch size) i.e. the labels should be in one hot encoding format. This format consists of vectors of size `num_classes` (one entry for each class). Thus, for the class, for example, 6, instead of having a number representing it, we have a vector of size 9 (number of classes) where position 5 (label 6) contains a 1 while the others contain 0: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]. In reality, what this format represents is a vector where each index corresponds to the probability of each of the classes. \r\n\r\nTensorflow allows encoding labels in this format within the `image_dataset_from_directory` function using the input variable `label_mode = &quot;categorical&quot;`.\r\n\r\n```python\r\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n       ...\r\n       label_mode = &quot;categorical&quot;\r\n)\r\n```",
                    "title": "logits and labels must have the same shape error in skincancer image classification"
                }
            ],
            "owner": {
                "account_id": 29794320,
                "reputation": 1,
                "user_id": 22833776,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocIhxvrILfMxYqfPCW0B2mJeYAsuCE5uHx9k7uRCqVJkpuk=k-s256",
                "display_name": "Subho",
                "link": "https://stackoverflow.com/users/22833776/subho"
            },
            "is_answered": true,
            "view_count": 33,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709040379,
            "question_id": 78067906,
            "body_markdown": "i am using latest tensorflow package and isic skin cancer image dataset. am completely new to this machine learning and neural nets and was trying to classify images using tensorflow neural networks and keras. \r\n\r\ni used the code off from kaggle and changed it a bit up to suit my need for the model however the code is not running and giving me an error that i am not understanding and able to do anything as the vanialla code ran just fine. \r\n\r\nHow to resolve this error?\r\n\r\n\r\n\r\n\r\n\r\n\r\nthis is the function that i have written to make the nerural network. The code is based of from a kaggle project and i have tried to make functions which can be used to easily supply desired parameters and hyper parameters to easily train the models. \r\n\r\n```\r\n#function to select the optimizers\r\ndef select_optimizer(optimizer , lr):\r\n    optimizers = {\r\n      &quot;adam&quot;: tf.keras.optimizers.Adam(learning_rate=lr),\r\n      &quot;sgd&quot;: tf.keras.optimizers.SGD(learning_rate=lr),\r\n      &quot;lion&quot;: tf.keras.optimizers.Lion(learning_rate = lr),\r\n      &quot;adafactor&quot;: tf.keras.optimizers.Adafactor(learning_rate = lr)}\r\n    return optimizers[optimizer]\r\n   \r\n# final function that compiles the prototype model and gets the model and history    \r\ndef proto_model(n , neuron_density , num_classes , acti_functions , final_acti , lr , loss_func , optimize , epochs):\r\n    \r\n    model = Sequential([layers.experimental.preprocessing.Rescaling(1.0 / 255 , input_shape = (img_height , img_width , 3))])\r\n    #initial properties of the layer of the neurons in the first element of the arrays \r\n    model.add(Conv2D(neuron_density[0] , 3 , padding = &quot;same&quot; , activation = acti_functions[0]))\r\n    model.add(MaxPool2D())\r\n    \r\n    #for loop for the internal desne layer creations\r\n    for i in range(1 , n):\r\n        model.add(Conv2D(neuron_density[i] , 3 , padding = &quot;same&quot; , activation = acti_functions[i]))\r\n        model.add(MaxPool2D())\r\n    \r\n    \r\n    #final output dense layer of the neurons taken from the final layer of the arrays \r\n    model.add(Flatten())\r\n    model.add(Dense(neuron_density[n-1] , activation = acti_functions[n-1]))\r\n    model.add(Dense(units = num_classes , activation = final_acti))\r\n    \r\n    optimizer_algo = select_optimizer(optimize , lr)\r\n    model.compile(optimizer = optimizer_algo, loss = loss_func,\r\n    metrics = [&#39;accuracy&#39;])\r\n     \r\n    history = model.fit(train_ds , validation_data = val_ds , epochs = epochs)\r\n    \r\n    return model , history\r\n```\r\n\r\nThe parameters that i have supplied :- \r\n\r\n```\r\ndensities = [32 , 64 , 128 , 256 , 512 , 1024] \r\nacties = [&quot;relu&quot; , &quot;relu&quot; , &quot;relu&quot; , &quot;relu&quot; , &quot;relu&quot; , &quot;relu&quot;] \r\nfin_acti = &quot;softmax&quot;\r\nn = 6\r\nclasses = 9\r\nlearning_rate = 0.001\r\nloss_func = &quot;BinaryCrossentropy&quot;\r\noptimizer = &quot;adam&quot;\r\nepochs = 10\r\nmodel , history = proto_model(n , densities , classes , acties , fin_acti , learning_rate , loss_func , optimizer , epochs)\r\n```\r\nThe above were the exact parameters that were even in vanilla original code however this time i have made it into arrays and supplied to the function that i have created from the vanilla code. \r\n\r\n\r\n\r\nError that i have encountered : \r\nValueError: `logits` and `labels` must have the same shape, received ((None, 9) vs (None, 1)).\r\n\r\nalso shows :- \r\n\r\n```\r\nEpoch 1/10\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[25], line 10\r\n      8 optimizer = &quot;adam&quot;\r\n      9 epochs = 10\r\n---&gt; 10 model , history = proto_model(n , densities , classes , acties , fin_acti , learning_rate , loss_func , optimizer , epochs)\r\n\r\nCell In[24], line 33, in proto_model(n, neuron_density, num_classes, acti_functions, final_acti, lr, loss_func, optimize, epochs)\r\n     29 optimizer_algo = select_optimizer(optimize , lr)\r\n     30 model.compile(optimizer = optimizer_algo, loss = loss_func,\r\n     31 metrics = [&#39;accuracy&#39;])\r\n---&gt; 33 history = model.fit(train_ds , validation_data = val_ds , epochs = epochs)\r\n     35 return model , history\r\n\r\nFile ~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70, in filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)\r\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\r\n     68     # To get the full stack trace, call:\r\n     69     # `tf.debugging.disable_traceback_filtering()`\r\n---&gt; 70     raise e.with_traceback(filtered_tb) from None\r\n     71 finally:\r\n     72     del filtered_tb\r\n\r\nFile C:\\Users\\SUBHOJ~1\\AppData\\Local\\Temp\\__autograph_generated_fileoc8gwbam.py:15, in outer_factory.&lt;locals&gt;.inner_factory.&lt;locals&gt;.tf__train_function(iterator)\r\n     13 try:\r\n     14     do_return = True\r\n---&gt; 15     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\r\n     16 except:\r\n     17     do_return = False\r\n\r\nValueError: in user code:\r\n```\r\n",
            "link": "https://stackoverflow.com/questions/78067906/logits-and-labels-must-have-the-same-shape-error-in-skincancer-image-classificat",
            "title": "logits and labels must have the same shape error in skincancer image classification"
        },
        {
            "tags": [
                "python",
                "machine-learning",
                "flask",
                "scikit-learn"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 24224100,
                        "reputation": 310,
                        "user_id": 18178867,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/t77Px.jpg?s=256&g=1",
                        "display_name": "Reza",
                        "link": "https://stackoverflow.com/users/18178867/reza"
                    },
                    "is_accepted": true,
                    "score": 2,
                    "creation_date": 1709040526,
                    "answer_id": 78067920,
                    "question_id": 78067888,
                    "body_markdown": "I encountered this issue two months ago and could resolved it after spending days on it.\r\n\r\nYou can restrict the access of your scikit-learn model to the resources using &lt;code&gt;joblib&lt;/code&gt;:\r\n\r\n    from joblib import parallel_backend\r\n    import sklearn.neighbors.KNeighborsClassifier as KNN\r\n    model = KNN(n_jobs=1)\r\n    with parallel_backend(&quot;threading&quot;, n_jobs=1):\r\n        model.fit(X,y)",
                    "title": "Reaching maximum resources on python webhost"
                }
            ],
            "owner": {
                "account_id": 30642901,
                "reputation": 23,
                "user_id": 23490951,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/a372017f6d071eec168d1a2fc166be44?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Michael",
                "link": "https://stackoverflow.com/users/23490951/michael"
            },
            "is_answered": true,
            "view_count": 57,
            "favorite_count": 0,
            "accepted_answer_id": 78067920,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709040235,
            "question_id": 78067888,
            "body_markdown": "I want to deploy a flask app on a python webhost. The app is built using machine learning models link KNN, SVM, etc. I have developed the models using the scikit-learn library. \r\nThe app works fine on the my local machine, but encounters Internal Server Error when I run it on the host. \r\nI checked the error log and found that when running the ML models, the server runs out of resources. How can I fix this?\r\n\r\nI have tried limiting the n_jobs in scikit-learn models to 1, but it didn&#39;t work.",
            "link": "https://stackoverflow.com/questions/78067888/reaching-maximum-resources-on-python-webhost",
            "title": "Reaching maximum resources on python webhost"
        },
        {
            "tags": [
                "python",
                "pytorch",
                "dataset",
                "tracking",
                "training-data"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30643190,
                        "reputation": 1,
                        "user_id": 23491196,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJM9E6bLTLjb4C-IpSzZBx69XcsfuegflUNB2sRNK69=k-s256",
                        "display_name": "user23491196",
                        "link": "https://stackoverflow.com/users/23491196/user23491196"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709042548,
                    "answer_id": 78068119,
                    "question_id": 78067874,
                    "body_markdown": "nice job Reza!\r\nit will be nice if you share the full code  in your github or in the original repo.\r\nabout your problem, may be you are wrong with your stirde and grid_to_search_y. just try changing them and every thing will be fine!\r\ngood luck mate, better think more before asking your problem, your brain is your power as a developer or data Scientist :)",
                    "title": "Problem with creating dataset for visual object tracker"
                }
            ],
            "owner": {
                "account_id": 25708029,
                "reputation": 25,
                "user_id": 19467019,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a-/AOh14GgAcrrdhuwIwLEIEr8wRwb930VmBlkXsPWlhlcn=k-s256",
                "display_name": "Reza shahriari",
                "link": "https://stackoverflow.com/users/19467019/reza-shahriari"
            },
            "is_answered": false,
            "view_count": 25,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709040123,
            "question_id": 78067874,
            "body_markdown": "I wanted to train [ET-Track][1](a nice video object tracker). which is based on [Ocean][2](another video object tracker).\r\n\r\nthe problem is they did not share any code for training it before. now we have the code(changing codes from Ocean) but we have a big problem with it. we have a random shift when trying to crop images for our template-image. this is an example:\r\n\r\n[![crop results][3]][3]\r\n\r\nas you can see the search2 image which the model will train with it have a shift in it. I can figure out why I have this shift. would you help me please?\r\n\r\n```\r\n        (template,search,out_label,reg_label,reg_weight,bbox,) = dataset[0]\r\n        x1, y1, x2, y2 = map(int, bbox)            \r\n        search = search.transpose((1, 2, 0)).astype(np.uint8)\r\n        \r\n        search = cv2.rectangle((search) , (x1, y1), (x2, y2), (200, 100, 150),1)\r\n        \r\n        reg_weight = cv2.cvtColor(reg_weight.astype(np.uint8), cv2.COLOR_GRAY2RGB)\r\n        reg_weight = cv2.resize(reg_weight, (search.shape[1], search.shape[0]))\r\n        out_label = cv2.cvtColor(out_label.astype(np.uint8) * 255, cv2.COLOR_GRAY2RGB)\r\n        out_label = cv2.resize(out_label, (search.shape[1], search.shape[0]))\r\n        x1, y1, x2, y2 = map(int, bbox)\r\n        search2 = cv2.rectangle(search * reg_weight, (x1, y1), (x2, y2), (200, 100, 150))\r\n        cv2.imshow(&quot;search2&quot;, search2)\r\n        cv2.imshow(&quot;search&quot;,search)\r\n        cv2.imshow(&quot;out_label&quot;, out_label)\r\n``` \r\n\r\nThis is how these outputs are created.\r\n\r\nand this is my dataset `__getitem__`:\r\n```\r\n        if self.random_data:\r\n             template, search = self._get_pairs(index)\r\n             #choose 2 random image for search and template\r\n        \r\n        template_image = cv2.imread(template[0].as_posix())\r\n        search_image = cv2.imread(search[0].as_posix())\r\n        # change bboxes format and pick the first one\r\n        template_target_bbox = self.yolo2ocean(template[1], template_image)\r\n        search_target_bbox = self.yolo2ocean(search[1], search_image)\r\n        _, template_image = crop_like_SiamFC(\r\n            template_image,\r\n            bbox=template_target_bbox,\r\n            exemplar_size=self.template_size,\r\n            instance_size=self.search_size,\r\n        )\r\n        _, search_image = crop_like_SiamFC(\r\n            search_image,\r\n            bbox=search_target_bbox,\r\n            exemplar_size=self.template_size,\r\n            instance_size=self.search_size + self.search_margin,\r\n        )\r\n        template_box = self._toBBox(template_image, template_target_bbox)\r\n        search_box = self._toBBox(search_image, search_target_bbox)\r\n\r\n        template, _, _ = self._augmentation(\r\n            template_image, template_box, self.template_size\r\n        )\r\n        search, bbox, dag_param = self._augmentation(\r\n            search_image, search_box, self.search_size, search=True\r\n        )\r\n        #No augment i have turned off all of them! \r\n        # from PIL image to numpy\r\n        template = np.array(template)\r\n        search = np.array(search)\r\n        out_label = self._dynamic_label([self.size, self.size], dag_param.shift)\r\n\r\n        reg_label, reg_weight = self.reg_label(bbox)\r\n```\r\n\r\nI think the `self.reg_label` is actual problem but I don&#39;t know why?\r\nthis is the function:\r\n```\r\ndef reg_label(self, bbox):\r\n        &quot;&quot;&quot;\r\n        generate regression label\r\n        :param bbox: [x1, y1, x2, y2]\r\n        :return: [l, t, r, b]\r\n        &quot;&quot;&quot;\r\n        x1, y1, x2, y2 = bbox\r\n        l = self.grid_to_search_x - x1  # [17, 17]\r\n        t = self.grid_to_search_y - y1\r\n        r = x2 - self.grid_to_search_x\r\n        b = y2 - self.grid_to_search_y\r\n        l, t, r, b = map(lambda x: np.expand_dims(x, axis=-1), [l, t, r, b])\r\n        \r\n        \r\n        reg_label = np.concatenate((l, t, r, b), axis=-1)  # [17, 17, 4]\r\n        reg_label_min = np.min(reg_label, axis=-1)\r\n        inds_nonzero = (reg_label_min &gt; 0).astype(float)\r\n\r\n        return reg_label, inds_nonzero\r\ndef grids(self):\r\n        &quot;&quot;&quot;\r\n        each element of feature map on input search image\r\n        :return: H*W*2 (position for each element)\r\n        &quot;&quot;&quot;\r\n        sz = self.size #25\r\n\r\n        sz_x = sz // 2\r\n        sz_y = sz // 2\r\n\r\n        x, y = np.meshgrid(\r\n            np.arange(0, sz) - np.floor(float(sz_x)),\r\n            np.arange(0, sz) - np.floor(float(sz_y)),\r\n        )\r\n        self.grid_to_search = {}\r\n        self.stride = 8\r\n        self.grid_to_search_x = x * self.stride + self.search_size // 2\r\n        self.grid_to_search_y = y * self.stride + self.search_size // 2\r\n``` \r\nAny idea would be helpful. Thanks a lot\r\n\r\n\r\n  [1]: https://github.com/pblatter/ettrack/tree/main/pytracking\r\n  [2]: https://github.com/researchmm/TracKit\r\n  [3]: https://i.stack.imgur.com/Qphne.png",
            "link": "https://stackoverflow.com/questions/78067874/problem-with-creating-dataset-for-visual-object-tracker",
            "title": "Problem with creating dataset for visual object tracker"
        },
        {
            "tags": [
                "python",
                "unit-testing",
                "testing",
                "python-unittest"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 11443181,
                        "reputation": 19277,
                        "user_id": 8431111,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/GteAE.jpg?s=256&g=1",
                        "display_name": "J_H",
                        "link": "https://stackoverflow.com/users/8431111/j-h"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709039867,
                    "answer_id": 78067851,
                    "question_id": 78067735,
                    "body_markdown": "\r\nYes.\r\n\r\nConsult the documentation for the \u201cinspect\u201d and \u201cdis\u201d builtin modules.",
                    "title": "statically inspect a python test suite"
                }
            ],
            "owner": {
                "account_id": 101780,
                "reputation": 2407,
                "user_id": 273593,
                "user_type": "registered",
                "accept_rate": 38,
                "profile_image": "https://www.gravatar.com/avatar/5b8ba221ade55df80b623122471d81e5?s=256&d=identicon&r=PG",
                "display_name": "Vito De Tullio",
                "link": "https://stackoverflow.com/users/273593/vito-de-tullio"
            },
            "is_answered": false,
            "view_count": 29,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709038555,
            "question_id": 78067735,
            "body_markdown": "I have a (unittest-based) test suite for my python project.\r\nHere I have my test classes, with my test methods, etc...\r\nIn (some of my) tests I call a function to initialize the scenarios of the tests. Let&#39;s call this function `generate_scenario(...)`, and it has a bunch of parameters.\r\n\r\nI was wondering if I could write an additional python code that could find all the times `generate_scenario(...)` is called and with the parameter passed, so I could check if all the &quot;possible&quot; scenarios are actually generated.\r\n\r\nIdeally I want an additional test module to check that.",
            "link": "https://stackoverflow.com/questions/78067735/statically-inspect-a-python-test-suite",
            "title": "statically inspect a python test suite"
        },
        {
            "tags": [
                "python",
                "pandas",
                "dataframe",
                "dictionary",
                "nested"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 22084389,
                        "reputation": 223378,
                        "user_id": 16343464,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/7kTic.png?s=256&g=1",
                        "display_name": "mozway",
                        "link": "https://stackoverflow.com/users/16343464/mozway"
                    },
                    "is_accepted": true,
                    "score": 2,
                    "creation_date": 1709038034,
                    "answer_id": 78067681,
                    "question_id": 78067647,
                    "body_markdown": "Use [`str.get`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.get.html) to access the dictionary key and [boolean indexing](https://pandas.pydata.org/docs/user_guide/indexing.html#boolean-indexing):\r\n```\r\nout = df[df[&#39;Location&#39;].str.get(&#39;State&#39;).eq(&#39;NY&#39;)]\r\n```\r\nAlternatively, with a list comprehension:\r\n```\r\nout = df[[d.get(&#39;State&#39;)==&#39;NY&#39; for d in df[&#39;Location&#39;]]]\r\n```\r\nOutput:\r\n```\r\n     Name  Age                             Location\r\n1     Bob   30  {&#39;City&#39;: &#39;New York&#39;, &#39;State&#39;: &#39;NY&#39;}\r\n2  Aritra   35    {&#39;City&#39;: &#39;Albany&#39;, &#39;State&#39;: &#39;NY&#39;}\r\n```",
                    "title": "Pandas: Filter rows on value in dictionaries in Series"
                }
            ],
            "owner": {
                "account_id": 3930650,
                "reputation": 141,
                "user_id": 7179031,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/TYoKO.jpg?s=256&g=1",
                "display_name": "Jopie",
                "link": "https://stackoverflow.com/users/7179031/jopie"
            },
            "is_answered": true,
            "view_count": 38,
            "favorite_count": 0,
            "accepted_answer_id": 78067681,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709037765,
            "question_id": 78067647,
            "body_markdown": "Some columns in my dataframe consist of dictionaries themselves, like this dataframe:\r\n\r\n    df = pd.DataFrame({&#39;Name&#39;: [&#39;Alice&#39;, &#39;Bob&#39;, &#39;Aritra&#39;],\r\n                       &#39;Age&#39;: [25, 30, 35],\r\n                       &#39;Location&#39;: [\r\n                          {&#39;City&#39;: &#39;Seattle&#39;, &#39;State&#39;: &#39;WA&#39;}, \r\n                          {&#39;City&#39;: &#39;New York&#39;, &#39;State&#39;: &#39;NY&#39;}, \r\n                          {&#39;City&#39;: &#39;Albany&#39;, &#39;State&#39;: &#39;NY&#39;}\r\n                        ]\r\n                        })\r\n    \r\n    df\r\n    \tName\tAge\tLocation\r\n    0\tAlice\t25\t{&#39;City&#39;: &#39;Seattle&#39;, &#39;State&#39;: &#39;WA&#39;}\r\n    1\tBob\t    30\t{&#39;City&#39;: &#39;New York&#39;, &#39;State&#39;: &#39;NY&#39;}\r\n    2\tAritra\t35\t{&#39;City&#39;: &#39;Albany&#39;, &#39;State&#39;: &#39;NY&#39;}\r\n\r\nHow can I filter the dataframe on a value in that dictionary? \r\n\r\nWhen I just want one value, I can do this:\r\n\r\n    df[&#39;Location&#39;][0][&#39;State&#39;] \r\n    &#39;WA&#39;\r\n\r\nBut the issue is that the index is necessary in between the column name and the dictionary key. Thus something like ```df[df[&#39;Location&#39;][&#39;State&#39;] == &#39;NY&#39;]``` to select all people from NY won&#39;t work. \r\n\r\nIs there a way to include any index, or must this be done otherwise?\r\n\r\nThe desired output is\r\n\r\n    \tName\tAge\tLocation\r\n    1\tBob\t    30\t{&#39;City&#39;: &#39;New York&#39;, &#39;State&#39;: &#39;NY&#39;}\r\n    2\tAritra\t35\t{&#39;City&#39;: &#39;Albany&#39;, &#39;State&#39;: &#39;NY&#39;}",
            "link": "https://stackoverflow.com/questions/78067647/pandas-filter-rows-on-value-in-dictionaries-in-series",
            "title": "Pandas: Filter rows on value in dictionaries in Series"
        },
        {
            "tags": [
                "python",
                "huggingface-transformers",
                "embedding",
                "mteb"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 365813,
                        "reputation": 5430,
                        "user_id": 710955,
                        "user_type": "registered",
                        "accept_rate": 77,
                        "profile_image": "https://i.stack.imgur.com/GvorM.png?s=256&g=1",
                        "display_name": "LeMoussel",
                        "link": "https://stackoverflow.com/users/710955/lemoussel"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709039053,
                    "answer_id": 78067780,
                    "question_id": 78067552,
                    "body_markdown": "Typo error !\r\nIn code, I do `evaluation.run(model_name, output_folder=f&quot;fr_results/{model_name}&quot;)`. It&#39;s rather `evaluation.run(model, output_folder=f&quot;fr_results/{model_name}&quot;)` ",
                    "title": "Error when benchmarking French datasets constituting the MTEB French leaderboard"
                }
            ],
            "owner": {
                "account_id": 365813,
                "reputation": 5430,
                "user_id": 710955,
                "user_type": "registered",
                "accept_rate": 77,
                "profile_image": "https://i.stack.imgur.com/GvorM.png?s=256&g=1",
                "display_name": "LeMoussel",
                "link": "https://stackoverflow.com/users/710955/lemoussel"
            },
            "is_answered": true,
            "view_count": 14,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709036799,
            "question_id": 78067552,
            "body_markdown": "I want to evaluate some french embeddings models using MTEB Semantic Text Similarity (STS) task.\r\nTo do this, I took inspiration from this code [run_mteb_french.py][1]\r\n\r\n       import logging\r\n    \r\n       from sentence_transformers import SentenceTransformer\r\n       from mteb import MTEB\r\n    \r\n       logging.basicConfig(level=logging.INFO)\r\n       logger = logging.getLogger(&quot;main&quot;)\r\n    \r\n       model_name = &quot;dangvantuan/sentence-camembert-large&quot;\r\n       model = SentenceTransformer(model_name)\r\n\r\n       TASK_LIST_STS = [\r\n            &quot;SummEvalFr&quot;,\r\n            &quot;STSBenchmarkMultilingualSTS&quot;,\r\n            &quot;STS22&quot;,\r\n            &quot;SICKFr&quot;\r\n        ]\r\n        \r\n        for task in TASK_LIST_STS:\r\n          logger.info(f&quot;Running task: {task}&quot;)\r\n          evaluation = MTEB(tasks=[task], task_langs=[&quot;fr&quot;]) \r\n          evaluation.run(model_name, output_folder=f&quot;fr_results/{model_name}&quot;)\r\n\r\nBut I got this error:\r\n\r\n&gt; Summarization\r\n&gt; \r\n&gt;     - SummEvalFr, p2p\r\n&gt; \r\n&gt; \r\n&gt; ERROR:mteb.evaluation.MTEB:Error while evaluating SummEvalFr:\r\n&gt; &#39;batch_size&#39; is an invalid keyword argument for encode()\r\n&gt; \r\n&gt; ---------------------------------------------------------------------------\r\n&gt; \r\n&gt; TypeError                                 Traceback (most recent call\r\n&gt; last)\r\n&gt; \r\n&gt; &lt;ipython-input-10-7efe611f2e22&gt; in &lt;cell line: 17&gt;()\r\n&gt;      18   logger.info(f&quot;Running task: {task}&quot;)\r\n&gt;      19   evaluation = MTEB(tasks=[task], task_langs=[&quot;fr&quot;])\r\n&gt; ---&gt; 20   evaluation.run(model_name, output_folder=f&quot;fr_results/{model_name}&quot;)\r\n&gt; \r\n&gt; 4 frames\r\n&gt; \r\n&gt; /usr/local/lib/python3.10/dist-packages/mteb/evaluation/evaluators/SummarizationEvaluator.py\r\n&gt; in __call__(self, model)\r\n&gt;      51 \r\n&gt;      52         logger.info(f&quot;Encoding {sum(human_lens)} human summaries...&quot;)\r\n&gt; ---&gt; 53         embs_human_summaries_all = model.encode(\r\n&gt;      54             [summary for human_summaries in self.human_summaries for summary in human_summaries],\r\n&gt;      55             batch_size=self.batch_size,\r\n&gt; \r\n&gt; TypeError: &#39;batch_size&#39; is an invalid keyword argument for encode()\r\n\r\n\r\nWhat should I do ?\r\n\r\n\r\n  [1]: https://github.com/embeddings-benchmark/mteb/blob/main/scripts/run_mteb_french.py\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/78067552/error-when-benchmarking-french-datasets-constituting-the-mteb-french-leaderboard",
            "title": "Error when benchmarking French datasets constituting the MTEB French leaderboard"
        },
        {
            "tags": [
                "python",
                "pandas",
                "dataframe"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 22084389,
                        "reputation": 223378,
                        "user_id": 16343464,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/7kTic.png?s=256&g=1",
                        "display_name": "mozway",
                        "link": "https://stackoverflow.com/users/16343464/mozway"
                    },
                    "is_accepted": true,
                    "score": 7,
                    "creation_date": 1709036842,
                    "answer_id": 78067555,
                    "question_id": 78067486,
                    "body_markdown": "You can use a [`merge_asof`](https://pandas.pydata.org/docs/reference/api/pandas.merge_asof.html) to identify the closest value to each value in `df1`, then a [`rolling.max`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.window.rolling.Rolling.max.html) to extend the selection to the neighboring N rows:\r\n```\r\nN = 2 # number of surronding rows to keep\r\n\r\ns1 = df1[&#39;seconds&#39;].sort_values()\r\ns2 = df2[&#39;seconds&#39;].sort_values().rename(&#39;_&#39;)\r\n\r\nkeep = pd.merge_asof(s1, s2, left_on=&#39;seconds&#39;, right_on=&#39;_&#39;,\r\n                     direction=&#39;nearest&#39;)[&#39;_&#39;]\r\n\r\nout = df2[s2.isin(keep)\r\n            .rolling(2*N+1, center=True, min_periods=1)\r\n            .max().astype(bool)]\r\n```\r\n*NB. if the seconds are already sorted, you can skip the `.sort_values()`.*\r\n\r\nOutput:\r\n```\r\n    prize  seconds\r\n0     5.5      840\r\n1    14.5     1080\r\n2    14.6     1380\r\n3    21.0     1620\r\n7    38.0     1740\r\n8    39.0     2040\r\n9    40.0     2100\r\n10   50.0     2160\r\n```\r\nIntermediates:\r\n```\r\n    prize  seconds  closest  isin(keep)  rolling.max\r\n0     5.5      840      NaN       False         True\r\n1    14.5     1080   1140.0        True         True\r\n2    14.6     1380      NaN       False         True\r\n3    21.0     1620      NaN       False         True\r\n4    23.0     1650      NaN       False        False\r\n5    24.0     1680      NaN       False        False\r\n6    26.0     1700      NaN       False        False\r\n7    38.0     1740      NaN       False         True\r\n8    39.0     2040      NaN       False         True\r\n9    40.0     2100   2100.0        True         True\r\n10   50.0     2160      NaN       False         True\r\n```",
                    "title": "Given a value from a pandas column DataFrame, select N rows above and below to that closest value in other DataFrame"
                },
                {
                    "owner": {
                        "account_id": 842741,
                        "reputation": 22832,
                        "user_id": 11564487,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/ZtfZ4.jpg?s=256&g=1",
                        "display_name": "PaulS",
                        "link": "https://stackoverflow.com/users/11564487/pauls"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709058913,
                    "answer_id": 78069829,
                    "question_id": 78067486,
                    "body_markdown": "A semi-vectorized approach, based on numpy broadcasting, can be the following. It first determines the indexes of the rows we want and then uses those indexes to retrieve the rows from `df2`:\r\n\r\n    n = 2\r\n    matches = np.abs(df2.values[:,1] - df1.values[:,1].reshape(-1, 1)).argmin(1)\r\n    lowest_idx = np.maximum(matches-n, 0)\r\n    largest_idx = np.minimum(matches+n+1, len(df2))\r\n    df2.iloc[np.concatenate(\r\n        [np.arange(x, y) for x, y in zip(lowest_idx, largest_idx)]), :]\r\n\r\nOutput:\r\n\r\n        prize  seconds\r\n    0     5.5      840\r\n    1    14.5     1080\r\n    2    14.6     1380\r\n    3    21.0     1620\r\n    7    38.0     1740\r\n    8    39.0     2040\r\n    9    40.0     2100\r\n    10   50.0     2160\r\n\r\n\r\n\r\n\r\n\r\n",
                    "title": "Given a value from a pandas column DataFrame, select N rows above and below to that closest value in other DataFrame"
                }
            ],
            "owner": {
                "account_id": 29063571,
                "reputation": 109,
                "user_id": 22263688,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/1455225b0fcdc93b1f86a95d2fd27233?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "mauriciokaminski",
                "link": "https://stackoverflow.com/users/22263688/mauriciokaminski"
            },
            "is_answered": true,
            "view_count": 64,
            "favorite_count": 0,
            "accepted_answer_id": 78067555,
            "answer_count": 2,
            "score": 5,
            "creation_date": 1709036132,
            "question_id": 78067486,
            "body_markdown": "I have two pandas DataFrames:\r\n```\r\nimport pandas as pd\r\n\r\ndata1 = {\r\n    &#39;score&#39;: [1, 2],\r\n    &#39;seconds&#39;: [1140, 2100],\r\n}\r\n\r\ndata2 = {\r\n    &#39;prize&#39;: [5.5, 14.5, 14.6, 21, 23, 24, 26, 38, 39, 40, 50],\r\n    &#39;seconds&#39;: [840, 1080, 1380, 1620, 1650, 1680, 1700, 1740, 2040, 2100, 2160],\r\n}\r\n\r\ndf1 = pd.DataFrame.from_dict(data1)\r\ndf2 = pd.DataFrame.from_dict(data2)\r\n\r\nOutput: df1\r\n   score  seconds\r\n0      1     1140\r\n1      2     2100\r\n\r\nOutput: df2\r\n    prize  seconds\r\n0     5.5      840\r\n1    14.5     1080\r\n2    14.6     1380\r\n3    21.0     1620\r\n4    23.0     1650\r\n5    24.0     1680\r\n6    26.0     1700\r\n7    38.0     1740\r\n8    39.0     2040\r\n9    40.0     2100\r\n10   50.0     2160\r\n```\r\n\r\nFor each value in `seconds` column from df1, I would like to get the match (or the closest to) row from df2 and also the closest 2 rows above and below the match.\r\n\r\nThe seconds columns contains only sorted unique values.\r\n\r\nAs result, I expect this:\r\n\r\n```\r\nOutput: result\r\n    prize  seconds\r\n0     5.5      840\r\n1    14.5     1080 # closest match to 1140\r\n2    14.6     1380\r\n3    21.0     1620\r\n7    38.0     1740\r\n8    39.0     2040\r\n9    40.0     2100 # match 2100\r\n10   50.0     2160\r\n```\r\n\r\n",
            "link": "https://stackoverflow.com/questions/78067486/given-a-value-from-a-pandas-column-dataframe-select-n-rows-above-and-below-to-t",
            "title": "Given a value from a pandas column DataFrame, select N rows above and below to that closest value in other DataFrame"
        },
        {
            "tags": [
                "python",
                "numpy",
                "scipy",
                "linear-algebra"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 22039759,
                        "reputation": 305,
                        "user_id": 16305712,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/c197da7ada6b7ed0c8c237d0cf187dd0?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Olivier Gauth&#233;",
                        "link": "https://stackoverflow.com/users/16305712/olivier-gauth%c3%a9"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709059553,
                    "answer_id": 78069881,
                    "question_id": 78067383,
                    "body_markdown": "I remember discussing this issue on [github][1]. The fact that the return order depends on eigenvector is surprising, there is no obvious reason for that, but at least it is documented. As of why exactly, this is how ARPACK works internally, I did not dig into it.\r\n\r\nNow your case abides by the documentation. For case `E1` with `return_eigenvector=False`, you get `abs(E1[i]) &lt; abs(E1[i+1])`. For case `E2` with `return_eigenvector=True`, you have `E2[i]) &lt; E2[i+1])`. Both cases are sorted, but with a different sort depending on `return_eigenvector`. The eigenvectors are sorted according to the eigenvalues. You can always sort them with a different conventions that suits you better:\r\n\r\n```python\r\nE2, V = H.eigsh(k=NEvals, which=&#39;SA&#39;)\r\nso = np.abs(E2).argsort()\r\nE2 = E2[so]\r\nV = V[:, so]\r\n```\r\n\r\nThis is not related to the properties of the input matrix, just a convention in the function.\r\n\r\n  [1]: https://github.com/scipy/scipy/issues/9082",
                    "title": "Algebraic value sorting of eigsh()"
                }
            ],
            "owner": {
                "account_id": 6578169,
                "reputation": 1,
                "user_id": 5083345,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/223fcec8883ee8d9a21f87c54fddd7f4?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "WikawTirso",
                "link": "https://stackoverflow.com/users/5083345/wikawtirso"
            },
            "is_answered": false,
            "view_count": 42,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709035118,
            "question_id": 78067383,
            "body_markdown": "I am using `scipy.sparse.linalg.eigsh()`\r\nto find the first 10 smallest eigenvalues of a large, sparse and Hermitian matrix H. I&#39;m finding the eigenvalues following the [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.eigsh.html)  \r\n&gt; \r\n&gt; For which = \u2018LM\u2019 or \u2018SA\u2019:\r\n&gt; \r\n&gt; If return_eigenvectors is True, eigenvalues are sorted by algebraic value.\r\n&gt; \r\n&gt; If return_eigenvectors is False, eigenvalues are sorted by absolute value.\r\n\r\nThe eigenvalues I get for `H` do not seem to be in any apparent order. For instance, if I am  not returning eigenvectors\r\n\r\n``E1 = H.eigsh(k=10,which=&#39;SA&#39;,maxiter=1E4,return_eigenvectors=False)``\r\n\r\ngives\r\n\r\n``E1: [-5.8445426  -5.87106398 -5.87106398 -5.88635936 -6.37709649 -6.38166066 -6.39249619 -6.39249619 -6.39756682 -6.42135482]``\r\n\r\nIf I am returning eigenvalues via \r\n``E2,V = H.eigsh(k=10,which=&#39;SA&#39;,maxiter=1E4,return_eigenvectors=True)`` \r\nor equally \r\n``E2, V = H.eigsh(k=NEvals, which=&#39;SA&#39;)``\r\n\r\nI get,\r\n\r\n``E2: [-6.42135482 -6.39756682 -6.39249619 -6.38166066 -6.37709649 -6.39249619 -5.88635936 -5.87106398 -5.8445426  -5.87106398]``\r\n\r\n\r\n\r\n\r\nQuestions\r\n\r\n1) In `E1` the eigenvalues are in ascending order. Why do I need to sort the eigenvalues again after I specified `&#39;SA&#39;` to get the smallest eigenvalue?\r\n\r\n2) Why are the eigenvalues in `E2` not in any order? Or better, what does it mean to sort by algebraic value? Do I need to sort  the eigenvalues again or is there reason (perhaps to do with the complex eigenvectors) as to why they&#39;re in this order?\r\n\r\n3) Finally, where I can learn about how (if at all) the eigenvectors affect the order of the eigenvalues? Any explanation with a physics application, where finding the ground state  corresponds to the finding the lowest eigenvalue, is also appreciated. \r\n\r\nI looked for documentation of eigsh.",
            "link": "https://stackoverflow.com/questions/78067383/algebraic-value-sorting-of-eigsh",
            "title": "Algebraic value sorting of eigsh()"
        },
        {
            "tags": [
                "python",
                "python-3.x"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 18005173,
                        "reputation": 14892,
                        "user_id": 13086128,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/VaFAW.png?s=256&g=1",
                        "display_name": "Palestine",
                        "link": "https://stackoverflow.com/users/13086128/palestine"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709040550,
                    "answer_id": 78067922,
                    "question_id": 78067338,
                    "body_markdown": "You need to do it from scratch.\r\n\r\n**Install python 3.11 and create a virtual environment.** \r\n\r\nthen install `fyers-api-v3`\r\n\r\n",
                    "title": "error C2039: &#39;ob_digit&#39;: is not a member of &#39;_longobject&#39; while installing fyers-apiv3"
                }
            ],
            "owner": {
                "account_id": 7228404,
                "reputation": 31,
                "user_id": 5516185,
                "user_type": "registered",
                "accept_rate": 14,
                "profile_image": "https://www.gravatar.com/avatar/5a86172a9f08616ff077133f729d8f7f?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "mona",
                "link": "https://stackoverflow.com/users/5516185/mona"
            },
            "is_answered": false,
            "view_count": 17,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709034566,
            "question_id": 78067338,
            "body_markdown": "I am trying to install fyers-apiv3. but it is giving following error\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n&lt;pre&gt;\r\n     Building wheel for aiohttp (pyproject.toml) ... error\r\n  error: subprocess-exited-with-error\r\n\r\n  &#215; Building wheel for aiohttp (pyproject.toml) did not run successfully.\r\n  \u2502 exit code: 1\r\n  \u2570\u2500&gt; [110 lines of output]\r\n      *********************\r\n      * Accelerated build *\r\n      *********************\r\n      running bdist_wheel\r\n      running build\r\n      running build_py\r\n      creating build\r\n      creating build\\lib.win-amd64-cpython-312\r\n      creating build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\abc.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\base_protocol.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\client.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\client_exceptions.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\client_proto.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\client_reqrep.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\client_ws.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\connector.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\cookiejar.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\formdata.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\hdrs.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\helpers.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\http.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\http_exceptions.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\http_parser.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\http_websocket.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\http_writer.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\locks.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\log.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\multipart.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\payload.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\payload_streamer.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\pytest_plugin.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\resolver.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\streams.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\tcp_helpers.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\test_utils.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\tracing.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\typedefs.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_app.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_exceptions.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_fileresponse.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_log.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_middlewares.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_protocol.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_request.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_response.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_routedef.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_runner.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_server.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_urldispatcher.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\web_ws.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\worker.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\__init__.py -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      running egg_info\r\n      writing aiohttp.egg-info\\PKG-INFO\r\n      writing dependency_links to aiohttp.egg-info\\dependency_links.txt\r\n      writing requirements to aiohttp.egg-info\\requires.txt\r\n      writing top-level names to aiohttp.egg-info\\top_level.txt\r\n      reading manifest file &#39;aiohttp.egg-info\\SOURCES.txt&#39;\r\n      reading manifest template &#39;MANIFEST.in&#39;\r\n      warning: no files found matching &#39;aiohttp&#39; anywhere in distribution\r\n      warning: no previously-included files matching &#39;*.pyc&#39; found anywhere in distribution\r\n      warning: no previously-included files matching &#39;*.pyd&#39; found anywhere in distribution\r\n      warning: no previously-included files matching &#39;*.so&#39; found anywhere in distribution\r\n      warning: no previously-included files matching &#39;*.lib&#39; found anywhere in distribution\r\n      warning: no previously-included files matching &#39;*.dll&#39; found anywhere in distribution\r\n      warning: no previously-included files matching &#39;*.a&#39; found anywhere in distribution\r\n      warning: no previously-included files matching &#39;*.obj&#39; found anywhere in distribution\r\n      warning: no previously-included files found matching &#39;aiohttp\\*.html&#39;\r\n      no previously-included directories found matching &#39;docs\\_build&#39;\r\n      adding license file &#39;LICENSE.txt&#39;\r\n      writing manifest file &#39;aiohttp.egg-info\\SOURCES.txt&#39;\r\n      copying aiohttp\\_cparser.pxd -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\_find_header.pxd -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\_headers.pxi -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\_helpers.pyi -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\_helpers.pyx -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\_http_parser.pyx -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\_http_writer.pyx -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\_websocket.pyx -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      copying aiohttp\\py.typed -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\r\n      creating build\\lib.win-amd64-cpython-312\\aiohttp\\.hash\r\n      copying aiohttp\\.hash\\_cparser.pxd.hash -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\\.hash\r\n      copying aiohttp\\.hash\\_find_header.pxd.hash -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\\.hash\r\n      copying aiohttp\\.hash\\_helpers.pyi.hash -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\\.hash\r\n      copying aiohttp\\.hash\\_helpers.pyx.hash -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\\.hash\r\n      copying aiohttp\\.hash\\_http_parser.pyx.hash -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\\.hash\r\n      copying aiohttp\\.hash\\_http_writer.pyx.hash -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\\.hash\r\n      copying aiohttp\\.hash\\_websocket.pyx.hash -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\\.hash\r\n      copying aiohttp\\.hash\\hdrs.py.hash -&gt; build\\lib.win-amd64-cpython-312\\aiohttp\\.hash\r\n      running build_ext\r\n      building &#39;aiohttp._websocket&#39; extension\r\n      creating build\\temp.win-amd64-cpython-312\r\n      creating build\\temp.win-amd64-cpython-312\\Release\r\n      creating build\\temp.win-amd64-cpython-312\\Release\\aiohttp\r\n      &quot;C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\cl.exe&quot; /c /nologo /O2 /W3 /GL /DNDEBUG /MD &quot;-IC:\\Users\\Alpha Derivatives\\AppData\\Local\\Programs\\Python\\Python312\\include&quot; &quot;-IC:\\Users\\Alpha Derivatives\\AppData\\Local\\Programs\\Python\\Python312\\Include&quot; &quot;-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\include&quot; &quot;-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include&quot; &quot;-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt&quot; &quot;-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.18362.0\\\\um&quot; &quot;-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.18362.0\\\\shared&quot; &quot;-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.18362.0\\\\winrt&quot; &quot;-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.18362.0\\\\cppwinrt&quot; /Tcaiohttp/_websocket.c /Fobuild\\temp.win-amd64-cpython-312\\Release\\aiohttp/_websocket.obj\r\n      _websocket.c\r\n      aiohttp/_websocket.c(1475): warning C4996: &#39;Py_OptimizeFlag&#39;: deprecated in 3.12\r\n      aiohttp/_websocket.c(3042): error C2039: &#39;ob_digit&#39;: is not a member of &#39;_longobject&#39;\r\n      C:\\Users\\Alpha Derivatives\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/longintrepr.h(87): note: see declaration of &#39;_longobject&#39;\r\n      aiohttp/_websocket.c(3097): error C2039: &#39;ob_digit&#39;: is not a member of &#39;_longobject&#39;\r\n      C:\\Users\\Alpha Derivatives\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/longintrepr.h(87): note: see declaration of &#39;_longobject&#39;\r\n      aiohttp/_websocket.c(3238): error C2039: &#39;ob_digit&#39;: is not a member of &#39;_longobject&#39;\r\n      C:\\Users\\Alpha Derivatives\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/longintrepr.h(87): note: see declaration of &#39;_longobject&#39;\r\n      aiohttp/_websocket.c(3293): error C2039: &#39;ob_digit&#39;: is not a member of &#39;_longobject&#39;\r\n      C:\\Users\\Alpha Derivatives\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/longintrepr.h(87): note: see declaration of &#39;_longobject&#39;\r\n      aiohttp/_websocket.c(3744): error C2039: &#39;ob_digit&#39;: is not a member of &#39;_longobject&#39;\r\n      C:\\Users\\Alpha Derivatives\\AppData\\Local\\Programs\\Python\\Python312\\include\\cpython/longintrepr.h(87): note: see declaration of &#39;_longobject&#39;\r\n      error: command &#39;C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.39.33519\\\\bin\\\\HostX86\\\\x64\\\\cl.exe&#39; failed with exit code 2\r\n      [end of output]\r\n\r\n  note: This error originates from a subprocess, and is likely not a problem with pip.\r\n  ERROR: Failed building wheel for aiohttp\r\nFailed to build aiohttp\r\nERROR: Could not build wheels for aiohttp, which is required to install pyproject.toml-based projects\r\n\r\n&lt;/pre&gt;\r\n\r\n\r\nI tried many things but nothing seems to work. I tried installing the beta version of aiohttps \r\n\r\n&lt;pre&gt;\r\n        `$ pip install aiohttp==3.9.0b0`\r\n&lt;/pre&gt;\r\n\r\n\r\n\r\n\r\nthis did not work.\r\nThen I installed pyenv and changed the python version to 3.11.6, still getting the same error. \r\n\r\n&lt;pre&gt;\r\n        `$pyenv install 3.11.6`\r\n        `$pyenv global 3.11.6`\r\n&lt;/pre&gt;\r\n\r\n\r\n\r\n\r\n\r\n\r\ndoes anyone knows what to do here?\r\n\r\n\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/78067338/error-c2039-ob-digit-is-not-a-member-of-longobject-while-installing-fyers",
            "title": "error C2039: &#39;ob_digit&#39;: is not a member of &#39;_longobject&#39; while installing fyers-apiv3"
        },
        {
            "tags": [
                "python",
                "arrays",
                "bin",
                "group"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 8260894,
                        "reputation": 2799,
                        "user_id": 6212350,
                        "user_type": "registered",
                        "accept_rate": 70,
                        "profile_image": "https://i.stack.imgur.com/qXnGn.jpg?s=256&g=1",
                        "display_name": "TheHungryCub",
                        "link": "https://stackoverflow.com/users/6212350/thehungrycub"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709034905,
                    "answer_id": 78067366,
                    "question_id": 78067336,
                    "body_markdown": "Try this :\r\n\r\n    def rebin_array(arr):\r\n        rebinned = []\r\n        current_group = []\r\n        current_sum = 0\r\n        \r\n        for num in arr:\r\n            if current_sum + num &lt;= 10:\r\n                current_group.append(num)\r\n                current_sum += num\r\n            else:\r\n                rebinned.append(current_group)\r\n                current_group = [num]\r\n                current_sum = num\r\n        \r\n        if current_group:\r\n            rebinned.append(current_group)\r\n        \r\n        return rebinned\r\n    \r\n    A = [1,8,2,6,4,8,1,0,1,6,7,3,1,4,9,1,2,1,2,1,1,2]\r\n    A_rebinned = rebin_array(A)\r\n    A_rebinned_sum = [sum(group) for group in A_rebinned]\r\n    \r\n    print(&quot;A_rebinned:&quot;, A_rebinned)\r\n    print(&quot;A_rebinned_sum:&quot;, A_rebinned_sum)",
                    "title": "rebin an array in python to have at least N counts in each entry"
                },
                {
                    "owner": {
                        "account_id": 22084389,
                        "reputation": 223378,
                        "user_id": 16343464,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/7kTic.png?s=256&g=1",
                        "display_name": "mozway",
                        "link": "https://stackoverflow.com/users/16343464/mozway"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709037882,
                    "answer_id": 78067663,
                    "question_id": 78067336,
                    "body_markdown": "You can loop over the items, add the value to current total. If the total passes the threshold, `append` to the output and reset the total. Optionally add the last (incomplete) group to the output:\r\n```\r\nA = [1,8,2,6,4,8,1,0,1,6,7,3,1,4,9,1,2,1,2,1,1,2]\r\n\r\nthreshold = 10\r\n\r\nstart = 0\r\ntotal = 0\r\nout = []\r\nfor end, val in enumerate(A, start=1):\r\n    total += val\r\n    if total &gt;= threshold:\r\n        out.append(A[start:end])\r\n        total = 0\r\n        start = end\r\n\r\n# if you want to add the last incomplete group (if any)\r\nif start &lt; len(A):\r\n    out.append(A[start:])\r\n```\r\nOutput:\r\n```\r\n[[1, 8, 2], [6, 4], [8, 1, 0, 1], [6, 7], [3, 1, 4, 9], [1, 2, 1, 2, 1, 1, 2]]\r\n```",
                    "title": "rebin an array in python to have at least N counts in each entry"
                }
            ],
            "owner": {
                "account_id": 5238640,
                "reputation": 643,
                "user_id": 4186430,
                "user_type": "registered",
                "accept_rate": 54,
                "profile_image": "https://lh4.googleusercontent.com/-ZvVf8me1wWE/AAAAAAAAAAI/AAAAAAAAAFU/wLZvrOhPUnk/photo.jpg?sz=256",
                "display_name": "urgeo",
                "link": "https://stackoverflow.com/users/4186430/urgeo"
            },
            "is_answered": true,
            "view_count": 57,
            "favorite_count": 0,
            "answer_count": 2,
            "score": -1,
            "creation_date": 1709034528,
            "question_id": 78067336,
            "body_markdown": "I have an array as:\r\n\r\n    A = [1,8,2,6,4,8,1,0,1,6,7,3,1,4,9,1,2,1,2,1,1,2]\r\n\r\nand I&#39;d like to rebin/group it into a smaller size array, which has at least a value of `10` in each entry, i.e.:\r\n\r\n    A_reb = [[1,8,2],[6,4],[8,1,0,1],[6,7],[3,1,4,9],[1,2,1,2,1,1,2]]\r\n    A_reb = [11, 10, 10, 13, 17, 10]\r\n\r\nIs there an effective way to do it in python? Thanks in advance.",
            "link": "https://stackoverflow.com/questions/78067336/rebin-an-array-in-python-to-have-at-least-n-counts-in-each-entry",
            "title": "rebin an array in python to have at least N counts in each entry"
        },
        {
            "tags": [
                "python",
                "pandas",
                "time-series"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 22084389,
                        "reputation": 223378,
                        "user_id": 16343464,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/7kTic.png?s=256&g=1",
                        "display_name": "mozway",
                        "link": "https://stackoverflow.com/users/16343464/mozway"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709034572,
                    "answer_id": 78067342,
                    "question_id": 78067319,
                    "body_markdown": "Convert [`to_datetime`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html), [`floor`](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.floor.html) to `10min` and convert back to string:\r\n```\r\nbf_data[&#39;ts&#39;] = (pd.to_datetime(bf_data[&#39;ts&#39;]).dt.floor(&#39;10min&#39;)\r\n                   .dt.strftime(&#39;%Y-%-m-%-d %H:%M:%S&#39;)\r\n                )\r\n```\r\nOutput:\r\n```\r\n                  ts  values\r\n0  2020-1-1 00:00:00     0.2\r\n1  2020-1-1 00:10:00     0.3\r\n2  2020-1-1 00:00:00     0.5\r\n3  2020-1-1 00:10:00     0.9\r\n4  2020-1-1 00:20:00     1.0\r\n```",
                    "title": "find a way to keep size unchangable when i change the time series frequency in pandas"
                }
            ],
            "owner": {
                "account_id": 30642104,
                "reputation": 11,
                "user_id": 23490309,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKMG2YxwlKMEbPVemyQ8-Hbh6i0Ogq6G_XG89q-Pzhg=k-s256",
                "display_name": "green jim",
                "link": "https://stackoverflow.com/users/23490309/green-jim"
            },
            "is_answered": false,
            "view_count": 34,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709034347,
            "question_id": 78067319,
            "body_markdown": "\r\n```\r\nbefore transformation:\r\nbf_data = pd.DataFrame({&quot;ts&quot;:[&#39;2020-1-1 00:03:00&#39;,&#39;2020-1-1 00:12:00&#39;,&#39;2020-1-1 00:07:00&#39;,&#39;2020-1-1 00:18:00&#39;,&#39;2020-1-1 00:22:00&#39;],&#39;values&#39;:[0.2,0.3,0.5,0.9,1]})\r\nafter transformation:\r\naf_data = pd.DataFrame({&quot;ts&quot;:[&#39;2020-1-1 00:00:00&#39;,&#39;2020-1-1 00:10:00&#39;,&#39;2020-1-1 00:00:00&#39;,&#39;2020-1-1 00:10:00&#39;,&#39;2020-1-1 00:20:00&#39;],&#39;values&#39;:[0.2,0.3,0.5,0.9,1]})\r\n```\r\nfirst ,i need keep the size or shape of af_data is same as the bf_data&#39;s\r\nsecond,element in bf_data[&quot;ts&quot;] ,if it&#39;s minute is in [0,10),can be transformed &#39;2020-1-1 00:00:00&#39;,minute is in [10,20) can be transformed &#39;2020-1-1 00:10:00&#39; and so on\r\n",
            "link": "https://stackoverflow.com/questions/78067319/find-a-way-to-keep-size-unchangable-when-i-change-the-time-series-frequency-in-p",
            "title": "find a way to keep size unchangable when i change the time series frequency in pandas"
        },
        {
            "tags": [
                "python",
                "scipy",
                "pycharm",
                "interpreter",
                "site-packages"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 28013234,
                        "reputation": 31,
                        "user_id": 21395404,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/fb4aaa85e9872f20e55937272351cba3?s=256&d=identicon&r=PG",
                        "display_name": "Spike Vinalyan",
                        "link": "https://stackoverflow.com/users/21395404/spike-vinalyan"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709033918,
                    "answer_id": 78067268,
                    "question_id": 78067246,
                    "body_markdown": "Hm, weird. Did you installed with pip or with OS package manager. Anyways, try  the another with you not installed with.\r\n\r\nWith pip is \r\n\r\n    pip install scipy\r\n\r\nwith your OS package manager, normally, the package is named `python-scipy`",
                    "title": "PyCharm: ModuleNotFoundError although module (scipy) is installed"
                }
            ],
            "owner": {
                "account_id": 27109896,
                "reputation": 1,
                "user_id": 20655195,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/e58f8645280b03c1d0fc11190546353c?s=256&d=identicon&r=PG",
                "display_name": "chapatti",
                "link": "https://stackoverflow.com/users/20655195/chapatti"
            },
            "is_answered": false,
            "view_count": 26,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709033604,
            "question_id": 78067246,
            "body_markdown": "I am working with PyCharm and encountered a ModuleNotFoundError when I try running a script that was working about half a year ago. It says: \r\n\r\n```\r\nFile &quot;lalala/main.py&quot;, line 5, in &lt;module&gt;\r\n    import scipy\r\nModuleNotFoundError: No module named &#39;scipy&#39;\r\n```\r\n\r\nI am using PyCharm 2023.3.3 (Community Edition), python 3.10 and scipy 1.12. No virtual environment, all is installed globally. \r\n\r\n\r\n\r\nWhen I check my system, scipy is properly installed in `~/.local/lib/python3.10/site-packages/ `. Also the PyCharms Package Manager can find scipy and the site-packages path is known by PyCharm. I checked the interpreter settings. \r\n\r\nOther site packages like numpy are installed in the same location and are found properly. I can not understand where the scipy problem comes from. \r\n\r\nAny suggestions? ",
            "link": "https://stackoverflow.com/questions/78067246/pycharm-modulenotfounderror-although-module-scipy-is-installed",
            "title": "PyCharm: ModuleNotFoundError although module (scipy) is installed"
        },
        {
            "tags": [
                "python",
                "locust"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 8260894,
                        "reputation": 2799,
                        "user_id": 6212350,
                        "user_type": "registered",
                        "accept_rate": 70,
                        "profile_image": "https://i.stack.imgur.com/qXnGn.jpg?s=256&g=1",
                        "display_name": "TheHungryCub",
                        "link": "https://stackoverflow.com/users/6212350/thehungrycub"
                    },
                    "is_accepted": false,
                    "score": 2,
                    "creation_date": 1709033951,
                    "answer_id": 78067272,
                    "question_id": 78067236,
                    "body_markdown": "When you define the argument using type=bool, it interprets any value provided (such as \u2018False\u2019 or \u2018True\u2019) as True because it only checks if the argument exists, not its value. \r\n\r\n    # locustaction.py\r\n\r\n    @events.init_command_line_parser.add_listener\r\n    def parser_handler(parser):\r\n        parser.add_argument(\r\n            &#39;--loadindex&#39;,\r\n            action=&#39;store_true&#39;,  # Change to action=&#39;store_false&#39; if you want the default to be False\r\n            default=False,\r\n            help=&quot;Loads the index at init&quot;\r\n        )\r\n",
                    "title": "Boolean argument passed to locust script not recognized"
                }
            ],
            "owner": {
                "account_id": 29929886,
                "reputation": 65,
                "user_id": 22937036,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/f234048f002edcaf6d1d27e647890f77?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "vinnewbie",
                "link": "https://stackoverflow.com/users/22937036/vinnewbie"
            },
            "is_answered": true,
            "view_count": 32,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709033485,
            "question_id": 78067236,
            "body_markdown": "I have locust script with the following argument parser:\r\n\r\n\r\n```\r\n# locustaction.py\r\n\r\n@events.init_command_line_parser.add_listener\r\ndef parser_handler(parser):\r\n\r\n    parser.add_argument(\r\n        &#39;--loadindex&#39;,\r\n        type=bool,\r\n        default=False,\r\n        help=&quot;Loads the index at init&quot;\r\n    )\r\n\r\n\r\nclass MyUser(User):\r\n    \r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.loadindex = self.environment.parsed_options.loadindex\r\n\r\n        print(f&quot;self.loadindex={self.loadindex}&quot;)\r\n\r\n```\r\n\r\nI call this from the command line by:\r\n\r\n\r\n```\r\nlocust --headless -f locustaction.py --loadindex=False\r\n```\r\n\r\nHowever, irrespective of whether I set --loadindex=False or --loadindex=True, inside locustaction.py it is always seen as True.\r\n\r\nWhat am I doing wrong?\r\n\r\n\r\nTried with just \r\n```\r\nlocust --headless -f locustaction.py --loadindex\r\n```\r\n\r\nbut got the error message:\r\n\r\n\r\n```\r\nlocust: error: argument --loadindex: expected one argument\r\n```\r\n\r\n",
            "link": "https://stackoverflow.com/questions/78067236/boolean-argument-passed-to-locust-script-not-recognized",
            "title": "Boolean argument passed to locust script not recognized"
        },
        {
            "tags": [
                "python",
                "matplotlib"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30565637,
                        "reputation": 56,
                        "user_id": 23428120,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/c026a5a0d626f9ef8702d6dd887a3619?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "SurajSukale7",
                        "link": "https://stackoverflow.com/users/23428120/surajsukale7"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709038968,
                    "answer_id": 78067773,
                    "question_id": 78067215,
                    "body_markdown": "You can adjust the x-axis ticks and labels to ensure that the value at index 1000 appears in the middle of the plot.\r\n\r\n    import numpy as np\r\n    import matplotlib.pyplot as plt\r\n    \r\n    # Generate x_centered and arr data\r\n    x_centered = np.arange(500, 1501, 1)  # narrower range for demonstration\r\n    arr = np.random.rand(len(x_centered))  # example array data\r\n    \r\n    start_index = 0\r\n    end_index = len(arr) - 1\r\n    \r\n    # Calculate the midpoint index\r\n    midpoint_index = 500  # or 1000 in your case\r\n    \r\n    # Plot the data with a logarithmic x-axis\r\n    plt.semilogx(range(len(x_centered)), arr[start_index:end_index+1], label=&#39;Data&#39;)\r\n    \r\n    # Adjust x-axis ticks and labels\r\n    plt.xticks(ticks=[start_index, midpoint_index, end_index], labels=[f&#39;{x_centered[start_index]}&#39;, f&#39;{x_centered[midpoint_index]}&#39;, f&#39;{x_centered[end_index]}&#39;])\r\n    \r\n    # Add labels and legend\r\n    plt.xlabel(&#39;X Values&#39;)\r\n    plt.ylabel(&#39;Y Values&#39;)\r\n    plt.title(&#39;Logarithmic Plot with Midpoint at Index 1000&#39;)\r\n    plt.legend()\r\n    \r\n    # Show plot\r\n    plt.show()\r\n",
                    "title": "Specify the increase rate of values on a log plot"
                },
                {
                    "owner": {
                        "account_id": 30642014,
                        "reputation": 1,
                        "user_id": 23490235,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/e6eeb79e0a6fd3260b4b5f5180cad572?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "arturmic",
                        "link": "https://stackoverflow.com/users/23490235/arturmic"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709042832,
                    "answer_id": 78068157,
                    "question_id": 78067215,
                    "body_markdown": "O.k. it can be done like this:\r\n\r\n    start_index = 100\r\n    end_index = 10000\r\n\r\n    x = np.arange(100,10000,1)\r\n\r\n\r\n    # Plot the values\r\n    plt.figure(figsize=(10, 6))\r\n    plt.semilogx(x, arr[start_index:end_index+1], label=&#39;Data&#39;)\r\n    plt.title(&#39;Data Plot with Index 1000 in the Middle&#39;)\r\n    plt.xlabel(&#39;Index&#39;)\r\n    plt.ylabel(&#39;Value&#39;)\r\n    plt.grid(True)\r\n    plt.legend()\r\n    plt.show()",
                    "title": "Specify the increase rate of values on a log plot"
                }
            ],
            "owner": {
                "account_id": 30642014,
                "reputation": 1,
                "user_id": 23490235,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/e6eeb79e0a6fd3260b4b5f5180cad572?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "arturmic",
                "link": "https://stackoverflow.com/users/23490235/arturmic"
            },
            "is_answered": false,
            "view_count": 35,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 0,
            "creation_date": 1709033312,
            "question_id": 78067215,
            "body_markdown": "I am trying to plot values from an array in a logartihmic plot. \r\n\r\n\r\nI can achieve this with:\r\n\r\n`plt.semilogx(x_centered, arr[start_index:end_index+1], label=&#39;Data&#39;)`\r\n\r\nBut what I would like to have is the value of index 1000 in the middle of the plot (on x-axis).\r\nWhat would be the best way to achieve this?",
            "link": "https://stackoverflow.com/questions/78067215/specify-the-increase-rate-of-values-on-a-log-plot",
            "title": "Specify the increase rate of values on a log plot"
        },
        {
            "tags": [
                "python",
                "pandas",
                "matplotlib"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 28598629,
                        "reputation": 3199,
                        "user_id": 21896093,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/ThUyh.png?s=256&g=1",
                        "display_name": "Muhammed Yunus",
                        "link": "https://stackoverflow.com/users/21896093/muhammed-yunus"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709041016,
                    "answer_id": 78067962,
                    "question_id": 78067102,
                    "body_markdown": "The example below works for a dataset that&#39;s similar to yours. It scatter plots the two columns after filtering by `keyword`.\r\n\r\nNote that if the data is missing `&quot;Lettuce&quot;` it would result in an empty plot.\r\n\r\nTest data:\r\n```python\r\n\tProduct\tKGs_Purchased\tKGs_Sold\r\n0\tPeas\t6.692863502084602\t5.861591681351845\r\n1\tOranges\t13.40041570647459\t7.865275844481289\r\n2\tCarrots\t2.564579797199695\t0.9015340456777049\r\n3\tCarrots\t6.564341659704407\t3.9147955343374834\r\n4\tLettuce ...\r\n```\r\n\r\n[![enter image description here][1]][1]\r\n\r\nImports and create some test data:\r\n```python\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom matplotlib import pyplot as plt\r\n\r\n#Create test dataset\r\n# data = pd.read_csv(&quot;Task3_data.csv&quot;)  # Reads data\r\nnp.random.seed(0)\r\ndata = pd.DataFrame({\r\n    &#39;Product&#39;: np.random.choice([&#39;Oranges&#39;, &#39;Lemons&#39;, &#39;Lettuce&#39;, &#39;Carrots&#39;, &#39;Peas&#39;], 300),\r\n    &#39;KGs_Purchased&#39;: np.random.uniform(0.1, 1.2, 300) * 20, \r\n}).assign(KGs_Sold=lambda df: df.KGs_Purchased * 0.7 + np.random.randn(300))\r\n```\r\n\r\nThe modified `graph()` function:\r\n```python\r\n#Plotting function\r\ndef graph(data): # Represents certain data as a graph\r\n    keyword = &quot;Lettuce&quot;\r\n    column_name = &quot;Product&quot;\r\n    \r\n    filtered_df = data[data[column_name].str.contains(keyword, case=False, na=False)] # Filters data so only lettuce data is shown \r\n    \r\n    plt.scatter(filtered_df.KGs_Sold, filtered_df.KGs_Purchased)\r\n    plt.xlabel(&#39;KGs_Sold&#39;)\r\n    plt.ylabel(&#39;KGs_Purchased&#39;)\r\n    plt.title(&#39;Filtering by &#39; + column_name + &#39;=&#39; + keyword)\r\n    plt.gcf().set_size_inches(5, 3)\r\n    plt.show()\r\n\r\n#Usage:\r\ngraph(data)\r\n```\r\n\r\n  [1]: https://i.stack.imgur.com/zWsWq.png",
                    "title": "Plotting data from CSV file that has been filtered"
                }
            ],
            "owner": {
                "account_id": 29658961,
                "reputation": 7,
                "user_id": 22731044,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJYgGyAHTcdKCUBvpKOayP3lVTKhQhl4zK9QqSV5ZwW=k-s256",
                "display_name": "Jack Carruthers",
                "link": "https://stackoverflow.com/users/22731044/jack-carruthers"
            },
            "is_answered": false,
            "view_count": 35,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -1,
            "creation_date": 1709032344,
            "question_id": 78067102,
            "body_markdown": "I am aiming to create a program which can plot sales data (not for a real company). The dataset I have is pretty large so I tried filtering it so only one product is shown, there is duplications of each item so there is still quite a few. \r\n\r\nAfter filtering the data I can not seem to get to plot it. I have tried numerous different methods however none have worked. I am very new to pandas and matplotlib so any help would be appreciated.\r\n```python\r\ndef graph(data): # Represents certain data as a graph\r\n        \r\n    plt.rcParams[&quot;figure.figsize&quot;] = [7.50, 3.50]\r\n    plt.rcParams[&quot;figure.autolayout&quot;] = True\r\n\r\n   \r\n    datac = pd.read_csv(&quot;Task3_data.csv&quot;)  # Reads data\r\n\r\n    keyword = &quot;Lettuce&quot;\r\n    column_name = &quot;Product&quot;\r\n    \r\n    filtered_df = datac[datac[column_name].str.contains(keyword, case=False, na=False)] # Filters data so only lettuce data is shown \r\n    \r\n    plt.plot(filtered_df.KGs_Sold, filtered_df.KGs_Purchased)\r\n    plt.show\r\n\r\ngraph(data)\r\n``` \r\n \r\n`KGs_Sold` and `KGs_Purchased` are both columns I am wishing to plot. I could not find anything online to aid me doing this so if anyone can help that would be greatly appreciated, I will attach a photo of my data to help gather a general idea.\r\n\r\n\r\n[Picture of CSV file][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/QGchP.png",
            "link": "https://stackoverflow.com/questions/78067102/plotting-data-from-csv-file-that-has-been-filtered",
            "title": "Plotting data from CSV file that has been filtered"
        },
        {
            "tags": [
                "python",
                "python-3.x",
                "generator"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 8260894,
                        "reputation": 2799,
                        "user_id": 6212350,
                        "user_type": "registered",
                        "accept_rate": 70,
                        "profile_image": "https://i.stack.imgur.com/qXnGn.jpg?s=256&g=1",
                        "display_name": "TheHungryCub",
                        "link": "https://stackoverflow.com/users/6212350/thehungrycub"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709032537,
                    "answer_id": 78067127,
                    "question_id": 78067094,
                    "body_markdown": "When updating the guest dictionary with new guest information. In the line:\r\n\r\n    new_guest_info[&quot;name&quot;]=int(new_guest_info[&quot;age&quot;])\r\n\r\nYou\u2019re updating the \u201cname\u201d key with the age, which is causing the duplication. It should be:\r\n\r\n    new_guest_info[&quot;age&quot;]=int(new_guest_info[&quot;age&quot;])",
                    "title": "Why did adding &#39;Jane&#39; with an age of 35 result in two entries (&#39;name&#39; and &#39;age&#39;) instead of one?"
                }
            ],
            "owner": {
                "account_id": 29919272,
                "reputation": 1,
                "user_id": 22928796,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJILpu15o1LxjwycN7qXL-ZeGj0yMcGmL2EJOW0MPnQtmD7=k-s256",
                "display_name": "Joseph Matheri",
                "link": "https://stackoverflow.com/users/22928796/joseph-matheri"
            },
            "is_answered": true,
            "view_count": 49,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -3,
            "creation_date": 1709032312,
            "question_id": 78067094,
            "body_markdown": "Here is a python code:\r\n```\r\nguests = {}\r\ndef read_guestlist(file_name):\r\n  text_file = open(file_name,&#39;r&#39;)\r\n  while True:\r\n    line_data = text_file.readline().strip().split(&quot;,&quot;)\r\n    if len(line_data) &lt; 2:\r\n    # If no more lines, close file\r\n      text_file.close()\r\n      break\r\n    name = line_data[0]\r\n    age = int(line_data[1])\r\n    guests.update({name:age})\r\n    new_guest_info = yield name\r\n    if new_guest_info and &quot;age&quot; in new_guest_info:\r\n      new_guest_info[&quot;name&quot;]=int(new_guest_info[&quot;age&quot;])\r\n      guests.update(new_guest_info)\r\n      yield new_guest_info[&quot;name&quot;]\r\n  return guests\r\n\r\nguest_generator=read_guestlist(&#39;guest_list.txt&#39;)\r\nfor guest in range(10):\r\n  print(next(guest_generator))\r\n\r\nnew_guest_info={&quot;name&quot;:&quot;Jane&quot;, &quot;age&quot;:35}\r\nnew_guest=guest_generator.send(new_guest_info)\r\nprint(new_guest)\r\nfor guest in guest_generator:\r\n  print(guest)\r\n\r\ndef guests_above_21_generator(guests):\r\n  for guest_name,guest_age in guests.items():\r\n    if guest_age &gt;= 21:\r\n      yield guest_name\r\n\r\nguests_above_21=guests_above_21_generator(guests)\r\nfor guest_name in guests_above_21:\r\n  print(&quot;Yielding guest name:&quot;, guest_name)\r\n```\r\n\r\n\r\n\r\nI needed to add a guest onto the guests dictionally,-{&quot;name&quot;:&quot;Jane&quot; , &quot;age&quot;:35}\r\nHowever, the printout at the end shows what was added was two entries.- named &quot;name&quot; and &quot;age&quot;",
            "link": "https://stackoverflow.com/questions/78067094/why-did-adding-jane-with-an-age-of-35-result-in-two-entries-name-and-age",
            "title": "Why did adding &#39;Jane&#39; with an age of 35 result in two entries (&#39;name&#39; and &#39;age&#39;) instead of one?"
        },
        {
            "tags": [
                "python",
                "deep-learning",
                "pytorch"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 26129282,
                        "reputation": 171,
                        "user_id": 19820238,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/1a597bc6b3546671baaf1bf6384ae51d?s=256&d=identicon&r=PG",
                        "display_name": "OlafdeL",
                        "link": "https://stackoverflow.com/users/19820238/olafdel"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709045552,
                    "answer_id": 78068452,
                    "question_id": 78067070,
                    "body_markdown": "There is very little context in your question. For example, I don&#39;t know which other dependencies you use. However, I encountered the same error before, and with me it was caused by a `botocore` dependency which caused a conflict with `urllib3&gt;=2.0.0`. So, you may want to check your dependencies. Or even better, try `urllib3&lt;2`.\r\n\r\nSee also: https://stackoverflow.com/questions/76414514/cannot-import-name-default-ciphers-from-urllib3-util-ssl-on-aws-lambda-us",
                    "title": "ImportError: cannot import name &#39;DEFAULT_CIPHERS&#39; from &#39;urllib3.util.ssl_&#39;"
                }
            ],
            "owner": {
                "account_id": 30641913,
                "reputation": 1,
                "user_id": 23490158,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJWG9sldkXCjglXlzqwyBjRO2EUPUq6CdPQEIe_ggFI=k-s256",
                "display_name": "adeelryk67",
                "link": "https://stackoverflow.com/users/23490158/adeelryk67"
            },
            "is_answered": false,
            "view_count": 18,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709032063,
            "question_id": 78067070,
            "body_markdown": "How can I solve this error, I&#39;m trying to load dataset locally on jupyter notebook.\r\n\r\n    path=os.path.join(&quot;C:\\\\Users\\\\Adeel\\\\fashion-product-images-small&quot;)\r\n\r\n    from datasets import load_dataset\r\n    print(path)\r\n    fashion = load_dataset(\r\n       path,\r\n        split=&quot;train&quot;\r\n    )\r\n    fashion\r\n\r\nI try to load dataset but on Jupyter notebook, it gives the following error:\r\n\r\n&gt; ImportError: cannot import name &#39;DEFAULT_CIPHERS&#39; from\r\n&gt; &#39;urllib3.util.ssl_&#39;",
            "link": "https://stackoverflow.com/questions/78067070/importerror-cannot-import-name-default-ciphers-from-urllib3-util-ssl",
            "title": "ImportError: cannot import name &#39;DEFAULT_CIPHERS&#39; from &#39;urllib3.util.ssl_&#39;"
        },
        {
            "tags": [
                "python",
                "matplotlib"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 15983509,
                        "reputation": 6416,
                        "user_id": 12131013,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/2ca3cc0afaf24c7597cff635749204ec?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "jared",
                        "link": "https://stackoverflow.com/users/12131013/jared"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709055489,
                    "answer_id": 78069491,
                    "question_id": 78067054,
                    "body_markdown": "You can use `ax.set_xticks` to set the labels corresponding to the x-values. The x-tick locations can be retrieved using `ax.get_xticks`. Simply get the ticks and change the second to last tick to be what you want. The same can be done for the y-ticks, but my example just shows the x-ticks.\r\n\r\n```python\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\nx = np.arange(20)\r\ny = x**2\r\n\r\nfig, ax = plt.subplots()\r\nax.plot(x, y)\r\nxticks = ax.get_xticks()\r\nxtick_labels = list(xticks)\r\nxtick_labels[-2] = &quot;mA&quot;\r\nax.set_xticks(xticks, labels=xtick_labels)\r\n```\r\n\r\n[![][1]][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/asneO.png",
                    "title": "How to always place axis unit in specific tick label position in Matplotlib?"
                }
            ],
            "owner": {
                "account_id": 18860794,
                "reputation": 270,
                "user_id": 13757692,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/788578d3e453fcd3f0a7d916bcf6e4d0?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Alex V.",
                "link": "https://stackoverflow.com/users/13757692/alex-v"
            },
            "is_answered": false,
            "view_count": 39,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709031959,
            "question_id": 78067054,
            "body_markdown": "There is a specific way of including units in graphs that I like:\r\n[![Image from wikipedia][1]][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/541rp.png\r\n\r\nThe image is from Wikipedia, from a page about DIN 461.\r\n\r\nThe unit is always placed in the second to last axis tick. I want to recreate this kind of behaviour using Matplotlib and I have been successful by modifying the xlabels directly using plt.gca().set_xticklabels(). The use of set_xticklabels is however discouraged, because it stops displaying the proper values once you zoom/pan, do whatever with the plot. Instead, I would like to have a solution, where the second to last tick label is always changed to be a unit.\r\n\r\nI tried writing a custom tick label formatter and placing the unit depending on the position. This has not yet worked, due to the different number of ticks that might be shown, depending on the zoom aspect ratio, etc., as well as the fact, that pos is often None, for some reason. Alternatively, I used ax.set_xticks with some formatting function Formatter: ax.set_xticks(ax.get_xticks(), Formatter(ax.get_xticks())), but this shows more ticks than I want and also does not change the ticks when zooming.\r\n\r\n    from matplotlib.ticker import FuncFormatter\r\n\r\n    @FuncFormatter\r\n    def my_formatter(x, pos):\r\n        return f&quot;{x}&quot; if pos != 6 else &#39;Unit&#39;\r\n\r\nIs there a nice way of doing this?",
            "link": "https://stackoverflow.com/questions/78067054/how-to-always-place-axis-unit-in-specific-tick-label-position-in-matplotlib",
            "title": "How to always place axis unit in specific tick label position in Matplotlib?"
        },
        {
            "tags": [
                "python",
                "pandas",
                "folium"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 22441648,
                        "reputation": 1547,
                        "user_id": 16646078,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/BNJXr.jpg?s=256&g=1",
                        "display_name": "e-motta",
                        "link": "https://stackoverflow.com/users/16646078/e-motta"
                    },
                    "is_accepted": true,
                    "score": 0,
                    "creation_date": 1709033053,
                    "answer_id": 78067187,
                    "question_id": 78067050,
                    "body_markdown": "Assuming the dtype of `Breitengrad_x` is `int64`, `row[&quot;Breitengrad_x&quot;]` will give you a value of type `numpy.int64`. That&#39;s what may be causing the problem, since your code runs with the hardcoded values.\r\n\r\nTox fix it, try converting the values into regular `int`:\r\n\r\n```\r\n    ...\r\n    Breitengrad = int(row[&quot;Breitengrad_x&quot;])\r\n    L&#228;ngengrad = int(row[&quot;L&#228;ngengrad_x&quot;])\r\n    ...\r\n```",
                    "title": "Create PolyLines though a loop in Folium / Pandas"
                },
                {
                    "owner": {
                        "account_id": 21824236,
                        "reputation": 31954,
                        "user_id": 16120011,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/NmxUG.jpg?s=256&g=1",
                        "display_name": "Timeless",
                        "link": "https://stackoverflow.com/users/16120011/timeless"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709034993,
                    "answer_id": 78067372,
                    "question_id": 78067050,
                    "body_markdown": "FWIW, iterating through pandas objects is generally slow (*see [here][1]*).\r\n\r\nI would suggest you to make a [`GeoDataFrame`][2] using [`LineString`][3] objects, then [`explore`][4] them to make a folium [`Map`][5] :\r\n\r\n```\r\ngdf = gpd.GeoDataFrame(\r\n    geometry=[\r\n        LineString([extremity, ORIGIN])\r\n        for extremity in dfFilter.to_numpy()[:, ::-1]\r\n        # or hardcoded : dfFilter[[&quot;L&#228;ngengrad_x&quot;, &quot;Breitengrad_x&quot;]].to_numpy()\r\n    ],\r\n    crs=4326,\r\n)\r\n\r\nm = gdf.explore(\r\n    style_kwds={\r\n        &quot;weight&quot;: 5, &quot;color&quot;: &quot;#FF0000&quot;,\r\n    },\r\n    width=700, height=350,\r\n)\r\n```\r\n\r\nOutput (`m`):\r\n\r\n[![enter image description here][6]][6]\r\n\r\nUsed input (`dfFilter`):\r\n```\r\nfrom shapely import LineString\r\nimport geopandas as gpd\r\n\r\nORIGIN = (20, 20) # lon/lat\r\n\r\ndfFilter = pd.DataFrame(\r\n    {\r\n        &quot;Breitengrad_x&quot;: [50, 39, 10, 9],\r\n        &quot;L&#228;ngengrad_x&quot;: [20, -2, 3.5, 38],\r\n    }\r\n)\r\n```\r\n\r\n\r\n  [1]: https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#iteration\r\n  [2]: https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.html\r\n  [3]: https://shapely.readthedocs.io/en/stable/reference/shapely.LineString.html\r\n  [4]: https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.explore.html\r\n  [5]: https://python-visualization.github.io/folium/latest/reference.html#folium.folium.Map\r\n  [6]: https://i.stack.imgur.com/pSUGw.png",
                    "title": "Create PolyLines though a loop in Folium / Pandas"
                }
            ],
            "owner": {
                "account_id": 21573618,
                "reputation": 57,
                "user_id": 15906138,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/17043b3ef2af5efe8b9b18c85317b82a?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Andi3579",
                "link": "https://stackoverflow.com/users/15906138/andi3579"
            },
            "is_answered": true,
            "view_count": 29,
            "favorite_count": 0,
            "accepted_answer_id": 78067187,
            "answer_count": 2,
            "score": 0,
            "creation_date": 1709031948,
            "question_id": 78067050,
            "body_markdown": "I try to create multiple lines from a Dataframe in JupyterLab while looping. I have created the following code but every time I try to run it, my Jupyter Notebook crashes and tell me that the Kernel has died. What am I missing here?\r\n\r\n    m = folium.Map(location=[VstBreitengrad, VstL&#228;ngengrad], max_zoom=20, zoom_start=5)\r\n    \r\n    for index, row in dfFilter.iterrows():\r\n    \r\n        Breitengrad = row[&quot;Breitengrad_x&quot;]\r\n        L&#228;ngengrad = row[&quot;L&#228;ngengrad_x&quot;]\r\n    \r\n        coordinates = [\r\n                    [Breitengrad, L&#228;ngengrad],\r\n                    [20, 20]\r\n        ]\r\n                   \r\n        folium.PolyLine(\r\n                locations=coordinates,\r\n                color=&quot;#FF0000&quot;,\r\n                weight=5,\r\n        ).add_to(m)\r\n    \r\n    m\r\n\r\nBreitengrad_x and L&#228;ngengrad_x are the columns in the dataframe from where I&#39;ll get the coordinates. If I hardcode the coordinates like\r\n\r\n    Breitengrad = 50 #row[&quot;Breitengrad_x&quot;]\r\n    L&#228;ngengrad = 20 #row[&quot;L&#228;ngengrad_x&quot;]\r\n\r\nthe code runs without a problem. Thanks a lot for your ideas / solutions.",
            "link": "https://stackoverflow.com/questions/78067050/create-polylines-though-a-loop-in-folium-pandas",
            "title": "Create PolyLines though a loop in Folium / Pandas"
        },
        {
            "tags": [
                "python",
                "selenium-webdriver",
                "web-scraping",
                "selenium-chromedriver"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 2772450,
                        "reputation": 22632,
                        "user_id": 2386774,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/dea7da142cb7e85d5d5a8576e2625431?s=256&d=identicon&r=PG",
                        "display_name": "JeffC",
                        "link": "https://stackoverflow.com/users/2386774/jeffc"
                    },
                    "is_accepted": true,
                    "score": 0,
                    "creation_date": 1709047277,
                    "answer_id": 78068647,
                    "question_id": 78067018,
                    "body_markdown": "The source of the issue is that you are looping through all rows using\r\n\r\n    for i in range(number_of_pages_to_enter):\r\n\r\nbut you aren&#39;t using `i`, you are using `number_of_pages_to_enter`.\r\n\r\n----\r\n\r\nHaving said that, you are spending a lot of time/code parsing, calculating, building strings, etc. to loop through the table when there&#39;s a much simpler way. You just build a locator to the elements you want, use `find_elements(locator)`, and then loop through that group of elements.\r\n\r\nAlso, you are clicking the link to go to the next page to get who is playing in the game, e.g. &quot;Cleveland - Dallas&quot;, but that info is already on the first page.\r\n\r\n    Kos&#225;rlabda, NBA\r\n    Cleveland - Dallas &lt;&lt;&lt;\r\n    02.27. 18:00\r\n\r\nI modified your code to get you this without having to click anything, leave the page and return, etc.\r\n\r\n    url = &#39;https://www.tippmix.hu/sportfogadas#?q=nba&amp;page=1&#39;\r\n    driver = webdriver.Chrome()\r\n    driver.maximize_window()\r\n    driver.get(url)\r\n\r\n    wait = WebDriverWait(driver, 10)\r\n    games = wait.until(EC.visibility_of_all_elements_located((By.XPATH, &quot;//tbody/tr/td[3][@class=&#39;title&#39;]/a&quot;)))\r\n    for game in games:\r\n        print(game.text.split(&quot;\\n&quot;)[1])\r\n\r\nOutput\r\n\r\n    Cleveland - Dallas\r\n    Washington - Golden State\r\n    Orlando - Brooklyn       \r\n    New York - New Orleans   \r\n    Atlanta - Utah\r\n    Boston - Philadelphia\r\n    Milwaukee - Charlotte\r\n    Chicago - Detroit    \r\n    Minnesota - San Antonio\r\n    Oklahoma City - Houston\r\n    Portland - Miami\r\n    Hard - B&#228;rnbach/K&#246;flach\r\n    NBA 2023/24",
                    "title": "Issue using selenenium WebDriver to get text data"
                }
            ],
            "owner": {
                "account_id": 30215219,
                "reputation": 3,
                "user_id": 23156251,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/3feaa7a442c4154df11903139275ab1c?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "tompoc",
                "link": "https://stackoverflow.com/users/23156251/tompoc"
            },
            "is_answered": true,
            "view_count": 21,
            "favorite_count": 0,
            "accepted_answer_id": 78068647,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709031618,
            "question_id": 78067018,
            "body_markdown": "I have successfully navigated to a websites page, that has multiple links to more pages. In my code I count the number of links, than convert it to xpath, so I can enter all the pages. It all works fine, until I try to get anything out of these pages. All of them have the exact form factor, so I should be able to use the same xpath inside the pages.\r\n**\r\nHere is the section of the code that fails:**\r\n\r\n```\r\nxpath_expression = &#39;//*[@id=&quot;wrapper&quot;]/main/section/div/div[2]/table/tbody&#39;\r\nelement = browser.find_element(&quot;xpath&quot;, xpath_expression)\r\nhtml_code = element.get_attribute(&quot;outerHTML&quot;)\r\nnumber_of_pages_to_enter= html_code.count(&quot;&lt;tr&quot;)\r\nnumber_of_pages_to_enter=number_of_pages_to_enter-2\r\nxpatht_eleje=&#39;//*[@id=&quot;wrapper&quot;]/main/section/div/div[2]/table/tbody/tr[&#39;\r\n\r\n\r\ncimek=&#39;&#39;\r\nfor i in range(number_of_pages_to_enter):\r\n    number_of_pages_to_enter_str=str(number_of_pages_to_enter)\r\n    number_of_pages_to_enter_str=number_of_pages_to_enter_str+&quot;]/td[3]/a&quot;\r\n    xpath_expression=xpatht_eleje+number_of_pages_to_enter_str\r\n    button_locator = (&quot;xpath&quot;, xpath_expression)\r\n    button = WebDriverWait(browser, 5).until(\r\n        EC.presence_of_element_located(button_locator)\r\n    )\r\n    button.click()\r\n    time.sleep(0.5)\r\n    element = browser.find_element(By.XPATH, &#39;//*[@id=&quot;eventHeader&quot;]/div[2]/div/h1&#39;)\r\n    cim=element.text\r\n    cimek=cim+cim\r\n    if number_of_pages_to_enter&gt;0:\r\n        number_of_pages_to_enter=number_of_pages_to_enter-1\r\n    browser.back()\r\n```\r\nHere is the link of the page I am testing my code on:[text](https://www.tippmix.hu/sportfogadas#?q=nba&amp;page=1)\r\nThe string called cimek, is where I try to collect the data.\r\n\r\n\r\nI have already tried using other locators, then xpath, none works. The result that I get is only one element.",
            "link": "https://stackoverflow.com/questions/78067018/issue-using-selenenium-webdriver-to-get-text-data",
            "title": "Issue using selenenium WebDriver to get text data"
        },
        {
            "tags": [
                "python",
                "python-3.x"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 10109239,
                        "reputation": 4595,
                        "user_id": 7470786,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/h3dim.png?s=256&g=1",
                        "display_name": "Rarblack",
                        "link": "https://stackoverflow.com/users/7470786/rarblack"
                    },
                    "is_accepted": false,
                    "score": -1,
                    "creation_date": 1709028183,
                    "answer_id": 78066639,
                    "question_id": 78066598,
                    "body_markdown": "I assume you are having a loop and inside the loop, you are making actions such as shooting/hitting which eventually decreases the health. And the desire to have that loop going till health hits 0.\r\n\r\n    health = 100\r\n    hit_amount = 20\r\n\r\n    while(health &gt; 0):\r\n        health -= hit_amount\r\n\r\n`health -= hit_amount` is equal to `health = health - hit_amount` which decreases health by 20 in each loop cycle.",
                    "title": "Is there a way to continuously update the value of a variable, so i can keep subtracting from the new value?"
                }
            ],
            "owner": {
                "account_id": 30640904,
                "reputation": 1,
                "user_id": 23489342,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJgQD43KTz_lKfBv_YfOg0bJL-E35YnoZtnJXa7zU3F=k-s256",
                "display_name": "Sam M",
                "link": "https://stackoverflow.com/users/23489342/sam-m"
            },
            "is_answered": false,
            "view_count": 52,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -2,
            "creation_date": 1709027752,
            "question_id": 78066598,
            "body_markdown": "Hello I&#39;m new to python (taking a intro to python class).Im messing around and attempting to make a short d&amp;d battle. The goal is for the random dice roll to determine if the player misses or hits, and for that loop to continue until the health of the knight or monster hit zero\r\n```python\r\nfrom random import randint \r\n# knight defence 10, monster1 defence 5\r\n# Stats dictionaries ------------------------\r\nknight = {&#39;health&#39;:100,&#39;attack&#39;:20}\r\ntroll = {&#39;health&#39;:50,&#39;attack&#39;:10}\r\n# -------------------------------------------\r\nnew_health = knight[&quot;health&quot;] - troll[&#39;attack&#39;]\r\nnew_health2 = troll[&quot;health&quot;] - knight[&#39;attack&#39;]\r\ndice = randint(0,20)\r\naction = input(&quot;will you fight or flee:&quot;)\r\n# ------------------------------\r\nif action == &#39;fight&#39;:\r\n    while knight[&#39;health&#39;] &gt;= 1 or troll[&#39;health&#39;] &gt;= 1:\r\n       \r\n        if dice &gt;= 5:\r\n            print(&#39;your hit landed!troll health:&#39;,new_health2)\r\n        else:\r\n            print(&#39;your hit missed!knight health:&#39;,new_health)\r\nelse:\r\n    print(&#39;you ran away&#39;)\r\n```\r\nThis code works fine without the while statement. My question is , **Is there a way to update the health after the attack has been subtacted?**\r\n\r\nWhat im trying to do:\r\nhealth starts at 100 When hit misses subtract 10 new health = 90 and so on until health &lt;= 0.\r\n\r\nAgain im just starting so this is probably very messy. I&#39;ve tried things like \r\n\r\n```python\r\nknight[&#39;health&#39;] = knight[&#39;health&#39;]-troll[&#39;attack&#39;]\r\n```\r\nbut it does nothing. I&#39;ve also tried adding a break but that stops th program completely. these are i think the closest solutions everything else were wild shots in the dark.",
            "link": "https://stackoverflow.com/questions/78066598/is-there-a-way-to-continuously-update-the-value-of-a-variable-so-i-can-keep-sub",
            "title": "Is there a way to continuously update the value of a variable, so i can keep subtracting from the new value?"
        },
        {
            "tags": [
                "python",
                "machine-learning",
                "import",
                "kaggle",
                "modulenotfounderror"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 22963121,
                        "reputation": 337,
                        "user_id": 17092646,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/448830e694a3bdb4a9b7e2a533afe367?s=256&d=identicon&r=PG",
                        "display_name": "Ugochukwu Obinna",
                        "link": "https://stackoverflow.com/users/17092646/ugochukwu-obinna"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709027615,
                    "answer_id": 78066587,
                    "question_id": 78066569,
                    "body_markdown": "you made a typo error, it meant to be \r\n\r\n    import seaborn as sns\r\n    \r\nbut you use \r\n    \r\n    import seaburn as sns",
                    "title": "ModuleNotFoundError: No module named &#39;seaburn&#39; in Kaggle&#39;s Notebook"
                }
            ],
            "owner": {
                "account_id": 22607824,
                "reputation": 3,
                "user_id": 16788471,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/282ca02a58556f6f34a678e60b78c473?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Tudor Radu",
                "link": "https://stackoverflow.com/users/16788471/tudor-radu"
            },
            "is_answered": true,
            "view_count": 28,
            "favorite_count": 0,
            "accepted_answer_id": 78066587,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709027450,
            "question_id": 78066569,
            "body_markdown": "Using Kaggle&#39;s notebook, the imports seem to be working just fine, except seaburn.\r\n```\r\nimport numpy as np \r\nimport pandas as pd \r\nimport matplotlib.pyplot as plt \r\nimport seaburn as sns\r\n```\r\n\r\nThis is what I get from running the previous code:\r\n```\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\nCell In[21], line 4\r\n      2 import pandas as pd \r\n      3 import matplotlib.pyplot as plt \r\n----&gt; 4 import seaburn as sns\r\n      6 df = pd.read_csv(&#39;/kaggle/input/iris-flower-dataset/IRIS.csv&#39;)\r\n      7 print(df.head())\r\n\r\nModuleNotFoundError: No module named &#39;seaburn&#39;\r\n```\r\nAm I missing something?",
            "link": "https://stackoverflow.com/questions/78066569/modulenotfounderror-no-module-named-seaburn-in-kaggles-notebook",
            "title": "ModuleNotFoundError: No module named &#39;seaburn&#39; in Kaggle&#39;s Notebook"
        },
        {
            "tags": [
                "python"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 13900216,
                        "reputation": 184517,
                        "user_id": 10035985,
                        "user_type": "registered",
                        "profile_image": "https://lh4.googleusercontent.com/-1WgJ_2yA-78/AAAAAAAAAAI/AAAAAAAAAOA/0CBOlYqYe7M/photo.jpg?sz=256",
                        "display_name": "Andrej Kesely",
                        "link": "https://stackoverflow.com/users/10035985/andrej-kesely"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709027215,
                    "answer_id": 78066543,
                    "question_id": 78066495,
                    "body_markdown": "You can use [`np.c_`][1] (similar, `np.r_` for rows):\r\n\r\n```py\r\nA = np.zeros(shape=(10, 1))\r\nB = np.ones(shape=(10, 1))\r\n\r\nout = np.c_[A, B]\r\nprint(out)\r\n```\r\n\r\nPrints:\r\n\r\n```none\r\n[[0. 1.]\r\n [0. 1.]\r\n [0. 1.]\r\n [0. 1.]\r\n [0. 1.]\r\n [0. 1.]\r\n [0. 1.]\r\n [0. 1.]\r\n [0. 1.]\r\n [0. 1.]]\r\n```\r\n\r\n\r\n  [1]: https://numpy.org/doc/stable/reference/generated/numpy.c_.html#numpy.c_",
                    "title": "Assign a variable as a column of an array"
                }
            ],
            "owner": {
                "account_id": 30641140,
                "reputation": 19,
                "user_id": 23489540,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKplndHDfVyoiAzv1o-pAGFHiV5cutJDRwYLNH3grs=k-s256",
                "display_name": "PW14",
                "link": "https://stackoverflow.com/users/23489540/pw14"
            },
            "is_answered": false,
            "view_count": 43,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709026826,
            "question_id": 78066495,
            "body_markdown": "Consider having an array variable, A, with the shape of (100,1). It is intended to put another array variable named B with the same shape as that of A in the second column of A. In MATLAB, it is simply possible to do so by executing A(:,2) = B but I don&#39;t know how to handle it in Python. I would be grateful for your help.\r\n\r\nIt won&#39;t matter for me if we can define a new variable, C, and put A in its first column and B in its second one.\r\n\r\nI have tried using some ways but they haven&#39;t worked.",
            "link": "https://stackoverflow.com/questions/78066495/assign-a-variable-as-a-column-of-an-array",
            "title": "Assign a variable as a column of an array"
        },
        {
            "tags": [
                "python",
                "pytorch",
                "pytorch-geometric"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 7540103,
                        "reputation": 89,
                        "user_id": 16680828,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/9a6b51c1b3467a3df611213c94108066?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "mknull",
                        "link": "https://stackoverflow.com/users/16680828/mknull"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709030673,
                    "answer_id": 78066911,
                    "question_id": 78066450,
                    "body_markdown": "This snippet should take less on the ground that it does fewer operations. \r\n\r\n    p=0.5\r\n    D=[19000,19000]\r\n    torch.rand(D)&gt;p\r\n\r\nAs D increases, the mean approaches p.",
                    "title": "Create a binary pytorch tensor with n% ones"
                }
            ],
            "owner": {
                "account_id": 4708300,
                "reputation": 2929,
                "user_id": 3809691,
                "user_type": "registered",
                "accept_rate": 36,
                "profile_image": "https://graph.facebook.com/100001763021303/picture?type=large",
                "display_name": "Adnan Ali",
                "link": "https://stackoverflow.com/users/3809691/adnan-ali"
            },
            "is_answered": true,
            "view_count": 32,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709026412,
            "question_id": 78066450,
            "body_markdown": "I want to create a binary tensor with 0 and 1s only, but the number of 1s should be n%.\r\n\r\nI am using this code, but it takes 7+ seconds and has 19926MB of memory.\r\n\r\nIs there any faster way to do that?\r\n\r\n\r\n```\r\nimport torch\r\nimport time\r\nstart_time = time.time()\r\ndef create_random_binary_tensor(shape, percentage, device):\r\n    size = shape[0] * shape[1]\r\n    num_ones = int(size * (percentage / 100.0))\r\n    \r\n    # Create a tensor filled with zeros\r\n    tensor = torch.zeros(size, dtype=torch.float32, device=device)\r\n    \r\n    # Set random indices to ones until the desired number of ones is reached\r\n    indices = torch.randperm(size, device=device)[:num_ones]\r\n    tensor[indices] = 1\r\n    \r\n    # Reshape the tensor to the desired shape\r\n    tensor = tensor.view(shape)\r\n    \r\n    return tensor\r\n\r\n# Set the shape and percentage of ones\r\nshape = (19000, 19000)\r\npercentage = 0.5\r\n\r\n# Check if CUDA is available and use it if possible\r\ndevice = torch.device(&quot;cuda:2&quot; if torch.cuda.is_available() else &quot;cpu&quot;)\r\n\r\n# Create the random binary tensor\r\ntensor = create_random_binary_tensor(shape, percentage, device)\r\n\r\n# Print the tensor\r\nexecution_time = time.time() - start_time\r\nprint(&quot;Execution Time: {:.4f} seconds&quot;.format(execution_time))\r\n\r\n```",
            "link": "https://stackoverflow.com/questions/78066450/create-a-binary-pytorch-tensor-with-n-ones",
            "title": "Create a binary pytorch tensor with n% ones"
        },
        {
            "tags": [
                "python",
                "azure-active-directory",
                "auth0",
                "okta"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 24283882,
                        "reputation": 8923,
                        "user_id": 18229928,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/xeNOh.jpg?s=256&g=1",
                        "display_name": "Rukmini",
                        "link": "https://stackoverflow.com/users/18229928/rukmini"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709028367,
                    "answer_id": 78066657,
                    "question_id": 78066329,
                    "body_markdown": "To increase the token lifetime of the Azure AD access token, you can make use of Microsoft Graph Explorer or PowerShell:\r\n```json\r\nPOST https://graph.microsoft.com/v1.0/policies/tokenLifetimePolicies\r\nContent-type: application/json\r\n\r\n{\r\n    &quot;definition&quot;: [\r\n        &quot;{\\&quot;TokenLifetimePolicy\\&quot;:{\\&quot;Version\\&quot;:1,\\&quot;AccessTokenLifetime\\&quot;:\\&quot;23:59:59\\&quot;}}&quot;\r\n    ],\r\n    &quot;displayName&quot;: &quot;token lifetime policy&quot;,\r\n    &quot;isOrganizationDefault&quot;: true\r\n}\r\n```\r\n\r\n![enter image description here](https://i.imgur.com/c6gkV0E.png)\r\n\r\nFor **sample**, I generated access token and the token lifetime is 24 hours:\r\n```json\r\nhttps://login.microsoftonline.com/TenantID/oauth2/v2.0/token\r\n\r\nclient_id:ClientID\r\nclient_secret:ClientSecret\r\ngrant_type:client_credentials\r\nscope:https://graph.microsoft.com/.default\r\n```\r\n\r\n![enter image description here](https://i.imgur.com/661hkIt.png)\r\n\r\n**Note** that: The Azure AD access token lifetime can be set withing 10 mins to 24 hours.\r\n\r\n- You can assign the token lifetime policy to a Service Principal instead of whole organization. Check this [**MsDoc**](https://learn.microsoft.com/en-us/entra/identity-platform/configure-token-lifetimes#create-a-policy-and-assign-it-to-a-service-principal)\r\n- You can also make use of below PowerShell script instead of Microsoft Graph Explorer. Refer this [**MsDoc**](https://learn.microsoft.com/en-us/powershell/module/microsoft.graph.identity.signins/new-mgpolicytokenlifetimepolicy?view=graph-powershell-1.0#example-1-code-snippet)\r\n- Make sure to have **`Policy.ReadWrite.ApplicationConfiguration`** permission consented to perform the action.",
                    "title": "from okta auth0 how can i increase the azure ad token validity?"
                }
            ],
            "owner": {
                "account_id": 19064587,
                "reputation": 142,
                "user_id": 13919925,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/vAAUv.jpg?s=256&g=1",
                "display_name": "sandeepsinghnegi",
                "link": "https://stackoverflow.com/users/13919925/sandeepsinghnegi"
            },
            "is_answered": true,
            "view_count": 62,
            "favorite_count": 0,
            "accepted_answer_id": 78066657,
            "answer_count": 1,
            "score": -1,
            "creation_date": 1709025296,
            "question_id": 78066329,
            "body_markdown": "I&#39;m using Okta as the identity provider for user management and have integrated Azure AD with Auth0 for authentication. However, when i retrieve user information after authentication using this API of auth0\r\n```\r\nurl = &#39;https://&#39; + AUTH0_DOMAIN + &#39;/api/v2/users/&#39; + user_id\r\n```\r\nI notice that the providers access token remains the same each time I call the API.\r\nIs there a way to get different token. If not, then how can i increase the expiry time of provider access token \r\nas My auth0 expiry time is 72hr and azure ad is 1hr.\r\n\r\nI have used this but it didn&#39;t help me :\r\nhttps://learn.microsoft.com/en-us/entra/identity-platform/configure-token-lifetimes#create-a-policy-and-assign-it-to-a-service-principal",
            "link": "https://stackoverflow.com/questions/78066329/from-okta-auth0-how-can-i-increase-the-azure-ad-token-validity",
            "title": "from okta auth0 how can i increase the azure ad token validity?"
        },
        {
            "tags": [
                "python",
                "visual-studio-code",
                "data-science",
                "biopython"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 11064698,
                        "reputation": 1487,
                        "user_id": 9659620,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/f3e4eef6e25a850993af24243cfff530?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Klops",
                        "link": "https://stackoverflow.com/users/9659620/klops"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709025313,
                    "answer_id": 78066331,
                    "question_id": 78066305,
                    "body_markdown": "You probably use pip that does not &quot;belong&quot; to your python. Maybe you got confused with python environments.\r\n\r\n`which pip` will help you to understand which pip is used.\r\n\r\nif you want to make sure it is the one belonging to your current python. Install with `python -m pip install packagename`\r\n\r\nAs you name vscode: If you are using interactive python (the line-by-line execution of python code), make sure you [select the right kernel][1]:\r\n\r\n[![enter image description here][2]][2]\r\n\r\n\r\n  [1]: https://code.visualstudio.com/docs/datascience/jupyter-kernel-management\r\n  [2]: https://i.stack.imgur.com/gkcav.png",
                    "title": "no module found even after installation of any module for python"
                }
            ],
            "owner": {
                "account_id": 30178258,
                "reputation": 1,
                "user_id": 23127227,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocLTUfEMZk3bqu843amoqweA0I9oqn93LmVmMbMgpMbR6Qk=k-s256",
                "display_name": "Gitanjali kulkarni",
                "link": "https://stackoverflow.com/users/23127227/gitanjali-kulkarni"
            },
            "is_answered": true,
            "view_count": 57,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709025098,
            "question_id": 78066305,
            "body_markdown": "I am using VS code and python 3.10.5 with pip 24.0. I am getting error of nomodulefound even after installing. I want to use biopython and sciki-allele. I have created virtual environment too. Your help will be valuable. Thank you!\r\n\r\n\r\nI tried different solutions which were previously given. like &#39;pip3 install biopython&#39;. Also I am using windows10\r\n\r\n\r\n\r\n[for reference][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/At4Yz.png",
            "link": "https://stackoverflow.com/questions/78066305/no-module-found-even-after-installation-of-any-module-for-python",
            "title": "no module found even after installation of any module for python"
        },
        {
            "tags": [
                "python",
                "path",
                "subdirectory"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 15030224,
                        "reputation": 358,
                        "user_id": 12404101,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/58a51a528fae0634540a44014e06d796?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "onlinejudge95",
                        "link": "https://stackoverflow.com/users/12404101/onlinejudge95"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709024989,
                    "answer_id": 78066297,
                    "question_id": 78066260,
                    "body_markdown": "This can be solved using pathlib. Here is a straightforward solution for the same.\r\n\r\n\r\n```python\r\nimport pathlib\r\n\r\n\r\npath1 = pathlib.Path(&quot;/path/to/2012-01-01/files/2014-01-31/la.parquet&quot;)\r\nprint(path1.parent.name if not path1.is_dir() else path1.name)\r\n```\r\n\r\n**[EDIT]**:- Handling cases when the last path can be a directory or a file\r\n\r\nReference\r\n\r\n - https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.parent\r\n - https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.name",
                    "title": "In python how do you get the &quot;last&quot; directory in a path string?"
                },
                {
                    "owner": {
                        "account_id": 10326336,
                        "reputation": 84,
                        "user_id": 7617697,
                        "user_type": "registered",
                        "accept_rate": 80,
                        "profile_image": "https://i.stack.imgur.com/U3XFq.png?s=256&g=1",
                        "display_name": "olizimmermann",
                        "link": "https://stackoverflow.com/users/7617697/olizimmermann"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709025050,
                    "answer_id": 78066300,
                    "question_id": 78066260,
                    "body_markdown": "Probably something like this:\r\n\r\n```python\r\npathlib.Path(path).parent if not os.path.isdir(path) else pathlib.Path(path)\r\n```\r\n[![enter image description here][1]][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/yDAu4.png",
                    "title": "In python how do you get the &quot;last&quot; directory in a path string?"
                },
                {
                    "owner": {
                        "account_id": 4922180,
                        "reputation": 513,
                        "user_id": 3964482,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/c10105dd27ad296ccf48668fa195b085?s=256&d=identicon&r=PG",
                        "display_name": "Jatinder Kumar",
                        "link": "https://stackoverflow.com/users/3964482/jatinder-kumar"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709025193,
                    "answer_id": 78066321,
                    "question_id": 78066260,
                    "body_markdown": "You can use following code to get last directory name:\r\n\r\n    import os\r\n\tpath = &quot;/path/to/your/directory&quot;\r\n\tlast_directory = os.path.basename(os.path.dirname(path))\r\n\tprint(last_directory)\r\n\r\nYou have to make sure directory name is post fixed by directory separator, otherwise it will be considered as file.",
                    "title": "In python how do you get the &quot;last&quot; directory in a path string?"
                },
                {
                    "owner": {
                        "account_id": 6020437,
                        "reputation": 11687,
                        "user_id": 4727702,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/QlkUd.jpg?s=256&g=1",
                        "display_name": "Yevhen Kuzmovych",
                        "link": "https://stackoverflow.com/users/4727702/yevhen-kuzmovych"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709025654,
                    "answer_id": 78066370,
                    "question_id": 78066260,
                    "body_markdown": "Technically `la.parquet` is a valid directory name, so there&#39;s no way to tell just from the string, you&#39;ll need to introduce some manual logic. E.x. check for &#39;.&#39; in the name.\r\n\r\n```\r\n&gt;&gt;&gt; import pathlib\r\n&gt;&gt;&gt; p = pathlib.Path(path1)\r\n&gt;&gt;&gt; p.parent.name if &#39;.&#39; in p.name else p.name\r\n&#39;2014-01-31&#39;\r\n&gt;&gt;&gt; p = pathlib.Path(path2)\r\n&gt;&gt;&gt; p.parent.name if &#39;.&#39; in p.name else p.name\r\n&#39;2014-01-31&#39;\r\n&gt;&gt;&gt; p = pathlib.Path(path3)\r\n&gt;&gt;&gt; p.parent.name if &#39;.&#39; in p.name else p.name\r\n&#39;2014-01-31&#39;\r\n```\r\n\r\nYou can be more precise (e.x. check `&#39;.parquet&#39; in p.name`) if needed.\r\n ",
                    "title": "In python how do you get the &quot;last&quot; directory in a path string?"
                },
                {
                    "owner": {
                        "account_id": 1817378,
                        "reputation": 3464,
                        "user_id": 1652219,
                        "user_type": "registered",
                        "accept_rate": 87,
                        "profile_image": "https://i.stack.imgur.com/Kr8S0.jpg?s=256&g=1",
                        "display_name": "Esben Eickhardt",
                        "link": "https://stackoverflow.com/users/1652219/esben-eickhardt"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709033218,
                    "answer_id": 78067202,
                    "question_id": 78066260,
                    "body_markdown": "I expected there to be a function like &quot;basename&quot; to resolve this, but I guess as @Jatinder says, there is no way to differentiate between &quot;directory name&quot; and &quot;filename without extension&quot; without having access to the filesystem. \r\n\r\nI ended up just using regex for my specific use-case, and I guess if example 3 was left out there would be a general solution checking for strings ending with &quot;/&quot;.\r\n\r\nHere my solution:\r\n\r\n    import re\r\n    \r\n    # Examples\r\n    path1 = &quot;/path/to/2012-01-01/files/2014-01-31/la.parquet&quot;\r\n    path2 = &quot;/path/to/2012-01-01/files/2014-01-31/&quot;\r\n    path3 = &quot;/path/to/2012-01-01/files/2014-01-31&quot;\r\n    \r\n    # Find match\r\n    for path in [path1, path2, path3]:\r\n       print(re.search(r&#39;.*(\\d{4}-\\d{2}-\\d{2})&#39;, path).group(1))",
                    "title": "In python how do you get the &quot;last&quot; directory in a path string?"
                }
            ],
            "owner": {
                "account_id": 1817378,
                "reputation": 3464,
                "user_id": 1652219,
                "user_type": "registered",
                "accept_rate": 87,
                "profile_image": "https://i.stack.imgur.com/Kr8S0.jpg?s=256&g=1",
                "display_name": "Esben Eickhardt",
                "link": "https://stackoverflow.com/users/1652219/esben-eickhardt"
            },
            "is_answered": true,
            "view_count": 80,
            "favorite_count": 0,
            "accepted_answer_id": 78066370,
            "answer_count": 5,
            "score": -3,
            "creation_date": 1709024564,
            "question_id": 78066260,
            "body_markdown": "I am working on a remote file system, where I don&#39;t have direct access to the files/directories, so I cannot check if a string represents a file or a directory. \r\n\r\nI have the following paths I need to handle, where I have to get a hold of the &quot;partition column&quot;:\r\n\r\n    path1 = &quot;/path/to/2012-01-01/files/2014-01-31/la.parquet&quot;\r\n    path2 = &quot;/path/to/2012-01-01/files/2014-01-31/&quot;\r\n    path3 = &quot;/path/to/2012-01-01/files/2014-01-31&quot;\r\n\r\nIn all cases, the deepest path (partition column) is &quot;2014-01-31&quot;. Is there a way consistently to get this path in a single line of code, or do I have to do all sorts of checks of file names?\r\n\r\nI was hoping to do something like:\r\n\r\n    import os\r\n    os.path.dirname(path).split(&quot;/&quot;)[-1]\r\n\r\nBut this doesn&#39;t work for **path3**. Does one need to have access to the filesystem to correctly identify the deepest directory, or is there some easy way?",
            "link": "https://stackoverflow.com/questions/78066260/in-python-how-do-you-get-the-last-directory-in-a-path-string",
            "title": "In python how do you get the &quot;last&quot; directory in a path string?"
        },
        {
            "tags": [
                "python",
                "shutil",
                "os.system"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 7446795,
                        "reputation": 1,
                        "user_id": 15413346,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/ho5xu.jpg?s=256&g=1",
                        "display_name": "Atmadeep Arya",
                        "link": "https://stackoverflow.com/users/15413346/atmadeep-arya"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709029783,
                    "answer_id": 78066813,
                    "question_id": 78066195,
                    "body_markdown": "### The mistake in code is highlighted here:\r\n```\r\n    print(f&quot;Currently in {os.getcwd()}&quot;)\r\n    sample_files = os.listdir(&quot;./&quot;)\r\n```\r\nThis generates a list of &quot;all&quot; the files in the directory, which also includes `.txt` files. These files are then copied as image files later on in code. \r\n\r\n### How to prevent this from happening:\r\ncreate a list of images only using:\r\n```\r\n    print(f&quot;Currently in {os.getcwd()}&quot;)\r\n    #create a list of all the images in the folder.\r\n    sample_files = natsort.natsorted(img for img in os.listdir(&quot;./&quot;) if img.endswith(&quot;.PNG&quot;))\r\n```\r\nThis will ensure that loop only runs on images and not on `.txt` files.",
                    "title": "bulk copying images in python creates empty files"
                }
            ],
            "owner": {
                "account_id": 7446795,
                "reputation": 1,
                "user_id": 15413346,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/ho5xu.jpg?s=256&g=1",
                "display_name": "Atmadeep Arya",
                "link": "https://stackoverflow.com/users/15413346/atmadeep-arya"
            },
            "is_answered": false,
            "view_count": 33,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -1,
            "creation_date": 1709023845,
            "question_id": 78066195,
            "body_markdown": "I&#39;m working on creating a dataset for Yolo model training. Currently the frames and annotation files are present for multiple videos in their separate folders.\r\n\r\nHere&#39;s the code I wrote to split the images and annotation file from the different folders. \r\n\r\nThe images to be added in test/val folders are selected randomly and moved. \r\nI&#39;ve tried various copy methods (including `copy2`, `copyfileobj` from `shutils` etc) but only a few images are copied properly, the rest are empty files with size 38kb.\r\n\r\n```\r\n#Assume other libraries are imported\r\n\r\nfor video_folder in video_folders:\r\n    os.chdir(os.path.join(video_folder, &quot;obj_train_data&quot;))\r\n    print(f&quot;Currently in {os.getcwd()}&quot;)\r\n    sample_files = os.listdir(&quot;./&quot;)\r\n    for image_file in sample_files:\r\n        label_file = os.path.join(str(image_file[:-3] + &quot;txt&quot;))\r\n        print(f&quot;Image file name = {image_file}&quot;)\r\n        print(f&quot;label file name = {label_file}&quot;)\r\n        #Generate full path.\r\n        image_file = os.path.join(os.getcwd(), image_file)\r\n        label_file = os.path.join(os.getcwd(), label_file)\r\n        assert(os.path.exists(image_file))\r\n        assert(os.path.exists(label_file))\r\n        #rename the iamge and label file to avoid overwriting\r\n        new_image_file_name = f&quot;frame_{sample_moved}.PNG&quot;\r\n        new_label_file_name = f&quot;frame_{sample_moved}.txt&quot;\r\n\r\n        # Copy the background file\r\n        if not (os.path.exists(label_file)):\r\n            os.system(f&quot;cp {image_file} {os.path.join(__IMAGE_TRAIN_FOLDER__,new_image_file_name)}&quot;)\r\n            continue\r\n\r\n        if(sample_moved == random_indices[0]):\r\n            try:\r\n                random_indices.pop(0)\r\n            except IndexError as e:\r\n                print(&quot;array is empty!!&quot;)\r\n\r\n            #Move file to test folder\r\n            if(test_counter &lt; max_test_samples_count):\r\n                print(&quot;moving to test folder&quot;)\r\n                os.system(f&quot;cp {image_file} {os.path.join(__IMAGE_TEST_FOLDER__,new_image_file_name)}&quot;)\r\n                os.system(f&quot;cp {label_file} {os.path.join(__LABEL_TEST_FOLDER__,new_label_file_name)}&quot;)\r\n                sleep(0.1)\r\n                test_counter+=1\r\n            \r\n            #Move file to validation counter\r\n            elif(val_counter &lt; max_val_samples_count):\r\n                print(&quot;moving to validation folder&quot;)\r\n                os.system(f&quot;cp {image_file} {os.path.join(__IMAGE_VAL_FOLDER__,new_image_file_name)}&quot;)\r\n                os.system(f&quot;cp {label_file} {os.path.join(__LABEL_VAL_FOLDER__,new_label_file_name)}&quot;)\r\n                sleep(0.1)\r\n                val_counter+=1\r\n        else:\r\n            print(&quot;Moving to training folder&quot;)\r\n            os.system(f&quot;cp {image_file} {os.path.join(__IMAGE_TRAIN_FOLDER__,new_image_file_name)}&quot;)\r\n            os.system(f&quot;cp {label_file} {os.path.join(__LABEL_TRAIN_FOLDER__,new_label_file_name)}&quot;)\r\n            sleep(0.1)\r\n        sample_moved+=1\r\n    # Move to base directory.\r\n    os.chdir(&quot;../../&quot;)\r\n\r\nprint(f&quot;Total samples moved = {sample_moved}&quot;)\r\n\r\n```\r\nFollowing is the dir strucure:\r\n```\r\n-Images\r\n-Labels\r\n-video_1\r\n  -obj_train_data\r\n-video_2\r\n  --obj_train_data\r\n-video_3\r\n  --obj_train_data\r\n``` \r\n\r\nI utilized the following methods:\r\n1. `os.system(&quot;cp src dest&quot;)`\r\n2. `shutil.copy(&quot; src dest&quot;)`\r\n\r\nWhat I expect:\r\n* All the images and respective annotation files are copied in respective folders.\r\n\r\nWhat is happening:\r\n* Only some images are copied that are proper in size and can be viewed with image viewer applications. Most of the image files are only 38 kb in size and are empty.",
            "link": "https://stackoverflow.com/questions/78066195/bulk-copying-images-in-python-creates-empty-files",
            "title": "bulk copying images in python creates empty files"
        },
        {
            "tags": [
                "python",
                "telegram",
                "telegram-bot",
                "python-telegram-bot",
                "php-telegram-bot"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 6313442,
                        "reputation": 37916,
                        "user_id": 5625547,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/oqCND.jpg?s=256&g=1",
                        "display_name": "0stone0",
                        "link": "https://stackoverflow.com/users/5625547/0stone0"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709033381,
                    "answer_id": 78067224,
                    "question_id": 78066176,
                    "body_markdown": "That&#39;s not possible, Bot&#39;s can never talk to other bots.\r\n\r\nThe only option is to make use of the Core API, make your own Telegram client so you can programmatically talk with your own user to a Bot.\r\n\r\nFor example, you can use Telethon for that.",
                    "title": "send message from my personal telegram account to a telegram bot owned by other person"
                }
            ],
            "owner": {
                "account_id": 13053346,
                "reputation": 1,
                "user_id": 9432965,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=256",
                "display_name": "Lechani Houssam",
                "link": "https://stackoverflow.com/users/9432965/lechani-houssam"
            },
            "is_answered": false,
            "view_count": 19,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709023680,
            "question_id": 78066176,
            "body_markdown": "I m trying to send a message from my personal account to telegram bot that I dont know his tokken with python or php, I have searched a lot but I didn find how to do that and I dont know if its possible or no\r\n\r\nI m used to send messages from my bot to my account or to other users using this code:\r\n```\r\nimport requests\r\nTOKEN = &quot; &quot;\r\nchat_id = &quot; &quot;\r\nmessage = &quot;hello&quot;\r\nurl = f&quot;https://api.telegram.org/bot{TOKEN}/sendMessage?chat_id={chat_id}&amp;text={message}&quot;\r\nprint(requests.get(url).json())\r\n```\r\n\r\nbut how to send message to bot that I dont have its token",
            "link": "https://stackoverflow.com/questions/78066176/send-message-from-my-personal-telegram-account-to-a-telegram-bot-owned-by-other",
            "title": "send message from my personal telegram account to a telegram bot owned by other person"
        },
        {
            "tags": [
                "python",
                "grpc",
                "grpc-python"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 301516,
                        "reputation": 35271,
                        "user_id": 609290,
                        "user_type": "registered",
                        "accept_rate": 62,
                        "profile_image": "https://i.stack.imgur.com/WUBht.jpg?s=256&g=1",
                        "display_name": "DazWilkin",
                        "link": "https://stackoverflow.com/users/609290/dazwilkin"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709055441,
                    "answer_id": 78069481,
                    "question_id": 78066154,
                    "body_markdown": "Apologies for the weak example.\r\n\r\nIt&#39;s possible to run a single server with multiple (versions of) services and there&#39;s no intrinsic reason why you wouldn&#39;t want to do this.\r\n\r\nJust as you can share Python classes|methods (e.g. using packages), you can share the implementation details of classes for your servicers.\r\n\r\nIt&#39;s good practice to keep implementations of stubs in distinct packages (partly because of the way gRPC|protobuf use packages in Python) but as a way to (more accurately) reflect the structure and versioning of your code.\r\n\r\nFor example, ideally, you&#39;d not want to change the server implementation (simplistically reflected here by `main.py`) when you have minor version changes in v1 or v2; you&#39;d prefer to simply bump the `requirements.txt` packages.\r\n\r\nI&#39;m assuming that you&#39;ve breaking changes between v1 and v2 and have similar in the following:\r\n\r\n`protos/greet/v1/greet.proto`:\r\n```protobuf\r\nsyntax = &quot;proto3&quot;;\r\n\r\n// Reflect package in folder path i.e. protos/greet/v1\r\npackage greet.v1;\r\n\r\nservice Greeter {\r\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\r\n}\r\n\r\nmessage HelloRequest {\r\n  string name = 1;\r\n}\r\n\r\nmessage HelloReply {\r\n  string message = 1;\r\n}\r\n```\r\n\r\n`protos/greet/v2/greet.proto`:\r\n```protobuf\r\nsyntax = &quot;proto3&quot;;\r\n\r\n// Reflect package in folder path i.e. protos/greet/v1\r\npackage greet.v2;\r\n\r\n// Reuse (!) &#39;greet.v1.HelloReply&#39;\r\nimport &quot;greet/v1/greet.proto&quot;;\r\n\r\nservice Greeter {\r\n  rpc SayHello (HelloRequest) returns (greet.v1.HelloReply) {}\r\n}\r\n\r\nmessage HelloRequest {\r\n  fixed32  id = 1;\r\n}\r\n```\r\n\r\nAnd:\r\n\r\n`requirements.txt`:\r\n```\r\ngrpcio==1.62.0\r\ngrpcio-reflection==1.62.0\r\ngrpcio-tools==1.62.0\r\nprotobuf==4.25.3\r\n```\r\n\r\n```bash\r\npython3 -m venv venv\r\nsource venv/bin/activate\r\n\r\npython3 -m pip install --requirement requirements.txt\r\n\r\npython3 \\\r\n-m grpc_tools.protoc \\\r\n--proto_path=${PWD}/protos \\\r\n--python_out=${PWD} \\\r\n--pyi_out=${PWD} \\\r\n--grpc_python_out=${PWD} \\\r\n${PWD}/protos/greet/v1/greet.proto \\\r\n${PWD}/protos/greet/v2/greet.proto\r\n```\r\nAnd:\r\n`main.py`:\r\n```python\r\n# Python gRPC service reflection\r\nfrom grpc_reflection.v1alpha import reflection\r\n\r\nfrom concurrent import futures\r\nimport grpc\r\n\r\n# v1\r\nimport greet.v1.greet_pb2 as greet_v1_pb2\r\nimport greet.v1.greet_pb2_grpc as greet_v1_pb2_grpc\r\n\r\n\r\nclass GreeterV1(greet_v1_pb2_grpc.GreeterServicer):\r\n    def SayHello(self, request, context):\r\n        return greet_v1_pb2.HelloReply(message=f&quot;Hello {request.name}&quot;)\r\n\r\n# v2\r\nimport greet.v2.greet_pb2 as greet_v2_pb2\r\nimport greet.v2.greet_pb2_grpc as greet_v2_pb2_grpc\r\n\r\n\r\nclass GreeterV2(greet_v2_pb2_grpc.GreeterServicer):\r\n    def SayHello(self, request, context):\r\n        return greet_v1_pb2.HelloReply(message=f&quot;Hello {request.id}&quot;)\r\n\r\n\r\ndef serve():\r\n    # One service\r\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\r\n\r\n    # Adds v1 and v2 services\r\n    greet_v1_pb2_grpc.add_GreeterServicer_to_server(GreeterV1(), server)\r\n    greet_v2_pb2_grpc.add_GreeterServicer_to_server(GreeterV2(), server)\r\n\r\n    SERVICE_NAMES = (\r\n        greet_v1_pb2.DESCRIPTOR.services_by_name[&#39;Greeter&#39;].full_name,\r\n        greet_v2_pb2.DESCRIPTOR.services_by_name[&#39;Greeter&#39;].full_name,\r\n    )\r\n    # Adds third service (!)\r\n    reflection.enable_server_reflection(SERVICE_NAMES, server)\r\n\r\n    server.add_insecure_port(&quot;[::]:50051&quot;)\r\n    server.start()\r\n    server.wait_for_termination()\r\n\r\nif __name__ == &quot;__main__&quot;:\r\n    serve()\r\n```\r\nAnd:\r\n\r\nEnumerate v1 Method\r\n```bash\r\ngrpcurl \\\r\n-plaintext \\\r\nlocalhost:50051 \\\r\nlist greet.v1.Greeter\r\n```\r\n```\r\ngreet.v1.Greeter.SayHello\r\n```\r\nInvoke v1 Method\r\n```bash\r\ngrpcurl \\\r\n-plaintext \\\r\n-d &#39;{&quot;name&quot;:&quot;Freddie&quot;}&#39; \\\r\nlocalhost:50051 \\\r\ngreet.v1.Greeter.SayHello\r\n```\r\n```JSON\r\n{\r\n  &quot;message&quot;: &quot;Hello Freddie&quot;\r\n}\r\n```\r\nEnumerate v2 Method\r\n```bash\r\ngrpcurl \\\r\n-plaintext \\\r\nlocalhost:50051 \\\r\nlist greet.v2.Greeter\r\n```\r\n```\r\ngreet.v2.Greeter.SayHello\r\n```\r\nInvoke v2 Method\r\n```bash\r\ngrpcurl \\\r\n-plaintext \\\r\n-d &#39;{&quot;id&quot;:314159265}&#39; \\\r\nlocalhost:50051 \\\r\ngreet.v2.Greeter.SayHello\r\n```\r\n```JSON\r\n{\r\n  &quot;message&quot;: &quot;Hello 314159265&quot;\r\n}\r\n```\r\n\r\n&gt; **NOTE** Python&#39;s gRPC reflection service appears to not work with `describe {method}`.",
                    "title": "gRPC API versioning"
                }
            ],
            "owner": {
                "account_id": 25730638,
                "reputation": 1,
                "user_id": 19486290,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/808fdf5462caaa9f9bbda6a4a34981fa?s=256&d=identicon&r=PG",
                "display_name": "nagibator_archivator",
                "link": "https://stackoverflow.com/users/19486290/nagibator-archivator"
            },
            "is_answered": false,
            "view_count": 19,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709023383,
            "question_id": 78066154,
            "body_markdown": "There is a situation where I need to implement 2 versions of the grpc API on my server. How can I do this?\r\n\r\n```\r\nsyntax = &quot;proto3&quot;;\r\n\r\npackage greet.v1;\r\n```\r\nwill help me to add versioning to my pb2 autogenerated files, but I completely don&#39;t understand how to combine both pb2(v1 and v2) on the same server. Maybe anyone has an example of grpc versioning in Python? Or maybe it&#39;s a bad practice to use 2 versions in one server and I should use another pod for a new grpc version..\r\n",
            "link": "https://stackoverflow.com/questions/78066154/grpc-api-versioning",
            "title": "gRPC API versioning"
        },
        {
            "tags": [
                "python",
                "python-3.x",
                "django",
                "pytest",
                "factory-boy"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 7703761,
                        "reputation": 1224,
                        "user_id": 5835338,
                        "user_type": "registered",
                        "accept_rate": 62,
                        "profile_image": "https://www.gravatar.com/avatar/3fa90a729a6aa6eeb5ed0e613321b328?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Vaibhav",
                        "link": "https://stackoverflow.com/users/5835338/vaibhav"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709028776,
                    "answer_id": 78066699,
                    "question_id": 78066085,
                    "body_markdown": "This is because the BaseOrganizationFactory creates a circular reference with a parent field pointing to itself. This creates an infinite recursion during the factory creation process.\r\n\r\nChange your factory to avoid creating circular references. \r\nOne way to do this is by setting the parent field to None or a random value.\r\nChange the logic as per your business logic need\r\n\r\n\r\n    class BaseOrganizationFactory(factory.django.DjangoModelFactory):\r\n       &quot;&quot;&quot;Base organization factory&quot;&quot;&quot;\r\n       name = factory.Faker(&quot;company&quot;)\r\n       juridical_address = factory.Faker(&quot;address&quot;)\r\n       phone_number = factory.Faker(&quot;phone_number&quot;)\r\n\r\n       # Using factory.LazyAttribute to avoid circular reference\r\n       parent = factory.SubFactory(&quot;myapp.tests.factories.BaseOrganizationFactory&quot;)\r\n\r\n\r\n       class Meta:\r\n            model = BaseOrganization\r\n\r\n    @pytest.mark.django_db\r\n    class TestBaseOrganization:\r\n        @pytest.fixture\r\n        def base_organization(self):\r\n            return BaseOrganizationFactory(parent=None)\r\n    \r\n        def test_something(self, base_organization):\r\n            # Your test code here\r\n            assert base_organization is not None\r\n",
                    "title": "Factory boy field for self-referential field in django abstract model"
                }
            ],
            "owner": {
                "account_id": 25854218,
                "reputation": 9,
                "user_id": 19587771,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/AItbvmlh9ddSoO2vZrEatcxe4OzmlfTTQ5wN21L2n-vI=k-s256",
                "display_name": "Shokhrukh Shodiev",
                "link": "https://stackoverflow.com/users/19587771/shokhrukh-shodiev"
            },
            "is_answered": false,
            "view_count": 30,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709022770,
            "question_id": 78066085,
            "body_markdown": "    class BaseOrganization(\r\n        OrganizationModelMixin, TimeStampedModel, OrganizationWidgetsMixin\r\n    ):\r\n        name = models.CharField(max_length=255, verbose_name=&quot;Nomlanishi&quot;, null=True)\r\n        juridical_address = models.CharField(\r\n            max_length=150, verbose_name=&quot;Yuridik manzili&quot;, null=True, blank=True\r\n        )\r\n        phone_number = models.CharField(\r\n            max_length=150,\r\n            verbose_name=&quot;Telefon raqami&quot;,\r\n            null=True,\r\n            blank=True,\r\n            validators=[phone_regex],\r\n        )\r\n        parent = models.ForeignKey(\r\n            &quot;self&quot;,\r\n            on_delete=models.SET_NULL,\r\n            null=True,\r\n            blank=True,\r\n            related_name=&quot;%(class)s_children&quot;,\r\n            verbose_name=&quot;Yuqori tashkilot&quot;,\r\n        )\r\n    \r\n    \r\n        class Meta:\r\n            abstract = True\r\n    \r\n    class BaseOrganizationFactory(factory.django.DjangoModelFactory):\r\n    \r\n        &quot;&quot;&quot;Base organization factory&quot;&quot;&quot;\r\n        name = factory.Faker(&quot;company&quot;)\r\n        juridical_address = factory.Faker(&quot;address&quot;)\r\n        phone_number = factory.Faker(&quot;phone_number&quot;)\r\n        parent = factory.SubFactory(\r\n            &quot;myapp.tests.factories.BaseOrganizationFactory&quot;,\r\n        )\r\n    \r\n    \r\n    @pytest.mark.django_db\r\n    class TestBaseOrganization:\r\n        @pytest.fixture(autouse=True)\r\n        def setup(self):\r\n            self.base_organization = BaseOrganizationFactory(\r\n                parent=None\r\n            )\r\n    \r\n\r\nif i call BaseOrganizationFactory in setup method it caused RecursionError: maximum recursion depth exceeded while calling a Python object\r\n",
            "link": "https://stackoverflow.com/questions/78066085/factory-boy-field-for-self-referential-field-in-django-abstract-model",
            "title": "Factory boy field for self-referential field in django abstract model"
        },
        {
            "tags": [
                "python",
                "cs50"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 23535348,
                        "reputation": 22467,
                        "user_id": 17580381,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/0h7Fj.jpg?s=256&g=1",
                        "display_name": "CtrlZ",
                        "link": "https://stackoverflow.com/users/17580381/ctrlz"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709025721,
                    "answer_id": 78066376,
                    "question_id": 78066001,
                    "body_markdown": "There is no reason why you shouldn&#39;t return values at different points in a function. It&#39;s often possible to have single returns of True/False but that will invariably involve lots of if/and/or constructs that make the code difficult to maintain and understand.\r\n\r\nBetter to break down the logic into its discrete components.\r\n\r\ne.g.,\r\n\r\n    def is_valid(plate):\r\n        if not 2 &lt;= len(plate) &lt;= 6:\r\n            return False\r\n        if not plate[:2].isalpha():\r\n            return False\r\n        if not plate.isalnum():\r\n            return False\r\n        for i, c in enumerate(plate[2:], 2):\r\n            if c.isdecimal():\r\n                if c == &quot;0&quot;:\r\n                    return False\r\n                if not plate[i:].isdecimal():\r\n                    return False\r\n                break\r\n        return True\r\n\r\nNote the use of isdecimal rather than isdigit. The former tests strictly for values in the range 0-9 whereas the latter would also return True for superscript digits which would (obviously) not be valid on a licence plate",
                    "title": "CS50P problems Set 5"
                }
            ],
            "owner": {
                "account_id": 30620065,
                "reputation": 1,
                "user_id": 23472626,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKODzz2vz3Zh-pXrS-mHR6mdAQ_5yNrpFQMAUkD0Sq2pPo=k-s256",
                "display_name": "Abdelrahman Tareq",
                "link": "https://stackoverflow.com/users/23472626/abdelrahman-tareq"
            },
            "is_answered": false,
            "view_count": 39,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -2,
            "creation_date": 1709021656,
            "question_id": 78066001,
            "body_markdown": "in CS50P Problem 5 call &quot;Re-requesting a Vanity Plate&quot;(https://cs50.harvard.edu/python/2022/psets/5/test_plates/)\r\nThis program works but I am confused about it\r\nwhy i have did write &quot;return valid&quot; and &quot;return invalid&quot; two times for each \r\nwhat&#39;s the diffrent?\r\n```\r\ndef main():\r\n    plate = input(&quot;Plate: &quot;)\r\n    print(is_valid(plate))\r\n\r\ndef is_valid(s):\r\n    if 2 &lt;= len(s) &lt;= 6 and s[0:2].isalpha() and s[0] != 0 and s.isalnum():\r\n        for char in s:\r\n            if char.isdigit():\r\n                index = s.index(char)\r\n                if s[index:].isdigit() and char != 0:\r\n                    return &quot;Valid&quot;\r\n                else:\r\n                    return &quot;Invalid&quot;\r\n        return &quot;Valid&quot;\r\n    return &quot;Invalid&quot;\r\n\r\n\r\n\r\n\r\n\r\nif __name__ == &quot;__main__&quot;:\r\n    main()\r\n\r\n```\r\n\r\n\r\ni except to write &quot;return &quot;Valid&quot;&quot; and &quot;return &quot;Invalid&quot;&quot; one time",
            "link": "https://stackoverflow.com/questions/78066001/cs50p-problems-set-5",
            "title": "CS50P problems Set 5"
        },
        {
            "tags": [
                "python",
                "pandas"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 18814962,
                        "reputation": 50,
                        "user_id": 13722335,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/-57oPNCQHIoA/AAAAAAAAAAI/AAAAAAAAAAA/AMZuucl99hQ3eNilkkSY76viaIVfo73PWA/photo.jpg?sz=256",
                        "display_name": "Greg Gonastarev",
                        "link": "https://stackoverflow.com/users/13722335/greg-gonastarev"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709022961,
                    "answer_id": 78066108,
                    "question_id": 78065964,
                    "body_markdown": "You can speed up your read_csv by reading only necessary cols\r\n\r\n    import pandas as pd\r\n    \r\n    # Define the columns you want to read from the CSV files\r\n    # Assuming &#39;unique_id&#39; is the column you use to uniquely identify rows\r\n    # and &#39;that_col&#39; is the column you need to process\r\n    columns_to_read = [&#39;unique_id&#39;, &#39;that_col&#39;]\r\n    \r\n    # Modify your pd.read_csv() calls to include `usecols`\r\n    csv1_df = pd.read_csv(&#39;input_file1.csv&#39;, sep=&#39;\\x1D&#39;, engine=&#39;python&#39;, skiprows=1, skipfooter=1, header=0, dtype=str, keep_default_na=False, usecols=columns_to_read)\r\n    csv2_df = pd.read_csv(&#39;input_file2.csv&#39;, sep=&#39;\\x1D&#39;, engine=&#39;python&#39;, skiprows=1, skipfooter=1, header=0, dtype=str, keep_default_na=False, usecols=columns_to_read)\r\n    \r\n    # Your processing steps remain the same\r\n    def resolver(series_1, series_2):\r\n        # Your resolver function implementation\r\n        pass\r\n    \r\n    # Assuming &#39;unique_id&#39; is set as the index if it&#39;s not already\r\n    csv1_df.set_index(&#39;unique_id&#39;, inplace=True)\r\n    csv2_df.set_index(&#39;unique_id&#39;, inplace=True)\r\n    \r\n    csv2_df[&#39;that_col&#39;] = csv1_df[&#39;that_col&#39;].combine(csv2_df[&#39;that_col&#39;], resolver)\r\n    \r\n    # Concatenate csv1 with csv2 preferring csv2 for the intersecting rows\r\n    result_df = pd.concat([csv1_df[~csv1_df.index.isin(csv2_df.index)], csv2_df])\r\n    \r\n    # Remove rows that are marked for deletion\r\n    result_df = result_df[result_df[&#39;that_col&#39;] != &#39;$Delete&#39;]\r\n    \r\n    # Write the result to a new CSV file\r\n    result_df.to_csv(&#39;output_file.csv&#39;, sep=&#39;\\x1D&#39;, index=True)\r\n\r\n",
                    "title": "Is it possible to load limited columns with pandas for processing but output with entire columns though"
                }
            ],
            "owner": {
                "account_id": 12997311,
                "reputation": 491,
                "user_id": 9394465,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=256",
                "display_name": "SpaceyBot",
                "link": "https://stackoverflow.com/users/9394465/spaceybot"
            },
            "is_answered": false,
            "view_count": 46,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709021166,
            "question_id": 78065964,
            "body_markdown": "I have been working with pandas to process very huge csv files lately, and the read_csv(..) itself is taking more time than the actual processing. I am not able to figure out if its possible to read only few columns from the csv for the task that I am doing so my read_csv would be faster? \r\nMy task involve reading two CSVs and concatenate them by doing the following:\r\n 1. Take one of the column from both and change them to something which is defined in a method `def resolver(series_1, series_2)`. This is done by doing the `csv2_df[that_col] = csv1_df[that_col].combine(csv2_df[that_col], resolver)`.\r\n 2. Concatenate csv1 with csv2 preferring csv2 for the intersecting rows: `result_df = pd.concat([csv1_df[~csv1_df.index.isin(csv2_df.index)], csv2_df])`\r\n 3. Remove rows that are marked for deletion in the 1st step: `result_df = result_df[result_df[that_col] != &#39;$Delete&#39;]`\r\n 4. result_df.to_csv(...)\r\n\r\n - Note: Before these steps, my read_csv(..) for those two files resembles the following: `pd.read_csv(input_file, sep=&#39;\\x1D&#39;, engine=&#39;python&#39;, skiprows=1, skipfooter=1, header=0, dtype=str, keep_default_na=False)`\r\n\r\n**EDIT:**\r\nReproducible code:\r\n\r\n```\r\ncsv2_df = pd.read_csv(csv2, sep=&#39;\\x1D&#39;, engine=&#39;python&#39;, skiprows=1, skipfooter=1, header=0, dtype=str, keep_default_na=False)\r\ncsv1_df = pd.read_csv(csv1, sep=&#39;\\x1D&#39;, engine=&#39;python&#39;, skiprows=1, skipfooter=1, header=0, dtype=str, keep_default_na=False)\r\ncsv2_df.set_index(primary_idx_list, inplace=True, verify_integrity=verify_integrity)\r\ncsv1_df.set_index(primary_idx_list, inplace=True, verify_integrity=verify_integrity)\r\n\r\ndef resolver(v1, v2):\r\n    return &#39;$Delete&#39; if v1 == &#39;A&#39; and v2 == &#39;B&#39; else (v1 if v1 == &#39;A&#39; and v2 == &#39;C&#39; else (v2 if pd.notna(v2) else v1))\r\n\r\ncsv2_df[that_col] = csv1_df[that_col].combine(csv2_df[that_col], resolver)\r\nresult_df = pd.concat([csv1_df[~csv1_df.index.isin(csv2_df.index)], csv2_df])\r\nresult_df = result_df[result_df[that_col] != &#39;$Delete&#39;]\r\nresult_df.to_csv(...)\r\n```",
            "link": "https://stackoverflow.com/questions/78065964/is-it-possible-to-load-limited-columns-with-pandas-for-processing-but-output-wit",
            "title": "Is it possible to load limited columns with pandas for processing but output with entire columns though"
        },
        {
            "tags": [
                "python"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30637138,
                        "reputation": 1,
                        "user_id": 23486331,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJ-00qnCeWkgVERGZfRzA2hGdSCHnwKi1EPj0mbpqhMAkY=k-s256",
                        "display_name": "Victor Martinescu",
                        "link": "https://stackoverflow.com/users/23486331/victor-martinescu"
                    },
                    "is_accepted": false,
                    "score": -1,
                    "creation_date": 1709018355,
                    "answer_id": 78065749,
                    "question_id": 78065728,
                    "body_markdown": "Return freg-list is not reachable like with the others, when you start a loop it goes forever and when there is a loop all commands most remain reachable.\r\nIn this case, it&#39;s not reachable.",
                    "title": "Why is there a range error in the for loop?"
                },
                {
                    "owner": {
                        "account_id": 16326713,
                        "reputation": 103,
                        "user_id": 11791110,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/-YmJfEipdneI/AAAAAAAAAAI/AAAAAAAAAAA/ACHi3rfVV7YMHXB-WNEUHe6nykS8-7ebaQ/photo.jpg?sz=256",
                        "display_name": "HOBE",
                        "link": "https://stackoverflow.com/users/11791110/hobe"
                    },
                    "is_accepted": false,
                    "score": 2,
                    "creation_date": 1709019425,
                    "answer_id": 78065824,
                    "question_id": 78065728,
                    "body_markdown": "### 1. `[0] * 27`\r\n\r\n- **Structure**: A flat list of 27 zeros.\r\n- **Visualization**:\r\n\r\n| Index | Value |\r\n|-------|-------|\r\n| 0     | 0     |\r\n| 1     | 0     |\r\n| ...   | 0     |\r\n| 26    | 0     |\r\n\r\n- **Use Case**: Ideal for initializing a list of counters or setting default values for a one-dimensional array.\r\n\r\n### 2. `[[0] * 27]`\r\n\r\n- **Structure**: An outer list containing a single inner list of 27 zeros.\r\n- **Visualization**:\r\n\r\n| Outer Index | Inner List Value     |\r\n|-------------|----------------------|\r\n| 0           | [0, 0, ..., 0] (27 elements) |\r\n\r\n- **Use Case**: Suitable for starting a 2D matrix or list where you initially have one row, especially in scenarios requiring row-wise manipulation.\r\n\r\n### 3. `[[[0]] * 27]`\r\n\r\n- **Structure**: A list of 27 elements, where each element is a list containing a single list with `0`.\r\n- **Visualization**:\r\n\r\n| Outer Index | Inner Lists        |\r\n|-------------|---------------------|\r\n| 0           | [[0]]               |\r\n| 1           | [[0]]               |\r\n| ...         | ...                 |\r\n| 26          | [[0]]               |\r\n\r\n- **Use Case**: Useful for initializing a 3-dimensional structure where each element is to be a complex nested list, starting with a single value. Ideal for scenarios where the third dimension will be dynamically populated.\r\n\r\n### 4. `[[[0] * 27]]`\r\n\r\n- **Structure**: An outer list containing a single element, which is a list of 27 lists, each containing a single `0`.\r\n- **Visualization**:\r\n\r\n| Outer Index | Inner List containing 27 Lists with a single 0 each |\r\n|-------------|------------------------------------------------------|\r\n| 0           | [[0], [0], ..., [0]] (27 inner lists)                |\r\n\r\n- **Use Case**: This setup is geared towards creating a 3-dimensional data structure focusing on a single 2D layer or plane. It&#39;s a starting point for building more complex 3D structures where the initial layer is uniform.\r\n\r\nEach of these configurations serves a distinct purpose, offering flexibility in how data structures are initialized and manipulated in Python. Understanding the dimensionality and nesting of lists is crucial for effectively managing data in applications that require complex, multi-dimensional data storage.",
                    "title": "Why is there a range error in the for loop?"
                },
                {
                    "owner": {
                        "account_id": 18069266,
                        "reputation": 105,
                        "user_id": 13134286,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a-/AOh14Gg8OX-yxmdpXWg8QIfMpwgAV54qh5WLqyy6cjhouvY=k-s256",
                        "display_name": "balintd",
                        "link": "https://stackoverflow.com/users/13134286/balintd"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709019761,
                    "answer_id": 78065849,
                    "question_id": 78065728,
                    "body_markdown": "At `freq_list[0]`, your are creating a nested list. You should either declare it with\r\n```python\r\nfreq_list = [\r\n    [&quot; &quot;] * len(string),\r\n    []\r\n    ]\r\n```\r\n if the nesting is unwanted, or assign values in it with\r\n```python\r\nfreq_list[0][0][i] = string[i]\r\n```\r\nHere, with the two `[0]` indexing, you *do* access the inner list which you originally want to assign values within.",
                    "title": "Why is there a range error in the for loop?"
                }
            ],
            "owner": {
                "account_id": 30619467,
                "reputation": 33,
                "user_id": 23472156,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/1fdd0883e1590136803da80d1e1c294a?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Jsinotte",
                "link": "https://stackoverflow.com/users/23472156/jsinotte"
            },
            "is_answered": true,
            "view_count": 107,
            "favorite_count": 0,
            "accepted_answer_id": 78065849,
            "answer_count": 3,
            "score": 1,
            "creation_date": 1709018115,
            "question_id": 78065728,
            "body_markdown": "```python\r\ndef frequency_analysis(string):\r\n    count = 0\r\n    freq_list = [\r\n        [[&quot; &quot;] * len(string)],\r\n        []\r\n        ]\r\n    print(freq_list[0])\r\n    for i in range(len(string)):\r\n        print(i)\r\n        freq_list[0][i] = string[i]\r\n        print(freq_list[0])\r\n    return freq_list\r\nprint(frequency_analysis(&quot;fhfhffffj&quot;))\r\nprint(frequency_analysis(&quot;jfjf&quot;))\r\n```\r\n\r\nThis is for a school assignment and I am not allowed to use built in functions other than `len()`. I am trying to make the `freq_list[0]` a list of separate characters from the string input. For some reason, after the first switch it turns the first list created into a list of just one item and then there is an out of range error. Can anyone explain why this is happening.\r\n\r\nInput &quot;fhh&quot;\r\nprints:\r\n```none\r\n[&quot; &quot;,&quot; &quot;,&quot; &quot;]\r\n0\r\n&quot;f&quot;\r\n1\r\nError\r\n```",
            "link": "https://stackoverflow.com/questions/78065728/why-is-there-a-range-error-in-the-for-loop",
            "title": "Why is there a range error in the for loop?"
        },
        {
            "tags": [
                "python",
                "outlook",
                "pywin32"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 131793,
                        "reputation": 64486,
                        "user_id": 332059,
                        "user_type": "registered",
                        "accept_rate": 57,
                        "profile_image": "https://i.stack.imgur.com/cSNOK.png?s=256&g=1",
                        "display_name": "Dmitry Streblechenko",
                        "link": "https://stackoverflow.com/users/332059/dmitry-streblechenko"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709051658,
                    "answer_id": 78069096,
                    "question_id": 78065642,
                    "body_markdown": "Not much you can do in OOM alone - with the `AddressEntries` collection, you are forced to access one entry and one property at a time. `AddressEntries` object does expose the `RawTable` property  (returns `IMAPITable` MAPI object), but it cannot be used in Python, you&#39;d need C++ or Delphi. If using [Redemption][1] (I am its author) is an option, you can use the [Redemption.MAPITable][2] object - it allows to retrieve all values in a single call.\r\n\r\nIn VBS:\r\n\r\n```vba\r\nset addrEntries = Application.Session.AddressLists(&quot;Offline Global Address List&quot;).AddressEntries.Item(&quot;Everybody&quot;).Members\r\nset Table = CreateObject(&quot;Redemption.MAPITable&quot;)\r\nTable.Item = addrEntries\r\n&#39;0x39FE001F is PR_SMTP_ADDRESSS, need to specify it as a DASL name for ExecSQL\r\nset Recordset = Table.ExecSQL(&quot;SELECT Name, &quot;&quot;http://schemas.microsoft.com/mapi/proptag/0x39FE001F&quot;&quot;, JobTitle, OfficeLocation, Department from List&quot;)\r\nwhile not Recordset.EOF\r\n    Debug.Print(Recordset.Fields(0).Value &amp; &quot; - &quot; &amp; Recordset.Fields(1).Value &amp; &quot; - &quot; &amp; Recordset.Fields(2).Value &amp; &quot; - &quot; &amp; Recordset.Fields(3).Value &amp; &quot; - &quot; &amp; Recordset.Fields(4).Value)\r\n    Recordset.MoveNext\r\nwend\r\n```\r\n\r\n\r\n  [1]: https://www.dimastr.com/redemption\r\n  [2]: https://www.dimastr.com/redemption/mapitable.htm",
                    "title": "Using Python to extract employee details from Outlook is suddenly very slow"
                }
            ],
            "owner": {
                "account_id": 30640130,
                "reputation": 11,
                "user_id": 23488702,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/84296803c8a7a160bc9ec160f4388d24?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Samrat",
                "link": "https://stackoverflow.com/users/23488702/samrat"
            },
            "is_answered": false,
            "view_count": 46,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709016948,
            "question_id": 78065642,
            "body_markdown": "I&#39;ve been utilizing pywin32 in Python to extract names, email IDs, job titles, and other details of all members from specified Outlook distribution lists. Initially, the code executed very quickly; although I lack an exact estimate, it could extract all pertinent details for even 100-200 or more members within 1-2 minutes. However, after changing laptops within my organization, I&#39;ve noticed a significant slowdown. The code now takes up to an hour for similar outputs. Despite searching online, I haven&#39;t found any relevant mentions of such an issue. Your guidance would be appreciated.\r\n\r\nA sample of the code:\r\n```python\r\n            outApp = win32com.client.gencache.EnsureDispatch(&#39;Outlook.Application&#39;).GetNamespace(&quot;MAPI&quot;)\r\n            entries = outApp.AddressLists\r\n            dist_lists = entries[&#39;All Distribution Lists&#39;]\r\n\r\n            outlookdf=pd.DataFrame(columns=[&#39;User Name&#39;,&#39;Email&#39;,&#39;Job Level&#39;,&#39;Location&#39;,&#39;Department&#39;,&#39;DL Name&#39;])\r\n\r\n            dl_names_list = [&quot;&lt;insert name of distribution list here&gt;&quot;]\r\n\r\n            print(&quot;Distribution Lists being extracted are: &quot;)\r\n            for i in dl_names_list:\r\n                print(str(i))\r\n            print(&quot;----------------------------&quot;)\r\n\r\n            #########GET DL Names from list and put it in a dataframe\r\n\r\n            for i in dl_names_list:\r\n                print(&quot;Distribution List now being extracted: &quot;)\r\n                print(str(i))\r\n\r\n                #initialize widgets\r\n                widgets = [&#39;Remaining Time: &#39;, pb.Percentage(), &#39; &#39;, \r\n                            pb.Bar(marker=pb.RotatingMarker()), &#39; &#39;, pb.ETA()]\r\n                #initialize timer\r\n                timer = pb.ProgressBar(widgets=widgets,        maxval=len(dist_lists.AddressEntries.Item(str(i)).GetExchangeDistributionList().Members)).start()\r\n                ind = 0\r\n                m_list_1 = []\r\n                m_list_2 = []\r\n                m_list_3 = []\r\n                m_list_4 = []\r\n                m_list_5 = []\r\n                for m in dist_lists.AddressEntries.Item(str(i)).GetExchangeDistributionList().Members:\r\n                        user=m.GetExchangeUser()\r\n                        try:\r\n                            if len(user.Name) &gt; 0 and (user.Name.find(&#39;, &#39;) != -1):\r\n                                    value1 = user.Name\r\n                                    m_list_1.append(value1)\r\n\r\n                                    value2 = user.PrimarySmtpAddress  \r\n                                    m_list_2.append(value2)\r\n\r\n                                    value3 = user.JobTitle \r\n                                    m_list_3.append(value3)\r\n                                    \r\n                                    value4 = user.OfficeLocation\r\n                                    m_list_4.append(value4)\r\n                                    \r\n                                    value5 = user.Department\r\n                                    m_list_5.append(value5)\r\n                            timer.update(ind)\r\n                            ind = ind + 1\r\n                         except:\r\n                            continue\r\n                timer.finish()\r\n                print(&quot;---------------------------------------------------&quot;)\r\n\r\n                df_m = pd.DataFrame(pd.DataFrame(\r\n                {&#39;User Name&#39;: m_list_1,\r\n                 &#39;Email&#39;: m_list_2,\r\n                 &#39;Job Level&#39;: m_list_3,\r\n                 &#39;Location&#39;: m_list_4,\r\n                 &#39;Department&#39;: m_list_5\r\n                }))\r\n                df_m[&quot;DL Name&quot;] = str(dist_lists.AddressEntries.Item(str(i)).GetExchangeDistributionList().Name)\r\n                outlookdf = pd.concat([outlookdf,df_m])\r\n\r\n            outlookdf = outlookdf.drop_duplicates()\r\n            outlookdf = outlookdf.reset_index(drop = True)\r\n\r\n```",
            "link": "https://stackoverflow.com/questions/78065642/using-python-to-extract-employee-details-from-outlook-is-suddenly-very-slow",
            "title": "Using Python to extract employee details from Outlook is suddenly very slow"
        },
        {
            "tags": [
                "python"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 6321039,
                        "reputation": 389745,
                        "user_id": 4909087,
                        "user_type": "registered",
                        "accept_rate": 97,
                        "profile_image": "https://i.stack.imgur.com/Zcszo.png?s=256&g=1",
                        "display_name": "this be Shiva",
                        "link": "https://stackoverflow.com/users/4909087/this-be-shiva"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709017947,
                    "answer_id": 78065716,
                    "question_id": 78065606,
                    "body_markdown": "I think you might be overcomplicating the solution. IMO you do not need to add trailing whitespace. Also, if you replace `word[:i+1].center(2*i+1)` with `&#39; &#39;.join(word[:i+1]))`, you get the correct output for the UP case, but not the DOWN case. To make the DOWN case work correctly, you need to iterate over levels in reverse.\r\n\r\nHere&#39;s how I would personally solve the problem:\r\n\r\n    def make_pyramid(S, direction=&#39;up&#39;):\r\n        parts = []\r\n        r = range(1, len(S)+1) if direction == &#39;up&#39; else range(len(S), 0, -1)\r\n        for i in r:\r\n            parts.append(&#39; &#39; * (len(S) - i) + &#39; &#39;.join(S[:i]))\r\n        \r\n        return &#39;\\n&#39;.join(parts)\r\n    \r\n    print(make_pyramid(&#39;Sunil was here&#39;))\r\n    print(make_pyramid(&#39;Sunil was here&#39;, direction=&#39;down&#39;))     \r\n&lt;!-- --&gt;\r\n\r\n                 S\r\n                S u\r\n               S u n\r\n              S u n i\r\n             S u n i l\r\n            S u n i l  \r\n           S u n i l   w\r\n          S u n i l   w a\r\n         S u n i l   w a s\r\n        S u n i l   w a s  \r\n       S u n i l   w a s   h\r\n      S u n i l   w a s   h e\r\n     S u n i l   w a s   h e r\r\n    S u n i l   w a s   h e r e\r\n    S u n i l   w a s   h e r e\r\n     S u n i l   w a s   h e r\r\n      S u n i l   w a s   h e\r\n       S u n i l   w a s   h\r\n        S u n i l   w a s  \r\n         S u n i l   w a s\r\n          S u n i l   w a\r\n           S u n i l   w\r\n            S u n i l  \r\n             S u n i l\r\n              S u n i\r\n               S u n\r\n                S u\r\n                 S\r\n\r\nAs a side note, I prefer my functions don&#39;t have side effects (such as printing stuff out), so I return the string and have the caller print it instead.  ",
                    "title": "Generating a program that generates a word pyramid pattern based on user input in Python"
                }
            ],
            "owner": {
                "account_id": 30639295,
                "reputation": 1,
                "user_id": 23488010,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKPlQPMEtWHg8uPbJGBHVPZpTxMl8LwQvftYiGsxCkSAII=k-s256",
                "display_name": "Rajesh Adhikari",
                "link": "https://stackoverflow.com/users/23488010/rajesh-adhikari"
            },
            "is_answered": true,
            "view_count": 46,
            "favorite_count": 0,
            "answer_count": 1,
            "score": -2,
            "creation_date": 1709016513,
            "question_id": 78065606,
            "body_markdown": "Requirements:\r\n1. Ask the user to input a word.\r\n2. Generate and print a pyramid pattern using the letters of the word.\r\n3. Each level of the pyramid should display the letters of the word up to that level.\r\n4. The word should be centered on each level of the pyramid.\r\n\r\nAdditional requirements:\r\n1. Implement a function to validate the input and ensure it&#39;s a valid word.\r\n2. Allow the user to choose the direction of the pyramid (upwards or downwards). \r\n3. Enhance the program to handle phrases instead of single words.\r\n\r\nExpected Output:\r\nif word level is up:\r\n```none\r\n            S    \r\n           S u   \r\n          S u n  \r\n         S u n i \r\n        S u n i l\r\n```\r\n\r\nif word level is Down:\r\n```none\r\n            S u n i l\r\n             S u n i \r\n              S u n  \r\n               S u   \r\n                S \r\n```\r\n\r\nTried code:\r\n\r\n```python\r\nimport string\r\n\r\ndef validate_word(word):\r\n    if not word.isalpha():\r\n        return False\r\n    if not word.isascii():\r\n        return False\r\n    if len(word) &lt; 3:\r\n        return False\r\n    return True\r\n\r\ndef get_word_from_user():\r\n    while True:\r\n        word = input(&quot;Enter a word: &quot;).strip()\r\n        if validate_word(word):\r\n            return word\r\n        else:\r\n            print(&quot;Invalid input. Please enter a valid word.&quot;)\r\n\r\ndef get_pyramid_direction():\r\n    while True:\r\n        direction = input(&quot;Choose the direction of the pyramid (up/down): &quot;).strip().lower()\r\n        if direction in [&#39;up&#39;, &#39;down&#39;]:\r\n            return direction\r\n        else:\r\n            print(&quot;Invalid input. Please enter &#39;up&#39; or &#39;down&#39;.&quot;)\r\n\r\ndef print_pyramid(word, direction):\r\n    levels = len(word)\r\n    for i in range(levels):\r\n        if direction == &#39;up&#39;:\r\n            print(&#39; &#39; * (levels - i - 1) + &#39; &#39; + word[:i+1].center(2*i+1) + &#39; &#39; * (levels - i - 1))\r\n        else:\r\n            print(&#39; &#39; * i + word[:i+1].center(2*i+1) + &#39; &#39; * i)\r\n\r\ndef main():\r\n    word = get_word_from_user()\r\n    direction = get_pyramid_direction()\r\n    print_pyramid(word, direction)\r\n\r\nif __name__ == &quot;__main__&quot;:\r\n    main()\r\n```\r\nThis code is giving out following output:\r\n \r\nfor up:\r\n\r\n      R     \r\n      Ra    \r\n     Raj    \r\n     Raje   \r\n    Rajes   \r\n    Rajesh  \r\n\r\nfor down:\r\n\r\nr\r\n  ra \r\n    raj   \r\n     raje    \r\n      rajes      \r\n        rajesh     ",
            "link": "https://stackoverflow.com/questions/78065606/generating-a-program-that-generates-a-word-pyramid-pattern-based-on-user-input-i",
            "title": "Generating a program that generates a word pyramid pattern based on user input in Python"
        },
        {
            "tags": [
                "python",
                "websocket"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 29436117,
                        "reputation": 11,
                        "user_id": 22554962,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/bWDwE.png?s=256&g=1",
                        "display_name": "BlackDiamond",
                        "link": "https://stackoverflow.com/users/22554962/blackdiamond"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709018268,
                    "answer_id": 78065740,
                    "question_id": 78065592,
                    "body_markdown": "I&#39;m stupid... whoops.\r\n\r\nIt turns out for the reason to the binding (and only one connection) was because I was trying to push multiple connections through the external IP of the server, not the local one (on LAN) for reasons that I&#39;ll get to in a moment. I only had the one port open on the external router, so the first connection took that one up, and the rest couldn&#39;t get through.\r\n\r\nThe clients that I&#39;m trying to run don&#39;t let you connect to a local server, so I had to connect to the outside port. I found a workaround for this, though, and was able to get it up and running just fine. \r\n\r\nI&#39;m not exactly sure why that is though, becuase I know that multiple clients on a minecraft server can connect on one port, so I don&#39;t see why this is any different. Oh well. Connecting locally is good enough for what I&#39;m doing so I don&#39;t need the help anymore.\r\n\r\n",
                    "title": "Trying to run multiple outbound websocket connections. All running on the same foreign port"
                }
            ],
            "owner": {
                "account_id": 29436117,
                "reputation": 11,
                "user_id": 22554962,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/bWDwE.png?s=256&g=1",
                "display_name": "BlackDiamond",
                "link": "https://stackoverflow.com/users/22554962/blackdiamond"
            },
            "is_answered": false,
            "view_count": 16,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709016364,
            "question_id": 78065592,
            "body_markdown": "I&#39;m trying to run a web socket on my home server using python. It works great as long as only one connection is going out from my machine. When I try to run another instance of a client connection from the same computer, it will lock up until the first one disconnects. However, it can handle two connections at once, as long as they aren&#39;t coming out of the same machine. (I.e. I had one client running on my computer, and another running locally on the server and they both sent and received data). I did some digging and found out that while the outgoing local port for the client is always different, the outgoing foreign port is always glued to 3000, the port of the websocket I&#39;m trying to connect to. Why is the outbound port always stuck at 3000? Why can&#39;t it be the same as the local port? Here is my server code:\r\n\r\n```python\r\nimport asyncio\r\nimport websockets\r\n\r\n\r\n# identifies the port\r\nPORT = &quot;3000&quot;\r\n\r\n# identifies the hostname\r\nHOST = &quot;rx-78-2&quot;\r\n\r\n# sets the trust message that essentially acts as a secondary handshake\r\nTURTLE_MESSAGE = &quot;Shake my hand bro&quot;\r\n\r\n# sets the message that will indicate a disconnection \r\nDISCONNECT_MESSAGE = &quot;END-OF-LINE&quot;\r\n\r\nturtles = []\r\n\r\n# handles a new connection\r\nasync def handle_connect(websocket, path):\r\n    print(f&quot;CONNECTION RECIEVED @ {path}&quot;)\r\n    turtleIndex = len(turtles)\r\n    turtles.append(f&quot;Turtle {len(turtles)}&quot;)\r\n\r\n    print(turtles[turtleIndex])\r\n\r\n\r\n    connected = True\r\n\r\n    first_msg = await websocket.recv()\r\n    if first_msg != TURTLE_MESSAGE:\r\n        print(&quot;Connection Refused&quot;)\r\n        await websocket.send(&quot;return print(&#39;Connection Refused&#39;)&quot;)\r\n        await websocket.close()\r\n    else:\r\n        print(&quot;Connection Established&quot;)\r\n        await websocket.send(&quot;return print(&#39;Connection Established&#39;)&quot;)\r\n\r\n    while connected:\r\n        msg = await websocket.recv()\r\n        if msg == DISCONNECT_MESSAGE:\r\n            break\r\n        print(msg)\r\n        await websocket.send(&quot;return turtle.turnRight()&quot;)\r\n\r\n    print(&quot;CLOSING SOCKET&quot;)\r\n\r\nasync def main():\r\n    async with websockets.serve(handle_connect, HOST, PORT, ssl=None, compression=None):\r\n        await asyncio.Future()\r\n\r\nprint(&quot;STARTING SERVER&quot;)\r\nasyncio.run(main())\r\n```\r\n\r\n(don&#39;t mind the goofy stuff in there)\r\n\r\nThe client code here is irrelevant because it needs to be fixed either on my system as a whole, or on the server side, due to the actual application of the clients will be very limited. \r\n\r\n**So to sum up**\r\n* I need to have multiple websocket clients running on my machine, connecting to my home server\r\n* They all keep trying to take the foreign outbound 3000 port, causing only one client to be able to run at any given time\r\n* It cannot be fixed in the client code, it either needs to be with my machine or the server code because the application of the actual clients doesn&#39;t provide enough control for me to be able to fix the issue there. \r\n\r\nMy machine is running Fedora 39 w/ KDE Plasma, and the server is running a RHEL based OS. Any help would be greatly appreciated. Thank you.\r\n\r\nI used netstat to see the outbound and incoming connections for both the clients and the server. The server reports a connection to it&#39;s port 3000, which is to be expected, from the connecting machine&#39;s port 3000. Looking at the outgoing connection from the client, the local port is completely different (typically somewhere in the range of 50000), but the foreign port is always 3000. ",
            "link": "https://stackoverflow.com/questions/78065592/trying-to-run-multiple-outbound-websocket-connections-all-running-on-the-same-f",
            "title": "Trying to run multiple outbound websocket connections. All running on the same foreign port"
        },
        {
            "tags": [
                "python",
                "python-3.x",
                "macos"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 12553416,
                        "reputation": 19,
                        "user_id": 11877406,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/-0eqK0kpMQu8/AAAAAAAAAAI/AAAAAAAAAGw/RcL8ReSsCqg/photo.jpg?sz=256",
                        "display_name": "\u03a3\u03c4\u03c5\u03bb\u03b9\u03b1\u03bd\u03cc\u03c2 \u039c\u03c0\u03af\u03c4\u03b6\u03b1\u03c2",
                        "link": "https://stackoverflow.com/users/11877406/%ce%a3%cf%84%cf%85%ce%bb%ce%b9%ce%b1%ce%bd%cf%8c%cf%82-%ce%9c%cf%80%ce%af%cf%84%ce%b6%ce%b1%cf%82"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709016538,
                    "answer_id": 78065607,
                    "question_id": 78065508,
                    "body_markdown": "macOS comes with Python already pre-installed. \r\nIf you want to use a specific version, you could install Python manually or with a package manager.\r\n\r\nVery often, you can use it like \r\n\r\n    python3 --version\r\n\r\nor with specific versions like \r\n\r\n    python3.12 --version\r\n\r\nHowever, this depends mostly on how your PATH and aliases are structured. \r\n\r\nInstalling Python versions directly is a bit harder, so you could use a tool like Homebrew to install multiple versions. Also, a virtual environment could help develop using different Python versions.\r\n\r\nhttps://brew.sh/\r\n\r\nhttps://docs.python.org/3/library/venv.html\r\n\r\n\r\n\r\nEdit: based on the comment made by triplee, I restructured the answer to clarify that I intended to provide alternatives to overcomplicate the process for someone new to Python development, and my intention wasn&#39;t to enforce anything.   \r\n",
                    "title": "Why different versions of Python are installed?"
                },
                {
                    "owner": {
                        "account_id": 4342327,
                        "reputation": 146317,
                        "user_id": 3545273,
                        "user_type": "registered",
                        "accept_rate": 100,
                        "profile_image": "https://i.stack.imgur.com/RDWxl.png?s=256&g=1",
                        "display_name": "Serge Ballesta",
                        "link": "https://stackoverflow.com/users/3545273/serge-ballesta"
                    },
                    "is_accepted": true,
                    "score": 3,
                    "creation_date": 1709017434,
                    "answer_id": 78065677,
                    "question_id": 78065508,
                    "body_markdown": "The underlying kernel of MacOS is Darwin, a close derivative from Unix BSD. And the command line adds very little magic to a standard Bash shell.\r\n\r\nThat means that there is nothing like *&quot;python&quot; is associated with version 3*. The standard Python version is installed in `/usr/bin` like the other standard commands, and the name of the Python interpreter executable is `python`. The new version has been installed under `/Library/Frameworks/` like any other *external* tool. And the name of its Python interpreter executable happens to be `python3`. It should even have another link with the full version, just do `ls -l /Library/Frameworks/Python.framework/Versions/3.12/bin/python*` to make sure.\r\n\r\nWhen you type `python` or `python3`, the shell searches the PATH for an executable file *having exactly that name* and uses it.\r\n\r\nWhat can be done? If you can stand the current way, do not change it, because it is the standard way. Some tools may expect to find the standard 3.9 version under the name `python`. On the other hand, if you want to have other tools to launch the 3.12 version through the name `python`, you can add a new link to the Python 3 executable:\r\n\r\n    cd /Library/Frameworks/Python.framework/Versions/3.12/bin/\r\n    ln -s /Library/Frameworks/Python.framework/Versions/3.12/bin/python3 python\r\n\r\n(Use the *real* file name if `python3` is already a symbolic link - I have no Mac on hand to test it...)\r\n\r\nBut I would not advise you to do that, because it changes what is called under the name `python` for every command using the `PATH`. The blessed way is instead to use *venv*(&lt;sup&gt;*&lt;/sup&gt;) to setup a new virtual environment in which `python` and `pip` would call the expected installation, *without disturbing any other installation including the standard one*. More or less:\r\n\r\n    cd my_working_folder\r\n    python3.12 -m venv venv\r\n    ./venv/bin/activate\r\n\r\nFrom that point, but only in the current session, `python` will start the 3.12 version.\r\n\r\n---\r\n\r\n(*) more on the standard Python [doc](https://docs.python.org/fr/3/library/venv.html)",
                    "title": "Why different versions of Python are installed?"
                }
            ],
            "owner": {
                "account_id": 30283933,
                "reputation": 3,
                "user_id": 23208288,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/IJxuS.jpg?s=256&g=1",
                "display_name": "Wetmarket",
                "link": "https://stackoverflow.com/users/23208288/wetmarket"
            },
            "is_answered": true,
            "view_count": 88,
            "favorite_count": 0,
            "accepted_answer_id": 78065677,
            "answer_count": 2,
            "score": 0,
            "creation_date": 1709015226,
            "question_id": 78065508,
            "body_markdown": "I want to clarify that I recently formatted my MacBook and decided to install Python 3.12 from python.org. Command Line Tools was automatically installed. After installing the pkg file I decided to check the version and now I&#39;m confused as to why this is the case.\r\n\r\nWhy do I have two versions of Python and have to write differently, why do different associations appear\r\n\r\n```\r\nvadim@MacBook ~ % python --version\r\nPython 3.9.6\r\nvadim@MacBook ~ % python3 --version\r\nPython 3.12.2\r\n```\r\n\r\n```\r\nvadim@MacBook ~ % which python\r\npython: aliased to /usr/bin/python3\r\nvadim@MacBook ~ % which python3\r\n/Library/Frameworks/Python.framework/Versions/3.12/bin/python3\r\n```\r\n\r\nWhere does Python 3.9 come from?",
            "link": "https://stackoverflow.com/questions/78065508/why-different-versions-of-python-are-installed",
            "title": "Why different versions of Python are installed?"
        },
        {
            "tags": [
                "python",
                "pandas",
                "numpy",
                "numba",
                "python-polars"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 8103570,
                        "reputation": 2124,
                        "user_id": 12978930,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/GCxoQ.jpg?s=256&g=1",
                        "display_name": "Hericks",
                        "link": "https://stackoverflow.com/users/12978930/hericks"
                    },
                    "is_accepted": true,
                    "score": 2,
                    "creation_date": 1709029482,
                    "answer_id": 78066786,
                    "question_id": 78065466,
                    "body_markdown": "As suggested in the comments, you&#39;ll need to call [`pl.Expr.map_batches`](https://docs.pola.rs/py-polars/html/reference/expressions/api/polars.Expr.map_batches.html) on a [struct](https://docs.pola.rs/user-guide/expressions/structs/) column that contains all information needed by the function. Inside the function, you then pick the struct apart to obtain the desired information. \r\n\r\n\r\n```python\r\n(\r\n    data\r\n    .group_by([&quot;ticker&quot;, &quot;date&quot;])\r\n    .agg(\r\n        pl.struct(&quot;cumulative_dollar_volume&quot;, &quot;dollar_tau&quot;).map_batches(lambda x: \\\r\n            generate_sample_numba(\r\n                x.struct.field(&quot;cumulative_dollar_volume&quot;).to_numpy(),\r\n                dollar_tau=x.struct.field(&quot;dollar_tau&quot;).to_numpy()\r\n            )\r\n        )\r\n        .alias(&quot;bar_index&quot;)\r\n    )\r\n).explode(&quot;bar_index&quot;)\r\n```",
                    "title": "Polars groupby map UDF using multiple columns as parameter"
                }
            ],
            "owner": {
                "account_id": 20976380,
                "reputation": 99,
                "user_id": 15412256,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/6c55c60f402cc751244c55a91040e9e2?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Kevin Li",
                "link": "https://stackoverflow.com/users/15412256/kevin-li"
            },
            "is_answered": true,
            "view_count": 84,
            "favorite_count": 0,
            "accepted_answer_id": 78066786,
            "answer_count": 1,
            "score": 0,
            "creation_date": 1709014538,
            "question_id": 78065466,
            "body_markdown": "I have a numba UDF:\r\n```python\r\n@numba.jit(nopython=True)\r\ndef generate_sample_numba(cumulative_dollar_volume: np.ndarray, dollar_tau: Union[int, np.ndarray]) -&gt; np.ndarray:\r\n        &quot;&quot;&quot; Generate the sample using numba for speed.\r\n        &quot;&quot;&quot;\r\n        covered_dollar_volume = 0\r\n        bar_index = 0\r\n        bar_index_array = np.zeros_like(cumulative_dollar_volume, dtype=np.uint32)\r\n        \r\n        if isinstance(dollar_tau, int):\r\n            dollar_tau = np.array([dollar_tau] * len(cumulative_dollar_volume))\r\n\r\n        for i in range(len(cumulative_dollar_volume)):\r\n            bar_index_array[i] = bar_index\r\n            if cumulative_dollar_volume[i] &gt;= covered_dollar_volume + dollar_tau[i]:\r\n                bar_index += 1\r\n                covered_dollar_volume = cumulative_dollar_volume[i]\r\n        return bar_index_array\r\n```\r\nThe UDF takes two inputs:\r\n\r\n1. The `cumulative_dollar_volume` numpy array, which is essentially the groups in `group_by`\r\n2. The `dollar_tau` threshold, which is either an *integer* or *numpy array*.\r\n\r\nIn this question, I am particularly interested in the numpy array configuration. [This post](https://stackoverflow.com/questions/76683540/how-to-vectorize-complex-cumulative-aggregation-problem) well explains the idea behind the `generat_sample_numba` function.\r\n\r\nI want to achieve the same results from Pandas by **using polars**:\r\n```python\r\ndata[&quot;bar_index&quot;] = data.groupby([&quot;ticker&quot;, &quot;date&quot;]).apply(lambda x: generate_sample_numba(x[&quot;cumulative_dollar_volume&quot;].values, x[&quot;dollar_tau&quot;].values)).explode().values.astype(int)\r\n```\r\n\r\nApprently, the best option in Polars is by `group_by().agg(pl.col().map_batehces()`:\r\n```python\r\ncqt_sample = cqt_sample.with_columns(\r\n    (pl.col(&quot;price&quot;) * pl.col(&quot;size&quot;)).alias(&quot;dollar_volume&quot;)).with_columns(\r\n    pl.col(&quot;dollar_volume&quot;).cum_sum().over([&quot;ticker&quot;, &quot;date&quot;]).alias(&quot;cumulative_dollar_volume&quot;),\r\n    pl.lit(1_000_000).alias(&quot;dollar_tau&quot;)\r\n    )\r\n\r\n(cqt_sample\r\n    .group_by([&quot;ticker&quot;, &quot;date&quot;])\r\n    .agg(pl.col([&quot;cumulative_dollar_volume&quot;, &quot;dollar_tau&quot;])\r\n         .map_batches(lambda x: generate_sample_numba(x[&quot;cumulative_dollar_volume&quot;].to_numpy(), 1_000_000))\r\n                      )#.alias(&quot;bar_index&quot;)\r\n                      )#.explode(&quot;bar_index&quot;)\r\n```\r\nbut the `map_bathces()` method seems to throw some strange results.`\r\n\r\nHowever, when I use the integer `dollar_tau` with one input column it works fine:\r\n```python\r\n(cqt_sample\r\n    .group_by([&quot;ticker&quot;, &quot;date&quot;])\r\n    .agg(pl.col(&quot;cumulative_dollar_volume&quot;)\r\n         .map_batches(lambda x: generate_sample_numba(x.to_numpy(), 1_000_000))\r\n                      ).alias(&quot;bar_index&quot;)\r\n                      ).explode(&quot;bar_index&quot;)\r\n```",
            "link": "https://stackoverflow.com/questions/78065466/polars-groupby-map-udf-using-multiple-columns-as-parameter",
            "title": "Polars groupby map UDF using multiple columns as parameter"
        },
        {
            "tags": [
                "python",
                "sympy"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 15983509,
                        "reputation": 6416,
                        "user_id": 12131013,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/2ca3cc0afaf24c7597cff635749204ec?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "jared",
                        "link": "https://stackoverflow.com/users/12131013/jared"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709014082,
                    "answer_id": 78065444,
                    "question_id": 78065410,
                    "body_markdown": "Sympy doesn&#39;t realize that you want `a` and `b` to be real variables, so its output assumes they are complex. If `a` and `b` are real, then terms containing `im(a)` and/or `im(b)` are 0 since there are no imaginary parts to `a` or `b`. To fix this, you should define your variables with your assumptions, i.e. tell sympy that `a` and `b` are real. Then the result will be as expected.\r\n\r\n```python\r\nfrom sympy import *\r\na, b = symbols(&quot;a b&quot;, real=True)\r\nz1 = a + b*I\r\nz2 = simplify(expand(z1**3))\r\nprint(re(z2))\r\n```\r\n\r\nOutput:\r\n\r\n```python\r\na**3 - 3*a*b**2\r\n```",
                    "title": "How to get real part of a sympy expression?"
                },
                {
                    "owner": {
                        "account_id": 3372967,
                        "reputation": 13779,
                        "user_id": 9450991,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/1ef2430b0575e28ba34ded7ca6225be3?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Oscar Benjamin",
                        "link": "https://stackoverflow.com/users/9450991/oscar-benjamin"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709030206,
                    "answer_id": 78066858,
                    "question_id": 78065410,
                    "body_markdown": "A way to do it without setting assumptions on the symbols is:\r\n```\r\nIn [2]: z2\r\nOut[2]:\r\n 3        2          2      3\r\na  + 3\u22c5\u2148\u22c5a \u22c5b - 3\u22c5a\u22c5b  - \u2148\u22c5b\r\n\r\nIn [3]: z2i, z2r = z2.as_poly(I).all_coeffs()\r\n\r\nIn [4]: z2i\r\nOut[4]:\r\n   2      3\r\n3\u22c5a \u22c5b - b\r\n\r\nIn [5]: z2r\r\nOut[5]:\r\n 3        2\r\na  - 3\u22c5a\u22c5b\r\n```",
                    "title": "How to get real part of a sympy expression?"
                }
            ],
            "owner": {
                "account_id": 23497980,
                "reputation": 13,
                "user_id": 17548175,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/e5c50131a5a9f7eebb8c78339f6c3b99?s=256&d=identicon&r=PG",
                "display_name": "gpv",
                "link": "https://stackoverflow.com/users/17548175/gpv"
            },
            "is_answered": true,
            "view_count": 37,
            "favorite_count": 0,
            "accepted_answer_id": 78065444,
            "answer_count": 2,
            "score": 1,
            "creation_date": 1709013398,
            "question_id": 78065410,
            "body_markdown": "In Sympy I want to get the real part of an expression, but unable to separate the real part. \r\n\r\n\r\nThe steps I have done: \r\n\r\n```python\r\nfrom sympy import *\r\na, b = symbols(&#39;a b&#39;)\r\nz1 = a + b*I\r\nz2 = simplify(expand(z1**3))\r\n```\r\n\r\nThe `z2` output is:\r\n\r\n```python\r\na**3 + 3*I*a**2*b - 3*a*b**2 - I*b**3\r\n```\r\n\r\nWhen I try to get the real part, I get this:\r\n```python\r\n&gt;&gt;&gt; re(z2) \r\nre(a)**3 - 3*re(a)*im(a)**2 + 3*re(b)**2*im(b) - 3*re(a*b**2) - im(b)**3 - 3*im(a**2*b)\r\n```\r\n\r\nI expected `a**3 - 3*a*b**2`.",
            "link": "https://stackoverflow.com/questions/78065410/how-to-get-real-part-of-a-sympy-expression",
            "title": "How to get real part of a sympy expression?"
        },
        {
            "tags": [
                "python",
                "arrays",
                "numpy"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 13113751,
                        "reputation": 144089,
                        "user_id": 9473764,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/pqE2g.jpg?s=256&g=1",
                        "display_name": "Nick",
                        "link": "https://stackoverflow.com/users/9473764/nick"
                    },
                    "is_accepted": false,
                    "score": 2,
                    "creation_date": 1709017342,
                    "answer_id": 78065669,
                    "question_id": 78065399,
                    "body_markdown": "You could use [`itertools.groupby`][1] to get the result you want:\r\n```\r\nimport itertools\r\n\r\nout = [list(g) for k, g in itertools.groupby(values, key=lambda v: v &lt; 0) if k]\r\n```\r\nOutput:\r\n```\r\n[[-1, -2, -3], [-7, -8]]\r\n```\r\n\r\n\r\n  [1]: https://docs.python.org/3/library/itertools.html#itertools.groupby\r\n  [2]: https://docs.python.org/3/library/functions.html#filter",
                    "title": "Select consecutive elements that satisfy a certain condition as separate arrays"
                },
                {
                    "owner": {
                        "account_id": 23521233,
                        "reputation": 1982,
                        "user_id": 17568469,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/Lu2Oc.jpg?s=256&g=1",
                        "display_name": "ljdyer",
                        "link": "https://stackoverflow.com/users/17568469/ljdyer"
                    },
                    "is_accepted": false,
                    "score": -2,
                    "creation_date": 1709017541,
                    "answer_id": 78065685,
                    "question_id": 78065399,
                    "body_markdown": "Here&#39;s an easy-to-understand solution using only pure Python:\r\n\r\n    # Example data\r\n    my_list = [1, 2, 3, -1, -2, -3, 4, 5, 6, -7, -8, 10]\r\n    my_condition = lambda x: x &lt; 0\r\n\r\n    # Get list of True, False values for whether elements satisfy the condition\r\n    mask = [my_condition(x) for x in my_list]\r\n    # Get list of indices in the list where the condition goes from being True to False\r\n    breakpoints = [i for i in range(1, len(mask)) if mask[i] != mask[i-1]]\r\n    # Get the sublists satisfying the condition\r\n    sublists = [my_list[a:b] \r\n                for a, b in zip([0, *breakpoints[:-1]], breakpoints)\r\n                if all(my_condition(x) for x in my_list[a:b])]\r\n\r\n    print(sublists)\r\n\r\nOutput:\r\n\r\n    [[-1, -2, -3], [-7, -8]]",
                    "title": "Select consecutive elements that satisfy a certain condition as separate arrays"
                },
                {
                    "owner": {
                        "account_id": 22084389,
                        "reputation": 223378,
                        "user_id": 16343464,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/7kTic.png?s=256&g=1",
                        "display_name": "mozway",
                        "link": "https://stackoverflow.com/users/16343464/mozway"
                    },
                    "is_accepted": true,
                    "score": 4,
                    "creation_date": 1709023508,
                    "answer_id": 78066162,
                    "question_id": 78065399,
                    "body_markdown": "#### clustering groups of negative numbers\r\nIf you only want to group the chunks of negative values, irrespective of their relative values, then simply compute a second mask to identify the starts of each negative chunk:\r\n```\r\nmask = values &lt; 0\r\nmask2 = np.r_[True, np.diff(mask)]\r\nout = np.array_split(values[mask], np.nonzero(mask2[mask])[0][1:])\r\n```\r\nOutput: `[array([-1, -7, -3]), array([-7, -8])]`\r\n\r\n#### clustering groups of negative numbers if they are successive in value\r\nIf you want to cluster the negative values that also a successively decreasing (e.g. `-1, -2, -3, -5, -6` would form 2 clusters: `-1, -2, -3` and `-5, -6`. Then I would use [tag:pandas]:\r\n\r\n- convert to `Series`\r\n- identify the negative values\r\n- create a grouper for consecutive negative values (`(~mask).cumsum()`)\r\n- add the index (or a range) to group the successive\r\n- `groupby`\r\n```\r\nimport pandas as pd\r\n\r\ns = pd.Series(values)\r\n\r\n# mask to keep negative values\r\nmask = s&lt;0\r\n# group consecutive negatives\r\ngroup1 = (~mask).cumsum()\r\n# group successive decrementing values\r\ns2 = s+s.index\r\ngroup2 = s2.ne(s2.shift()).cumsum()\r\n\r\nout = [g.to_numpy() for k, g in s[mask].groupby([group1, group2])]\r\n```\r\nOutput: `[array([-1, -2, -3]), array([-7, -8]), array([-7])]`\r\n\r\nIntermediates:\r\n```\r\n     s   mask  s2  group1  group2\r\n0    1  False   1       1       1\r\n1    2  False   3       2       2\r\n2    3  False   5       3       3\r\n3   -1   True   2       3       4 # out 1\r\n4   -2   True   2       3       4 #\r\n5   -3   True   2       3       4 #\r\n6    4  False  10       4       5\r\n7    5  False  12       5       6\r\n8    6  False  14       6       7\r\n9   -7   True   2       6       8  # out 2 \r\n10  -8   True   2       6       8  #\r\n11  -7   True   4       6       9    # out 3\r\n12  10  False  22       7      10\r\n```",
                    "title": "Select consecutive elements that satisfy a certain condition as separate arrays"
                }
            ],
            "owner": {
                "account_id": 4557100,
                "reputation": 3017,
                "user_id": 3700524,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/XVsYW.jpg?s=256&g=1",
                "display_name": "Mohsen_Fatemi",
                "link": "https://stackoverflow.com/users/3700524/mohsen-fatemi"
            },
            "is_answered": true,
            "view_count": 71,
            "favorite_count": 0,
            "accepted_answer_id": 78066162,
            "answer_count": 3,
            "score": 3,
            "creation_date": 1709013152,
            "question_id": 78065399,
            "body_markdown": "Given an array of values, I want to select multiple sequences of consecutive elements that satisfy a condition. The result should be one array for each sequence of elements. \r\n\r\nFor example I have an array containing both negative and positive numbers. I need to select sequences of negative numbers, with each sequence in a separate array.  \r\nHere is an example :\r\n\r\n    import numpy as np\r\n    \r\n    # Example data\r\n    values = np.array([1, 2, 3, -1, -2, -3, 4, 5, 6, -7, -8, 10])\r\n    \r\n    mask = values &lt; 0\r\nHere is how the output should look like :\r\n\r\n\r\n    Array 1:\r\n    \r\n    [-1 -2 -3]\r\n    \r\n    Array 2:\r\n    \r\n    [-7 -8]\r\n\r\nI tried to do it using `numpy.split`, but it became more like spaghetti code. I was wondering is there a Pythonic way to do this task?",
            "link": "https://stackoverflow.com/questions/78065399/select-consecutive-elements-that-satisfy-a-certain-condition-as-separate-arrays",
            "title": "Select consecutive elements that satisfy a certain condition as separate arrays"
        },
        {
            "tags": [
                "python",
                "pdf",
                "python-requests"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 5603241,
                        "reputation": 197,
                        "user_id": 7681119,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/7p1wH.jpg?s=256&g=1",
                        "display_name": "Caleb McNevin",
                        "link": "https://stackoverflow.com/users/7681119/caleb-mcnevin"
                    },
                    "is_accepted": false,
                    "score": 5,
                    "creation_date": 1709021178,
                    "answer_id": 78065965,
                    "question_id": 78065364,
                    "body_markdown": "I&#39;ll explain how I figured this out to help your understanding:\r\n\r\nI used the &#39;Network&#39; tab in my browser&#39;s (Chrome) devtools to find the successful request that is sent to the server by my browser. This is the request that allows you to successfully access the file, as opposed to the request sent from the python script which doesn&#39;t effectively download the file, and rather returns http error code [403 - Forbidden][1] (Note: as far as I&#39;m concerned, this is obviously the website indicating that downloading the file this way is forbidden).\r\n\r\nI looked into the request headers and added one to the `headers` argument of `request.get()`. This gave me a successful http status code of [200 - OK][2]. I continued to remove headers until finding the minimum set of headers needed, which are &quot;Cookie&quot; and &quot;User-Agent&quot;. If you copy those headers into the `headers` (headers is a dictionary) argument of `request.get()` it will work\r\n\r\nThat said, you will need to copy the values for the User-Agent and Cookies out of your browser&#39;s devtools. The cookies also change over time, so you&#39;ll need to use the browser anyway to get up-to-date values for your request. Either that, or you&#39;ll need to really dig deep into how the site works and reverse engineer their cookie generation, if that&#39;s even possible. I&#39;d advise against pursuing it too much further, as in my opinion the site is indicating that they don&#39;t want you downloading files programmatically like this.\r\n\r\n## Where to go from here\r\n\r\nApparently every paper in the Heliyon collection, which is the collection your example pdf is in, is also [hosted on ScienceDirect][3]:\r\n\r\n&gt; Every published article will be immediately available on both cell.com/heliyon and ScienceDirect and will be indexed by PubMed, Scopus, Web of Science\u2122 and Science Citation Index Expanded\u2122 (SCIE), ensuring that it reaches the widest possible audience. Heliyon&#39;s impact factor is 4.0 as of June 2023.\r\n\r\nElsevier, which runs ScienceDirect, has a [free-to-use API][4] with which you can easily download articles, including the one you are trying to download, with just the [doi][5] and your API key. I&#39;ve put together an extremely simple script below that you can use once you&#39;ve [registered for the Elsevier API][6] and created your own api key:\r\n\r\n    api_template = &#39;https://api.elsevier.com/content/article/doi/{doi}?apiKey={api_key}&amp;httpAccept={http_accept}&#39;\r\n\r\n    doi = &#39;10.1016/j.heliyon.2018.e00938&#39;\r\n    api_key = &#39;&lt;your_api_key&gt;&#39;\r\n    http_accept = &#39;application/pdf&#39;\r\n\r\n    uri = api_template.format(doi=doi, api_key=api_key, http_accept=http_accept)\r\n    res = requests.get(uri)\r\n    with open(&#39;out.pdf&#39;, &#39;wb&#39;) as f:\r\n        f.write(res.content)\r\n\r\nI&#39;ve not included things like error handling, or even wrapping this in a function, but this should get you started. Best of luck!\r\n\r\n\r\n  [1]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403\r\n  [2]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200\r\n  [3]: https://www.cell.com/heliyon/aims-and-scope\r\n  [4]: https://dev.elsevier.com/sciencedirect.html#!/Article_Retrieval/ArticleRetrieval\r\n  [5]: https://www.doi.org/\r\n  [6]: https://dev.elsevier.com/apikey/manage",
                    "title": "Download a pdf url using Python"
                },
                {
                    "owner": {
                        "account_id": 12647390,
                        "reputation": 11,
                        "user_id": 9244022,
                        "user_type": "registered",
                        "profile_image": "https://lh4.googleusercontent.com/-xlvwPs8HcK0/AAAAAAAAAAI/AAAAAAAAABg/c_4s0i7ozqg/photo.jpg?sz=256",
                        "display_name": "Shawn Lee",
                        "link": "https://stackoverflow.com/users/9244022/shawn-lee"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709022824,
                    "answer_id": 78066094,
                    "question_id": 78065364,
                    "body_markdown": "Some people who vote down this answer don&#39;t even want to click on the reference link to take a glance.\r\n\r\n    from seleniumbase import Driver\r\n    import time\r\n\r\n    driver = Driver(uc=True, external_pdf = True)\r\n    driver.get(url)\r\n    time.sleep(4)\r\n    driver.quit()\r\n\r\nRef:\r\nhttps://stackoverflow.com/questions/71518406/how-to-bypass-cloudflare-browser-checking-selenium-python\r\n",
                    "title": "Download a pdf url using Python"
                }
            ],
            "owner": {
                "account_id": 19023873,
                "reputation": 11,
                "user_id": 13887380,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/00c713e1d46c7cda17ad0b22f0bd6f3d?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "jonahbardos",
                "link": "https://stackoverflow.com/users/13887380/jonahbardos"
            },
            "is_answered": true,
            "view_count": 106,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 1,
            "creation_date": 1709012487,
            "question_id": 78065364,
            "body_markdown": "I am trying to download a .pdf url from this website \r\n[PDFLINK](https://www.cell.com/heliyon/pdf/S2405-8440(18)33206-7.pdf)\r\nhttps://www.cell.com/heliyon/pdf/S2405-8440(18)33206-7.pdf\r\nI am able to view it from my browser, but using the requests with Python won&#39;t let me download it.\r\n\r\nI tried the following, but I was not able to get it to download properly. It would return a 403 or say that the .pdf is corrupted. But I can view the link fine https://www.cell.com/heliyon/pdf/S2405-8440(18)33206-7.pdf\r\nAny ideas?\r\n```\r\nimport requests\r\n\r\n\r\ndef download_pdf(url):\r\n    response = requests.get(url)\r\n    with open(&#39;sample.pdf&#39;, &#39;wb&#39;) as f:\r\n        f.write(response.content)\r\n\r\n\r\nif __name__ == &quot;__main__&quot;:\r\n    url = &quot;https://www.cell.com/heliyon/pdf/S2405-8440(18)33206-7.pdf&quot;\r\n    download_pdf(url)\r\n\r\n```\r\n",
            "link": "https://stackoverflow.com/questions/78065364/download-a-pdf-url-using-python",
            "title": "Download a pdf url using Python"
        },
        {
            "tags": [
                "python",
                "class"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30596791,
                        "reputation": 11,
                        "user_id": 23453713,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocILgcIoG-fAF5bx0yEMuNaLpQcMqNGdg36nq5nIWfBBKg=k-s256",
                        "display_name": "Sumaiyaee",
                        "link": "https://stackoverflow.com/users/23453713/sumaiyaee"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709030951,
                    "answer_id": 78066943,
                    "question_id": 78065294,
                    "body_markdown": "Try:\r\n\r\n    import numpy as np\r\n    class Test(np.ndarray):\r\n      def __init__(self,npArray):\r\n        self.__npArr__ = npArray.copy()\r\n      def shift_up(self):\r\n        tempArr = list(self.__npArr__)\r\n        if len(tempArr) &lt;1:\r\n        \tpass #Make sure to check the boundaries\r\n        for i in range(len(tempArr)-1,0,-1):\r\n          tempArr[i] = tempArr[i-1]\r\n        tempArr[0] = np.nan\r\n        self.__npArr__ = tempArr\r\n      def truncate(self,index):\r\n        if index &gt; len(self.__npArr__):\r\n          pass #Make sure you check the boundaries first\r\n        self.__npArr__ = self.__npArr__[:index]\r\n      def __str__(self): #This is called when you&#39;re trying to print the object\r\n        return str(self.__npArr__)\r\n        \r\n    array = Test( np.array([1,2,3,4,5]))\r\n    print(array)\r\n    array.truncate(3)\r\n    print(array)\r\n    array.shift_up()\r\n    print(array)\r\n\r\n",
                    "title": "How to make a ndarray class object with function to change itself?"
                },
                {
                    "owner": {
                        "account_id": 30572910,
                        "reputation": 31,
                        "user_id": 23434143,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKOEegiVq-AIFjzEVCPHA1n6OEgjk8ex89fiC8EfpHS=k-s256",
                        "display_name": "MohammadJavad Yousefi",
                        "link": "https://stackoverflow.com/users/23434143/mohammadjavad-yousefi"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709035376,
                    "answer_id": 78067401,
                    "question_id": 78065294,
                    "body_markdown": "To answer the question about shifting up the array, you should know that **the main problem is that you modify a copy of the array, not the array itself**. I write an example to shift up elements in the array.\r\n\r\n    def shift_up(self):\r\n        # define a variable to access self\r\n        arr = self\r\n\r\n        # keep last element\r\n        last_element = arr[-1]\r\n\r\n        # shift other elements\r\n        n = len(self)\r\n        for i in range(1,n)[::-1]:\r\n            arr[i] = arr[i-1]\r\n          \r\n        # put last value to first elemetn to rotate\r\n        arr[0] = last_element\r\n\r\nyou also override __new__ to easily instantiate Test objects. Full code is like this:\r\n\r\n\r\n    import numpy as np\r\n    \r\n    class Test(np.ndarray): \r\n    \r\n        # this helps to create instace of Test\r\n        def __new__(cls, a):\r\n            obj = np.asarray(a).view(cls)\r\n            return obj\r\n    \r\n    \r\n        def shift_up(self):\r\n            # define a variable to access self\r\n            arr = self\r\n    \r\n            # keep last element\r\n            last_element = arr[-1]\r\n    \r\n            # shift other elements\r\n            n = len(self)\r\n            for i in range(1,n)[::-1]:\r\n                arr[i] = arr[i-1]\r\n              \r\n            # put last value to first elemetn to rotate\r\n            arr[0] = last_element\r\n    \r\n    \r\n    array = Test(np.array([1,2,3,4,5]))\r\n    array.shift_up()\r\n    print(array)\r\n\r\n",
                    "title": "How to make a ndarray class object with function to change itself?"
                }
            ],
            "owner": {
                "account_id": 21460477,
                "reputation": 73,
                "user_id": 15811337,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/b48525f96a1b98c004abe2c12ad145ea?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "Luluz",
                "link": "https://stackoverflow.com/users/15811337/luluz"
            },
            "is_answered": true,
            "view_count": 41,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 0,
            "creation_date": 1709011228,
            "question_id": 78065294,
            "body_markdown": "I would like to have a class like this\r\n\r\n\r\n    class Test(np.ndarray):\r\n\r\n        def shift_up(self):\r\n            arr = np.copy(self)\r\n            n = len(self)\r\n            for i in range(1,n)[::-1]:\r\n                arr[i] = arr[i-1]\r\n            arr[0] = np.nan\r\n            self.__init__(arr)\r\n\r\n        def truncate(self,index):\r\n            arr = np.copy(self)\r\n            arr_slice = np.copy(arr[:index+1])\r\n            self.__init__(arr_slice) \r\n\r\n    array = Test(np.array([1,2,3,4,5]))\r\n    array.truncate(5)\r\n\r\n\r\nI know I can just do it with the numpy functions. But I want it to be like this just to make it more legible. But this doesn&#39;t work.",
            "link": "https://stackoverflow.com/questions/78065294/how-to-make-a-ndarray-class-object-with-function-to-change-itself",
            "title": "How to make a ndarray class object with function to change itself?"
        },
        {
            "tags": [
                "python",
                "computer-vision",
                "ocr",
                "yolo"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 16060245,
                        "reputation": 407,
                        "user_id": 11591342,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/aJ3Gx.gif?s=256&g=1",
                        "display_name": "tacon",
                        "link": "https://stackoverflow.com/users/11591342/tacon"
                    },
                    "is_accepted": false,
                    "score": 1,
                    "creation_date": 1709052472,
                    "answer_id": 78069178,
                    "question_id": 78065293,
                    "body_markdown": "Welcome Pranith ! \r\n\r\nThe [EasyOCR project][1] on Github lists a commit to `utils.py`: [Update utils.py][2]. Apparently, `Image.Resampling.LANCZOS` replaced `PIL.Image.ANTIALIAS` in Pillow 10.\r\n\r\nYou can check your own Pillow version with `pip list | grep pillow`. \r\nMake sure you have:\r\n- either the EasyOCR version which includes the mentioned commit (and still compatible with Python `3.10`, which you are using)\r\n- or keep your EasyOCR version but downgrade your Pillow version accordingly, so that it has `PIL.Image.ANTIALIAS`\r\n\r\n  [1]: https://github.com/JaidedAI/EasyOCR\r\n  [2]: https://github.com/JaidedAI/EasyOCR/commit/caf88774f673774079c681d77d2314c986431104",
                    "title": "Attributeerror-module-pil-image-has-no-attribute-antialias"
                }
            ],
            "owner": {
                "account_id": 30639585,
                "reputation": 11,
                "user_id": 23488248,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocK5K2aSmUEbj4MzSLZP5448FO4hd9LOPmUN5nWqSvWryw=k-s256",
                "display_name": "Pranith Pashikanti",
                "link": "https://stackoverflow.com/users/23488248/pranith-pashikanti"
            },
            "is_answered": true,
            "view_count": 20,
            "favorite_count": 0,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709011212,
            "question_id": 78065293,
            "body_markdown": "I am working on Automatic Number plate detection problem using opencv and yolo.\r\nI am getting the below error when i pass the numpy array to easyocr readtext module\r\n```\r\nimport easyocr\r\nreader = easyocr.Reader([&#39;en&#39;], gpu=False)\r\n\r\nprint(type(license_plate_crop)) # &lt;class &#39;numpy.ndarray&#39;&gt;\r\nprint(license_plate_crop)\r\ndetections = reader.readtext(license_plate_crop)\r\n\r\n```\r\nThis is the error i am getting\r\n```\r\nline 619, in get_image_list\r\n    crop_img,ratio = compute_ratio_and_resize(crop_img,width,height,model_height)\r\n  File &quot;/home/pranith_dev/Desktop/Datavoice/Automatic-License-Plate-Recognition-using-YOLOv8/dev-venv/lib/python3.10/site-packages/easyocr/utils.py&quot;, line 582, in compute_ratio_and_resize\r\n    img = cv2.resize(img,(int(model_height*ratio),model_height),interpolation=Image.ANTIALIAS)\r\nAttributeError: module &#39;PIL.Image&#39; has no attribute &#39;ANTIALIAS&#39;\r\n```\r\n\r\n\r\nI tried downgrading pillow version from  10.0.0 to 9.5 or 9.4 according to online solutions but the issue still persists and the following is the output\r\n```\r\n&lt;class &#39;numpy.ndarray&#39;&gt;\r\n[[255 255 255 ... 255 255 255]\r\n [255 255 255 ... 255 255 255]\r\n [255 255 255 ... 255 255 255]\r\n ...\r\n [255 255 255 ... 255 255 255]\r\n [255 255 255 ... 255 255 255]\r\n [255 255 255 ... 255 255 255]]\r\nIllegal instruction\r\n```\r\n\r\n",
            "link": "https://stackoverflow.com/questions/78065293/attributeerror-module-pil-image-has-no-attribute-antialias",
            "title": "Attributeerror-module-pil-image-has-no-attribute-antialias"
        },
        {
            "tags": [
                "python",
                "pytorch",
                "active-learning"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 30632153,
                        "reputation": 1,
                        "user_id": 23482309,
                        "user_type": "registered",
                        "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocJk5ctEgdRa_ju-XfhHDOlANUZz7B1PiRlIDkXNVrVy=k-s256",
                        "display_name": "rajnee dhage",
                        "link": "https://stackoverflow.com/users/23482309/rajnee-dhage"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709008878,
                    "answer_id": 78065185,
                    "question_id": 78065138,
                    "body_markdown": "**Yes , it is possible to add data during training time , it dynamically updates during training !**\r\nCheck the inputs providing to training model, if encoded well or mapped to your model performance ?\r\n**CUDA Error -** occurring due to exceeding the dataset range or accessing elements beyond dataset size.\r\n",
                    "title": "Can I change the size of input data during training?"
                },
                {
                    "owner": {
                        "account_id": 13681702,
                        "reputation": 2213,
                        "user_id": 10044560,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/3319db89a56b1170adf6c51fe9616b72?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "Karl",
                        "link": "https://stackoverflow.com/users/10044560/karl"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709016164,
                    "answer_id": 78065575,
                    "question_id": 78065138,
                    "body_markdown": "The error is likely coming from an out of bounds index. Since you&#39;re adding a label, my guess is somewhere in the code the class index of the new label is trying to index into something sized for the old number of labels.",
                    "title": "Can I change the size of input data during training?"
                }
            ],
            "owner": {
                "account_id": 30639182,
                "reputation": 1,
                "user_id": 23487922,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocIlD2I8EdcWXhRGMA876MLf6zsCfCzIBBcJ-UhCSnBkBVE=k-s256",
                "display_name": "ChunFang",
                "link": "https://stackoverflow.com/users/23487922/chunfang"
            },
            "is_answered": false,
            "view_count": 27,
            "favorite_count": 0,
            "answer_count": 2,
            "score": 0,
            "creation_date": 1709007588,
            "question_id": 78065138,
            "body_markdown": "I am trying to do active learning and bump into the error:\r\n```\r\nRuntimeError: CUDA error: device-side assert triggered CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect. \r\n```\r\nI think the reason of this error is because that I add labeled data during training.\r\nIs it possible to add data to dataset during training?\r\n\r\nI have tried using just CPU.\r\nBut it&#39;s too slow.",
            "link": "https://stackoverflow.com/questions/78065138/can-i-change-the-size-of-input-data-during-training",
            "title": "Can I change the size of input data during training?"
        },
        {
            "tags": [
                "python",
                "pandas"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 14119619,
                        "reputation": 1569,
                        "user_id": 10200497,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/RQPQm.jpg?s=256&g=1",
                        "display_name": "x_Amir_x",
                        "link": "https://stackoverflow.com/users/10200497/x-amir-x"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709009837,
                    "answer_id": 78065229,
                    "question_id": 78065114,
                    "body_markdown": "Use ; to seperate CSS properties.\r\n\r\n    def highlight_cells(s):\r\n        if s.name==&#39;a&#39;:\r\n            conds = [s &gt; 0, s &lt; 0, s == 0]\r\n            labels = [&#39;background-color: lime; color: white&#39;, &#39;background-color: pink; color: white&#39;, &#39;background-color: gold&#39;]\r\n            array = np.select(conds, labels, default=&#39;&#39;)\r\n            return array\r\n        else:\r\n            return [&#39;&#39;]*s.shape[0]\r\n    \r\n    df.style.apply(highlight_cells).to_excel(&#39;df.xlsx&#39;, index=False)",
                    "title": "How can I conditionally change background color and font color of a cell when using Pandas to_excel?"
                },
                {
                    "owner": {
                        "account_id": 4557100,
                        "reputation": 3017,
                        "user_id": 3700524,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/XVsYW.jpg?s=256&g=1",
                        "display_name": "Mohsen_Fatemi",
                        "link": "https://stackoverflow.com/users/3700524/mohsen-fatemi"
                    },
                    "is_accepted": true,
                    "score": 1,
                    "creation_date": 1709010070,
                    "answer_id": 78065239,
                    "question_id": 78065114,
                    "body_markdown": "In this case you can add font colors as a list to the function too:\r\n\r\n    def highlight_cells(s):\r\n        if s.name == &#39;a&#39;:\r\n            conds = [s &gt; 0, s &lt; 0, s == 0]\r\n            background_labels = [&#39;background-color: lime&#39;, &#39;background-color: pink&#39;, &#39;background-color: gold&#39;]\r\n            # desired font colors\r\n            font_labels = [&#39;color: white&#39;, &#39;color: white&#39;, &#39;&#39;]  # Add font color labels\r\n            background_array = np.select(conds, background_labels, default=&#39;&#39;)\r\n            font_array = np.select(conds, font_labels, default=&#39;&#39;)  # Apply font color\r\n            return [f&#39;{b}; {f}&#39; for b, f in zip(background_array, font_array)]  # Combine background and font styles\r\n        else:\r\n            return [&#39;&#39;] * s.shape[0]",
                    "title": "How can I conditionally change background color and font color of a cell when using Pandas to_excel?"
                }
            ],
            "owner": {
                "account_id": 14119619,
                "reputation": 1569,
                "user_id": 10200497,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/RQPQm.jpg?s=256&g=1",
                "display_name": "x_Amir_x",
                "link": "https://stackoverflow.com/users/10200497/x-amir-x"
            },
            "is_answered": true,
            "view_count": 44,
            "favorite_count": 0,
            "accepted_answer_id": 78065239,
            "answer_count": 2,
            "score": 0,
            "creation_date": 1709007138,
            "question_id": 78065114,
            "body_markdown": "This is my DataFrame:\r\n\r\n    import numpy as np \r\n    import pandas as pd\r\n    \r\n    df = pd.DataFrame(\r\n        {\r\n            &#39;a&#39;: [2, 2, 2, -4, np.nan, np.nan, 4, -3, 2, -2, -6],\r\n            &#39;b&#39;: [2, 2, 2, 4, 4, 4, 4, 3, 2, 2, 6]\r\n        }\r\n    )\r\n\r\nI want to change background color and font color of cells only for column `a`. For example, if `df.a &gt; 0` background color is green otherwise it is red.\r\n\r\nThis code does that:\r\n\r\n    def highlight_cells(s):\r\n        if s.name==&#39;a&#39;:\r\n            conds = [s &gt; 0, s &lt; 0, s == 0]\r\n            labels = [&#39;background-color: lime&#39;, &#39;background-color: pink&#39;, &#39;background-color: gold&#39;]\r\n            array = np.select(conds, labels, default=&#39;&#39;)\r\n            return array\r\n        else:\r\n            return [&#39;&#39;]*s.shape[0]\r\n\r\n    df.style.apply(highlight_cells).to_excel(&#39;df.xlsx&#39;, index=False)\r\n     \r\nBut I don&#39;t know how to add font color to that. I can add the same conditional with `color` property and repeat these lines but I want to know if there is a better way.\r\n",
            "link": "https://stackoverflow.com/questions/78065114/how-can-i-conditionally-change-background-color-and-font-color-of-a-cell-when-us",
            "title": "How can I conditionally change background color and font color of a cell when using Pandas to_excel?"
        },
        {
            "tags": [
                "python",
                "selenium-webdriver",
                "web-scraping",
                "iframe"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 2772450,
                        "reputation": 22632,
                        "user_id": 2386774,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/dea7da142cb7e85d5d5a8576e2625431?s=256&d=identicon&r=PG",
                        "display_name": "JeffC",
                        "link": "https://stackoverflow.com/users/2386774/jeffc"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709008726,
                    "answer_id": 78065179,
                    "question_id": 78065113,
                    "body_markdown": "I think I was able to find the page you were on... at least it seems to be the same or similar. I inspected the Agree button and found that it was not in an IFRAME. The XPath below will find that button.\r\n\r\n    //a[text()=&#39;Agree&#39;]\r\n\r\nIt basically just looks for an A tag that contains the text &quot;Agree&quot;.",
                    "title": "How to interact with an iframe with no reference markup using python-selenium?"
                },
                {
                    "owner": {
                        "account_id": 15083819,
                        "reputation": 33211,
                        "user_id": 10885684,
                        "user_type": "registered",
                        "profile_image": "https://www.gravatar.com/avatar/8741f5157e8373f8e15707f358c6e941?s=256&d=identicon&r=PG&f=y&so-version=2",
                        "display_name": "KunduK",
                        "link": "https://stackoverflow.com/users/10885684/kunduk"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709025319,
                    "answer_id": 78066333,
                    "question_id": 78065113,
                    "body_markdown": "The `Agree` button on the webpage is NOT inside an Iframe.\r\nIt seems you are getting element visibility issue.\r\nUse `explicit wait` and wait for element to be clickable. \r\nUse following css selector to identify the element.\r\n\r\n    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, &quot;.modal-dialog a.button-1&quot;))).click()\r\n\r\nNeed to import following libraries as well.\r\n\r\n    from selenium.webdriver.common.by import By\r\n    from selenium.webdriver.support import expected_conditions as EC\r\n    from selenium.webdriver.support.ui import WebDriverWait\r\n\r\n",
                    "title": "How to interact with an iframe with no reference markup using python-selenium?"
                },
                {
                    "owner": {
                        "account_id": 10299692,
                        "reputation": 6278,
                        "user_id": 7598774,
                        "user_type": "registered",
                        "accept_rate": 75,
                        "profile_image": "https://i.stack.imgur.com/mei3t.jpg?s=256&g=1",
                        "display_name": "Shawn",
                        "link": "https://stackoverflow.com/users/7598774/shawn"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709025400,
                    "answer_id": 78066342,
                    "question_id": 78065113,
                    "body_markdown": "The &lt;kbd&gt;Agree&lt;/kbd&gt; button is not inside an `IFRAME`, so you no need to worry about dealing with IFRAME to click on the desired button.\r\n\r\nRefer the below code to click on the button using [Explicit Waits](https://www.selenium.dev/documentation/webdriver/waits/)\r\n\r\n````\r\nimport time\r\nfrom selenium import webdriver\r\nfrom selenium.webdriver.common.by import By\r\nfrom selenium.webdriver.support.wait import WebDriverWait\r\nfrom selenium.webdriver.support import expected_conditions as EC\r\n\r\ndriver = webdriver.Chrome()\r\ndriver.maximize_window()\r\ndriver.get(&#39;https://beacon.schneidercorp.com/Application.aspx?AppID=1015&amp;LayerID=21105&amp;PageTypeID=2&amp;PageID=9036&#39;)\r\n\r\n# Create a wait object with 10s wait time\r\nwait = WebDriverWait(driver,10)\r\n\r\n# Click on Agree cookies button\r\nwait.until(EC.element_to_be_clickable((By.XPATH, &quot;//a[text()=&#39;Agree&#39;]&quot;))).click()\r\ntime.sleep(10)\r\n````",
                    "title": "How to interact with an iframe with no reference markup using python-selenium?"
                },
                {
                    "owner": {
                        "account_id": 18043640,
                        "reputation": 845,
                        "user_id": 13115170,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/upyof.jpg?s=256&g=1",
                        "display_name": "Jakob Bagterp",
                        "link": "https://stackoverflow.com/users/13115170/jakob-bagterp"
                    },
                    "is_accepted": false,
                    "score": 0,
                    "creation_date": 1709039811,
                    "answer_id": 78067848,
                    "question_id": 78065113,
                    "body_markdown": "Would you consider using an extension to Selenium?\r\n\r\nIn full disclosure, I&#39;m the author of [Browserist][1]. This package is lightweight, less verbose extension of the Selenium web driver that makes browser automation even easier. Simply install the package with `pip install browserist` and you&#39;re ready to go.\r\n\r\nAs some of the other answers point out, the cookie banner isn&#39;t wrapped in an iframe. Maybe something like this would work?\r\n\r\n```python\r\nfrom browserist import Browser\r\n\r\nwith Browser() as browser:\r\n    browser.open.url(&quot;https://beacon.schneidercorp.com/Application.aspx?AppID=1015&amp;LayerID=21105&amp;PageTypeID=2&amp;PageID=9036&quot;)\r\n    browser.click.button(&quot;//div[@class=&#39;modal-footer&#39;]//a[text()=&#39;Agree&#39;]&quot;)\r\n```\r\n\r\nIf you wanted to engage with elements inside an iframe element and hereafter come back to the origin page, it&#39;s fairly easy. Example on how to continue your script with [Browserist][1]:\r\n\r\n```python\r\n    browser.iframe.switch_to(&quot;//iframe[@id=&#39;id-of-iframe&#39;]&quot;)\r\n    browser.click.button(&quot;//xpath/to/button/inside/iframe&quot;)\r\n    browser.iframe.switch_to_original_page()\r\n```\r\n\r\n[Browserist][1] also has a [built-in method to handle cookie banners][2], which makes it much more scalable and easier to read. You can refactor the example above to this: \r\n\r\n```python\r\nfrom browserist import Browser, CookieBannerSettings\r\n\r\naccept_cookies = CookieBannerSettings(\r\n    url=&quot;https://beacon.schneidercorp.com/Application.aspx?AppID=1015&amp;LayerID=21105&amp;PageTypeID=2&amp;PageID=9036&quot;,\r\n    button_xpath=&quot;//div[@class=&#39;modal-footer&#39;]//a[text()=&#39;Agree&#39;]&quot;\r\n)\r\n\r\nwith Browser() as browser:\r\n    browser.combo.cookie_banner(accept_cookies)\r\n```\r\n\r\nNotes:\r\n\r\n* [Browserist][1] doesn&#39;t need explicit conditions like `WebDriverWait`, `expected_conditions` or `element_to_be_clickable` \u2013 it&#39;s already built in so you don&#39;t have to worry about it. Instead, [Browserist][1] awaits an element to be fully loaded before it interacts with it. More on this concept [here][3].\r\n\r\n\r\n  [1]: https://jakob-bagterp.github.io/browserist/\r\n  [2]: https://jakob-bagterp.github.io/browserist/user-guide/combo-methods/cookie-banner/\r\n  [3]: https://jakob-bagterp.github.io/browserist/#difference-from-selenium",
                    "title": "How to interact with an iframe with no reference markup using python-selenium?"
                }
            ],
            "owner": {
                "account_id": 14471020,
                "reputation": 55,
                "user_id": 10453033,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/37mtA.png?s=256&g=1",
                "display_name": "Antonio Graterol",
                "link": "https://stackoverflow.com/users/10453033/antonio-graterol"
            },
            "is_answered": false,
            "view_count": 33,
            "favorite_count": 0,
            "answer_count": 4,
            "score": 2,
            "creation_date": 1709007097,
            "question_id": 78065113,
            "body_markdown": "I want to click the &quot;Agree&quot; button on this message, which I think is an iframe, on this [site](https://beacon.schneidercorp.com/Application.aspx?AppID=1015&amp;LayerID=21105&amp;PageTypeID=2&amp;PageID=9036) to fetch some data.\r\n\r\n[![picture of the popup I want to get through][1]][1]\r\n\r\nThe first problem I have is that I don&#39;t really know what I&#39;m dealing with.\r\n\r\nAt the beginning this page uses a cloudflare captcha to filter out bots, this was passed thanks to this [video](https://youtu.be/Sur4OSC5KW4?si=oYnFXNJLF7kqwc2P).\r\n\r\nThis what I&#39;ve tried so far:\r\n1. Reach the button through its container (classname &quot;modal-footer&quot; and xpath `//*[@id=&quot;appBody&quot;]/div[4]/div/div/div[2]/div[2]/a[1]`)\r\n2. Wait until the presence of message&#39;s title (classname &quot;close&quot;)\r\n3. Wait until message&#39;s &quot;X&quot; button is clickable (classname &quot;close&quot; and xpath `//*[@id=&quot;appBody&quot;]/div[4]/div/div/div[1]/button/span`)\r\n4. Count the iframes on the page so then I can use move_to statement with index argument\r\n\r\nA good approach might be using EC.frame_to_be_available_and_switch_to_it but I don&#39;t know how to refer to the frame.\r\n\r\nI&#39;ve noticed some things that might be of interest:\r\n1. The iframe I think I&#39;m dealing with is height=1, width=1, visibility: hidden as style attribute and it&#39;s located in the upper left corner of the popup window I&#39;m trying to interact with.\r\n2. Below the iframe&#39;s tags is a script hosted at [link](https://static.cloudflareinsights.com/beacon.min.js/v84a3a4012de94ce1a686ba8c167c359c1696973893317)\r\n\r\nAny advice on how solve this or in what direction I should be pointing to would be greatly appreciated\r\n\r\nThanks in advance,\r\nAntonio\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/E7BZq.png",
            "link": "https://stackoverflow.com/questions/78065113/how-to-interact-with-an-iframe-with-no-reference-markup-using-python-selenium",
            "title": "How to interact with an iframe with no reference markup using python-selenium?"
        },
        {
            "tags": [
                "python",
                "image-processing",
                "python-imaging-library",
                "png"
            ],
            "answers": [
                {
                    "owner": {
                        "account_id": 3379153,
                        "reputation": 198752,
                        "user_id": 2836621,
                        "user_type": "registered",
                        "profile_image": "https://i.stack.imgur.com/suHg4.jpg?s=256&g=1",
                        "display_name": "Mark Setchell",
                        "link": "https://stackoverflow.com/users/2836621/mark-setchell"
                    },
                    "is_accepted": true,
                    "score": 0,
                    "creation_date": 1709025132,
                    "answer_id": 78066311,
                    "question_id": 78065048,
                    "body_markdown": "**Updated Answer**\r\n\r\nMaybe @ChristophRackwitz has deduced in the comments what you want  - to actually zero out the transparent pixels so they cannot be recovered if someone later removes the alpha/transparency channel. If so, you can use:\r\n\r\n    from PIL import Image, ImageChops\r\n\r\n    # Load image and mask\r\n    im = Image.open(&#39;lena.jpg&#39;)\r\n    mask = Image.open(&#39;mask.png&#39;)\r\n\r\n    #&#160;Zero out all areas that will become transparent\r\n    darker = ImageChops.darker(im,mask)\r\n\r\n[![enter image description here][1]][1]\r\n\r\n    #&#160;Push alpha channel to make surrounding area transparent\r\n    darker.putalpha(mask.convert(&#39;L&#39;))\r\n    darker.save(&#39;result.png&#39;)\r\n\r\n[![enter image description here][2]][2]\r\n\r\n---\r\n\r\n\r\n**Original Answer**\r\n\r\nYour question doesn&#39;t make much sense to me. If you set the RGB values to 255 within the mask, the image will become white and you&#39;ll end up with your mask - which you already have.\r\n\r\nMaybe you mean you want to retain the rest of the Lena picture but just set the face to white and leave the remainder of the image *&quot;as is&quot;*. if that is the case you can use a ***Lighten*** blending mode which will simply select the brighter pixel at every location in both images - so it will select white where the mask is white and Lena everywhere else because that will certainly be brighter than the black of the mask:\r\n\r\n    PIL import Image, ImageChops\r\n\r\n    #&#160;Load image and mask\r\n    im = Image.open(&#39;lena.jpg&#39;)\r\n    mask = Image.open(&#39;mask.png&#39;)\r\n\r\n    #&#160;Select whichever is lighter at each pixel location\r\n    res = ImageChops.lighter(im,mask)\r\n    res.save(&#39;result.png&#39;)\r\n\r\n[![enter image description here][3]][3]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/yL4Ky.jpg\r\n  [2]: https://i.stack.imgur.com/HGjzm.png\r\n  [3]: https://i.stack.imgur.com/eZQWT.png",
                    "title": "How to use Pillow to set RGB value of a PNG based on a binary mask"
                }
            ],
            "owner": {
                "account_id": 2191492,
                "reputation": 381,
                "user_id": 1938410,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/c4f9ca6cda9a2759a0dd04cab9b9a014?s=256&d=identicon&r=PG&f=y&so-version=2",
                "display_name": "SamTest",
                "link": "https://stackoverflow.com/users/1938410/samtest"
            },
            "is_answered": true,
            "view_count": 39,
            "favorite_count": 0,
            "accepted_answer_id": 78066311,
            "answer_count": 1,
            "score": 1,
            "creation_date": 1709005493,
            "question_id": 78065048,
            "body_markdown": "I have an PNG image and a black-and-white mask. This post (https://note.nkmk.me/en/python-pillow-putalpha/) demonstrated how to use ```putalpha()``` to send the alpha channel of the image so the masked out area becomes transparent. I wonder if there is any function in Pillow can actually change the RGB value of the masked out area into all 255? \r\n\r\nFollowing is an example. The result image should have all white area actually have RGB value of 255, instead of only have alpha being set as 0. \r\n\r\n[![The original image][1]][1] [![The mask][2]][2] [![The image I want to get, the white area should have RGB value of 255.][3]][3]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/sxqxU.jpg\r\n  [2]: https://i.stack.imgur.com/ynq7c.png\r\n  [3]: https://i.stack.imgur.com/DfqoA.png\r\n\r\n\r\n**Updated question** \r\n\r\n(I run into some error when I try to use ```ImageChops```:\r\n\r\nHere is the code I ran:\r\n```\r\nfrom PIL import Image, ImageChops\r\n\r\nim = Image.open(&#39;lena.jpg&#39;)\r\nmask = Image.open(&#39;mask_circle.png&#39;)\r\n\r\nprint(im, mask)\r\ndarker = ImageChops.darker(im, mask)\r\ndarker.save(&#39;darker.png&#39;)\r\n```\r\nAnd the error I got:\r\n```\r\n&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x225 at 0x24725330BF0&gt; &lt;PIL.PngImagePlugin.PngImageFile image mode=RGBA size=400x225 at 0x24724F2CD40&gt;\r\nTraceback (most recent call last):\r\n  File &quot;E:\\test.py&quot;, line 7, in &lt;module&gt;\r\n    darker = ImageChops.darker(im, mask)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File &quot;C:\\...\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\ImageChops.py&quot;, line 81, in darker\r\n    return image1._new(image1.im.chop_darker(image2.im))\r\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nValueError: images do not match\r\n```\r\n",
            "link": "https://stackoverflow.com/questions/78065048/how-to-use-pillow-to-set-rgb-value-of-a-png-based-on-a-binary-mask",
            "title": "How to use Pillow to set RGB value of a PNG based on a binary mask"
        }
    ],
    "has_more": true,
    "quota_max": 300,
    "quota_remaining": 298
}

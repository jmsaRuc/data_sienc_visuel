{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet as chardet\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from alive_progress import alive_bar\n",
    "from alive_progress import alive_it\n",
    "from scripts import print_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-16le\n"
     ]
    }
   ],
   "source": [
    "def get_encoding(file):\n",
    "        with open(file, 'rb') as f:\n",
    "            result = chardet.detect(f.read())\n",
    "        return result['encoding']\n",
    "file_path = 'C:/Users/Jens/data_sienc_visuel/data/Resultat2.csv'\n",
    "encoding = get_encoding(file_path)\n",
    "print(encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57806 entries, 0 to 57805\n",
      "Data columns (total 29 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Rank                         57806 non-null  object \n",
      " 1   DokumentType                 57806 non-null  object \n",
      " 2   Titel                        57806 non-null  object \n",
      " 3   PopulærTitel                 1373 non-null   object \n",
      " 4   Ressort                      57806 non-null  object \n",
      " 5   AdministrerendeMyndighed     42568 non-null  object \n",
      " 6   JournalNummer                55179 non-null  object \n",
      " 7   Nummer                       57806 non-null  int64  \n",
      " 8   År                           57806 non-null  int64  \n",
      " 9   DokumentId                   57806 non-null  object \n",
      " 10  ACCN                         57806 non-null  object \n",
      " 11  Publiceringsmedie            57806 non-null  object \n",
      " 12  UndtagetFraOffentliggørelse  133 non-null    object \n",
      " 13  GeografiskDækning            57806 non-null  object \n",
      " 14  UnderskriftDato              57717 non-null  float64\n",
      " 15  PubliceretTidspunkt          57806 non-null  int64  \n",
      " 16  SidstPubliceretTidspunkt     57806 non-null  int64  \n",
      " 17  BekendtgørelsesDato          19304 non-null  float64\n",
      " 18  HistoriskDato                0 non-null      float64\n",
      " 19  Historisk                    57806 non-null  bool   \n",
      " 20  RedaktionelNote              5268 non-null   object \n",
      " 21  OmtryksNote                  140 non-null    object \n",
      " 22  AlternativeMedierNote        1766 non-null   object \n",
      " 23  AnfoerINote                  411 non-null    object \n",
      " 24  HjemmelVedroerer             37425 non-null  object \n",
      " 25  SenereAendringer             2711 non-null   object \n",
      " 26  ÆndrerI                      10222 non-null  object \n",
      " 27  Tiltræder                    82 non-null     object \n",
      " 28  EliUrl                       57806 non-null  object \n",
      "dtypes: bool(1), float64(3), int64(4), object(21)\n",
      "memory usage: 12.4+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jens\\AppData\\Local\\Temp\\ipykernel_18892\\3808103124.py:1: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding=encoding, sep=';')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path, encoding=encoding, sep=';')\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_nametemp = os.path.basename(df['ACCN'][0]) + \".pdf\"\n",
    "print(file_nametemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_nametemp = os.path.basename(df['ACCN'][0]) + \".xml\"\n",
    "print(file_nametemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "accn = []\n",
    "for object in df['ACCN']: \n",
    "    accn.append(object)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57806\n",
      "W20240917325\n"
     ]
    }
   ],
   "source": [
    "print(len(accn))\n",
    "print(accn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39409\n"
     ]
    }
   ],
   "source": [
    "file_names=[]\n",
    "def get_file_names(directory):\n",
    "    file_namesT = []\n",
    "    for dir in directory:\n",
    "        for root, dirs, files in os.walk(dir):\n",
    "            for file in files:\n",
    "                split_file= file.split(\".\")\n",
    "                file_name = split_file[0]\n",
    "                file_namesT.append(file_name)     \n",
    "    return file_namesT\n",
    "# Example usage\n",
    "directory_path = ['D:/school/ALL_PDFs/snip5']\n",
    "file_names = get_file_names(directory_path)\n",
    "print(len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18397\n",
      "['A20230076330' 'B20180021605' 'E19952P00A02' ... 'Y20060944958'\n",
      " 'Y20060945058' 'Y20061125558']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the two arrays\n",
    "\n",
    "\n",
    "# Find the non-duplicate elements\n",
    "non_duplicates = np.setdiff1d(accn, file_names)\n",
    "\n",
    "# Print the non-duplicates\n",
    "print(len(non_duplicates))\n",
    "print(non_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_pdf = []\n",
    "file_names = []\n",
    "def make_urls_and_file_names(files):\n",
    "    urls_pdfT = []\n",
    "    file_namesT = []\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        file_namesT.append(file)\n",
    "        urls_pdfT.append(\"https://www.retsinformation.dk/eli/accn/\" + file)\n",
    "        count += 1    \n",
    "        if count > 27490 :\n",
    "            return urls_pdfT,file_namesT\n",
    "    print(count)    \n",
    "    return urls_pdfT,file_namesT\n",
    "\n",
    "urls_pdf, file_names = make_urls_and_file_names(accn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "urls_pdf = []\n",
    "def get_file_names(directory):\n",
    "    file_namesT = []\n",
    "    count=0\n",
    "    urls_pdfT = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            split_file= file.split(\".\")\n",
    "            file_name = split_file[0]\n",
    "            file_namesT.append(file_name)\n",
    "            urls_pdfT.append(\"https://www.retsinformation.dk/eli/accn/\" + file_name)\n",
    "            count += 1    \n",
    "            if count > 27490 :\n",
    "                return urls_pdfT,file_namesT\n",
    "    print(count)        \n",
    "    return urls_pdfT, file_namesT\n",
    "# Example usage\n",
    "directory_path = 'D:/school/ALL_PDFs'\n",
    "urls_pdf, file_names = get_file_names(directory_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_pdf = ['https://lovkilden.dk/eli/retsinfo/1999/20028','https://lovkilden.dk/eli/retsinfo/2000/20071','https://lovkilden.dk/eli/retsinfo/2000/20072','https://lovkilden.dk/eli/retsinfo/2000/20073']\n",
    "file_names = ['E19993S00006','E20002P00A01','E20002P00E05','E20003S00006']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(urls_pdf)\n",
    "print(len(urls_pdf))\n",
    "print(file_names)\n",
    "print(len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "chunksed_filenamses = []\n",
    "\n",
    "chunksed_filenamses = list(chunks(file_names, 1))  \n",
    "chunksed_urls_pdf = list(chunks(urls_pdf, 1))\n",
    "  \n",
    "\n",
    "print(len(chunksed_urls_pdf))\n",
    "print(chunksed_urls_pdf[0])\n",
    "print(len(chunksed_filenamses))\n",
    "print(chunksed_filenamses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compined_lengt = 0\n",
    "\n",
    "for i in range(len(chunksed_filenamses)):\n",
    "    compined_lengt += len(chunksed_filenamses[i])\n",
    "    \n",
    "print(compined_lengt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = 0\n",
    "\n",
    "\n",
    "print(len(chunksed_urls_pdf[part]))\n",
    "print(chunksed_urls_pdf[part])\n",
    "print(len(chunksed_filenamses[part]))\n",
    "print(chunksed_filenamses[part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pdf_maker(urlPdf, filNames):\n",
    "    \n",
    "    pdf_fileT = print_pdf.PdfGenerator(urlPdf).main()\n",
    "\n",
    "    for i, url in enumerate(urlPdf):\n",
    "        file_name = os.path.basename(filNames[i]) + \".pdf\"\n",
    "        file_path = os.path.join(\"D:/school/result\", file_name)\n",
    "        with open(file_path, \"wb\") as outfile:\n",
    "            outfile.write(pdf_fileT[i].getbuffer())\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import asyncio\n",
    "import os \n",
    "import alive_progress as ap\n",
    "\n",
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def download(urls_pdfT,file_namesT): \n",
    "    pdf_maker(urls_pdfT, file_namesT)\n",
    "        \n",
    "leng = 1   \n",
    "        \n",
    "for i in range(leng):\n",
    "    if len(chunksed_urls_pdf[i]) == len(chunksed_filenamses[i]):\n",
    "        download(chunksed_urls_pdf[i], chunksed_filenamses[i])\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import asyncio\n",
    "import os \n",
    "import alive_progress as ap\n",
    "\n",
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "    return wrapped\n",
    "\n",
    "\n",
    "@background\n",
    "def download(url, fn):\n",
    "  r = requests.get(url)\n",
    "  file_name = os.path.basename(df['ACCN'][fn] + \".pdf\")\n",
    "  file_path = os.path.join(\"D:/school/bachlor_pdfs2\", file_name)\n",
    "  with open(file_path, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "     \n",
    "for i,url in enumerate(urls):\n",
    "    download(url,i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_schema = df.dtypes.to_dict()\n",
    "print(csv_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df.head())\n",
    "print (df.columns)\n",
    "print (df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print unique values in DokumentType column\n",
    "unique_values = df['DokumentType'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "# Count the occurrences of each unique value in \"DokumentType\"\n",
    "\n",
    "\n",
    "unique_values_count = len(unique_values)\n",
    "print (unique_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "plt.hist(df['DokumentType'], bins=83, alpha=0.5, label='DokumentType')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the CSV file\n",
    "\n",
    "# Create a new DataFrame to store the formatted content and metadata\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each row in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Download the content from the URL\n",
    "    response = requests.get(row['ELiurl'])\n",
    "    \n",
    "    # Parse the downloaded content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Format the text and append it and its metadata to the new DataFrame\n",
    "    formatted_text = format_text(text)  # You'll need to define this function\n",
    "    new_row = row.copy()\n",
    "    new_row['text'] = formatted_text\n",
    "    new_df = new_df.append(new_row)\n",
    "\n",
    "# Write the new DataFrame to a CSV file\n",
    "new_df.to_csv('formatted_content.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "api_url = \"https://api.retsinformation.dk/v1/Documents?documentId=DC001512\"\n",
    "\n",
    "response = requests.get(api_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    # Save the data to a file\n",
    "    with open(\"data.json\", \"w\") as file:\n",
    "        print(json.dumps(data, indent=4), file=file)\n",
    "else:\n",
    "    print(\"Error: Failed to retrieve data from the API\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_document(document_id):\n",
    "    api_url = f\"https://api.retsinformation.dk/v1/Documents?documentId={document_id}\"\n",
    "    response = requests.get(api_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        document = response.json()\n",
    "        return document\n",
    "    else:\n",
    "        print(\"Error: Failed to retrieve document from the API\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "document_id = \"DC001512\"\n",
    "document = get_document(document_id)\n",
    "print(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_api_base_url = \"https://api.stackexchange.com/2.3/search/advanced\"\n",
    "parameters = (\n",
    "        f\"?pagesize=100&page=1&order=desc&sort=creation&answers=1&tagged=python\"\n",
    "        \"&site=stackoverflow&filter=!*236eb_eL9rai)MOSNZ-6D3Q6ZKb0buI*IVotWaTb\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get(so_api_base_url + parameters).json()\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VRAM required for a 11b parameter LLM with q8 precision\n",
    "\n",
    "# Parameters\n",
    "num_parameters = 20e9  # 11 billion parameters\n",
    "precision = 4  # q8 (8 bits)\n",
    "\n",
    "# Calculate size of each parameter in bytes\n",
    "parameter_size = precision / 8  # bits to bytes\n",
    "\n",
    "# Calculate total memory required in bytes\n",
    "memory_required = num_parameters * parameter_size\n",
    "\n",
    "# Convert bytes to gigabytes\n",
    "vram_required = memory_required / (1024**3)  # B -> KB -> MB -> GB\n",
    "\n",
    "# Print result\n",
    "print(f\"VRAM required: {vram_required:.2f} GB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-sienc-visuel-mvgrUAeD-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
